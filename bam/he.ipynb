{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyze He's data to see how much ROH there is.\n",
    "Turns out there isn't much.\n",
    "In the two minimally contaminated male samples, there are only about 25cM of ROH genome-wide, I don't think that's enough for reliable inference.\n",
    "I think the Carribean dataset is a better alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid=\"GFW002.003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mpileup to hdf5\n",
    "from toHDF5 import mpileup2hdf5\n",
    "\n",
    "basepath=f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}\"\n",
    "for ch in range(1, 23):\n",
    "    print(f'processing chr{ch}')\n",
    "    mpileup2hdf5(f'{basepath}/mpileup/{iid}.chr{ch}.mpileup', \n",
    "        f'/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr{ch}.hdf5',\n",
    "        iid=iid, outPath=f'{basepath}/hdf5/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"/mnt/archgen/users/yilei/tools/hapROH/package\")  # hack to get local package first in path [FROM HARALD - DELETE!!!]\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_ind  # Need this import\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_chunk_negloglik\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_femaleROHcontam\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_multiChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapsb_ind(iid, chs=range(1,23), \n",
    "    path_targets_prefix = f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hdf5\",\n",
    "    h5_path1000g = \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr\", \n",
    "    meta_path_ref = \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/meta_df_all.csv\",\n",
    "    folder_out=f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hapRoh/\", prefix_out=\"\",\n",
    "    e_model=\"readcount\", p_model=\"SardHDF5\", post_model=\"Standard\",\n",
    "    processes=4, delete=False, output=True, save=True, save_fp=False, \n",
    "    n_ref=2504, diploid_ref=True, exclude_pops=[], readcounts=True, random_allele=False,\n",
    "    roh_in=1, roh_out=20, roh_jump=300, e_rate=0.01, e_rate_ref=1e-3, \n",
    "    cutoff_post = 0.999, max_gap=0, roh_min_l = 0.04, logfile=True, combine=True, \n",
    "    file_result=\"_roh_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapsb_chunk_negloglik(iid, 3, 0.05, 0.55, \n",
    "    f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hdf5/{iid}.chr3.hdf5\",\n",
    "    \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr\", \n",
    "    \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/meta_df_all.csv\",\n",
    "    f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hapRoh/\",\n",
    "    0.0, roh_in=1, roh_out=20, roh_jump=300, e_rate=0.01, e_rate_ref=0.0,\n",
    "    save=False, save_fp=False, n_ref=2504, diploid_ref=True, \n",
    "    exclude_pops=[], e_model=\"readcount_contam\", p_model=\"SardHDF5\", \n",
    "    readcounts=True, random_allele=False, prefix_out=\"\", logfile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid=\"GFW005.A0101\"\n",
    "hapsb_femaleROHcontam(iid, f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hapRoh/{iid}_roh_full.csv\", \n",
    "    f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hdf5/\", \n",
    "    \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr\", \n",
    "    \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/meta_df_all.csv\",\n",
    "    f\"/mnt/archgen/users/yilei/Data/He/contamX/{iid}/hapRoh/\", processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid=\"I2978\"\n",
    "contam, se = hapsb_femaleROHcontam(iid, f\"/mnt/archgen/users/yilei/Data/AGDP/contamX/{iid}/hapRoh/{iid}_roh_full.csv\", \n",
    "    f\"/mnt/archgen/users/yilei/Data/AGDP/contamX/{iid}/hdf5/\", \n",
    "    \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr\", \n",
    "    \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/meta_df_all.csv\",\n",
    "    f\"/mnt/archgen/users/yilei/Data/AGDP/contamX/{iid}/hapRoh/\", processes=4, e_rate=0.002526)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006106721763852304\n",
      "0.00038893090315670503\n"
     ]
    }
   ],
   "source": [
    "print(contam)\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid=\"I2978\"\n",
    "chunks = {}\n",
    "with open(f\"/mnt/archgen/users/yilei/Data/AGDP/contamX/{iid}/hapRoh/{iid}_roh_full.csv\") as f:\n",
    "    f.readline()\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        _, _, StartM, EndM, _, lengthM, _, ch, _, _ = line.strip().split(',')\n",
    "        StartM, EndM, lengthM = float(StartM), float(EndM), float(lengthM)\n",
    "        if lengthM >= 0.05:\n",
    "            chunks[ch] = (StartM + 0.005, EndM - 0.005)\n",
    "        line = f.readline()\n",
    "\n",
    "\n",
    "\n",
    "logliks = []\n",
    "for c in np.arange(0, 0.025, 0.001):\n",
    "    loglik = hapsb_multiChunk(c, chunks, \n",
    "        iid, f\"/mnt/archgen/users/yilei/Data/AGDP/contamX/{iid}/hdf5/\", \n",
    "        \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr\", \n",
    "        \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/meta_df_all.csv\",\n",
    "        f\"/mnt/archgen/users/yilei/Data/AGDP/contamX/{iid}/hapRoh/\", \n",
    "        conPop=[\"CEU\"], roh_in=1, roh_out=0, roh_jump=300, e_rate=0.002526, e_rate_ref=1e-3,\n",
    "        processes=4, save=False, save_fp=False, n_ref=2504, diploid_ref=True, \n",
    "        exclude_pops=[], e_model=\"readcount_contam\", p_model=\"SardHDF5\", \n",
    "        readcounts=True, random_allele=False, prefix_out=\"\", logfile=False)\n",
    "    logliks.append(loglik)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(0, 0.025, 0.001), logliks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Individual mixed.con10...\n",
      "31\n",
      "Running 22 total jobs; 4 in parallel.\n",
      "Starting Pool of multiple workers...\n",
      "Set Output Log path: /mnt/archgen/users/yilei/Data/AGDP/I4432/cov1over2/batch8/con10/hapRoh/mixed.con10/chr5/hmm_run_log.txtSet Output Log path: /mnt/archgen/users/yilei/Data/AGDP/I4432/cov1over2/batch8/con10/hapRoh/mixed.con10/chr1/hmm_run_log.txtSet Output Log path: /mnt/archgen/users/yilei/Data/AGDP/I4432/cov1over2/batch8/con10/hapRoh/mixed.con10/chr3/hmm_run_log.txtSet Output Log path: /mnt/archgen/users/yilei/Data/AGDP/I4432/cov1over2/batch8/con10/hapRoh/mixed.con10/chr7/hmm_run_log.txt\n",
      "\n",
      "\n",
      "\n",
      "Combining Information for 22 Chromosomes...\n",
      "Run finished successfully!\n"
     ]
    }
   ],
   "source": [
    "basepath=\"/mnt/archgen/users/yilei/Data/AGDP/I4432/cov1over2/batch8/con10\"\n",
    "iid=\"mixed.con10\"\n",
    "hapsb_ind(iid, chs=range(1,23), \n",
    "        path_targets_prefix = f\"{basepath}/hdf5\",\n",
    "        h5_path1000g = \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/chr\", \n",
    "        meta_path_ref = \"/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/meta_df_all.csv\",\n",
    "        folder_out=f\"{basepath}/hapRoh/\", prefix_out=\"\",\n",
    "        e_model=\"readcount_contam\", c=0.1, p_model=\"SardHDF5\", post_model=\"Standard\",\n",
    "        processes=4, delete=False, output=True, save=True, save_fp=False, \n",
    "        n_ref=2504, diploid_ref=True, exclude_pops=[], readcounts=True, random_allele=False,\n",
    "        roh_in=1, roh_out=20, roh_jump=300, e_rate=0.002, e_rate_ref=1e-3, logfile=True, combine=True, \n",
    "        file_result=\"_roh_full.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

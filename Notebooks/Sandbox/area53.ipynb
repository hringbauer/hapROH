{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import os\n",
    "import sys\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "import importlib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in posterior\n",
    "# posterior = numpy.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/posterior0.csv\")\n",
    "# # load some files maybe\n",
    "# # recombination map (in morgan)\n",
    "# recoMap = numpy.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/map.csv\", delimiter=',')\n",
    "# print (recoMap.shape)\n",
    "# # readcounts for target individual\n",
    "# # first line: reads for ref; second line: reads for alt\n",
    "# target = numpy.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/readcounts.csv\", delimiter=',')\n",
    "# print (target.shape)\n",
    "# numSnps = target.shape[1]\n",
    "# # read in references\n",
    "# # 0 in refHaps is refAllele\n",
    "# refHaps = numpy.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/refs.csv\", delimiter=',')\n",
    "# print (refHaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make it small for now, so we see what we are doing\n",
    "# numHaps = 8\n",
    "# numLoci = 12\n",
    "# refHaps = refHaps[0:numHaps,0:numLoci]\n",
    "# target = target[:,0:numLoci]\n",
    "# recoMap = recoMap[0:numLoci]\n",
    "\n",
    "# # refHaps = refHaps[360:380,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_rick = [refHaps, target, recoMap]\n",
    "# pickle.dump (pickle_rick, open(\"tmp.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_rick = pickle.load (open(\"tmp.pickle\", \"rb\"))\n",
    "myRefHaps = pickle_rick[0]\n",
    "myTarget = pickle_rick[1]\n",
    "myRecoMap = pickle_rick[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it small for now, so we see what we are doing\n",
    "numHaps = 8\n",
    "numLoci = 3\n",
    "myRefHaps = myRefHaps[0:numHaps,0:numLoci]\n",
    "myTarget = myTarget[:,0:numLoci]\n",
    "myRecoMap = myRecoMap[0:numLoci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path right, for some reason cython makes trouble\n",
    "sys.path.append(\"../../Python3/\")\n",
    "sys.path.append(\"../../Python3/Python3/\")\n",
    "sys.path.append(\"../../PackagesSupport/loadEigenstrat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm_inference import HMM_Analyze\n",
    "import msTransitions\n",
    "import msEmissions\n",
    "import msFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_transition_matrices (rates, rec_v):\n",
    "    transition_matrices = numpy.zeros((len(rec_v),6,6))\n",
    "    for i in range(len(rec_v)):\n",
    "        transition_matrices[i] = numpy.eye(6)\n",
    "#         transition_matrices[i] = numpy.zeros((6,6))\n",
    "#         transition_matrices[i,:2,:2] = 0.5\n",
    "#         transition_matrices[i,2:4,2:4] = 0.5\n",
    "#         transition_matrices[i,2:4,2:4] = numpy.ones((2,2)) - numpy.eye(2)\n",
    "#         transition_matrices[i,4:6,4:6] = 0.5\n",
    "    return transition_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"msTransitions\"])\n",
    "from msTransitions import rate_matrix_oneSL, exponentiate_rate_matrices, allele_frequencies\n",
    "from msTransitions import one_step_transitions_reference, non_roh_state_map, non_roh_transition_matrices\n",
    "from msHMM import fancy_initial_distribution, stationary_inital_distribution\n",
    "importlib.reload(sys.modules[\"msEmissions\"])\n",
    "from msEmissions import extended_genotype_emissions, extended_rc_emission_log, extended_binom_emission\n",
    "importlib.reload(sys.modules[\"msFun\"])\n",
    "from msFun import extended_fwd_bkwd_fast\n",
    "\n",
    "\n",
    "def analyze_targets (targets, refHaps, recoMap, pi_s = 1e-4, pi_l = 1e-4,\n",
    "                     in_S = 100, in_L = 2, out_S = 400, out_L = 10, roh_jump = 200,\n",
    "                     e_rate_ref=1e-3, e_rate=1e-2):\n",
    "    \n",
    "    # see how many targets we have\n",
    "    if (len(targets.shape) == 2):\n",
    "        # only one target, prepare accordingly\n",
    "        targets = targets[None,:,:]\n",
    "    # if already multiple targets, all fine\n",
    "    \n",
    "    # prepare target independent things\n",
    "    \n",
    "    # set up all the necessary stuff\n",
    "    n_ref = refHaps.shape[0]\n",
    "    n_loci = refHaps.shape[1]\n",
    "\n",
    "    # prepare the recombination map\n",
    "    # fake using a member function of class HMM_Analyze\n",
    "    blub = type('', (), {})()\n",
    "    blub.r_map = recoMap\n",
    "    blub.output = False\n",
    "    r_map = HMM_Analyze.prepare_rmap (self=blub)\n",
    "\n",
    "    # transition rate matrix Q\n",
    "    # t_mat = new_calc_transitions (roh_in=100, roh_out=100, roh_jump=100)\n",
    "    Q = rate_matrix_oneSL (in_S = in_S, in_L = in_L, out_S = out_S, out_L = out_L, roh_jump = roh_jump)\n",
    "#     Q = numpy.zeros((6,6))\n",
    "    # marginal properbilities\n",
    "    f_marg = allele_frequencies (refHaps)\n",
    "\n",
    "    # initial distribution\n",
    "#     init_d = numpy.log (fancy_initial_distribution (n_ref, f_marg[0], pi_s=pi_s, pi_l=pi_l))\n",
    "    init_d = numpy.log (stationary_inital_distribution (n_ref, f_marg[0], Q))\n",
    "    \n",
    "    # transition\n",
    "    transition_matrices = exponentiate_rate_matrices (rates=Q, rec_v=r_map)\n",
    "#     transition_matrices = fake_transition_matrices (rates=Q, rec_v=r_map)\n",
    "    # also need the allele frequencies\n",
    "    f_trans = one_step_transitions_reference (refHaps, f_marg)\n",
    "    # get transition matrices between the non-ROH states\n",
    "    non_roh_transitions = non_roh_transition_matrices (transition_matrices, f_trans, f_marg)\n",
    "\n",
    "    # emission\n",
    "    # prepare the emissions for all loci\n",
    "    e_mat_geno = extended_genotype_emissions (refHaps, e_rate_ref)\n",
    "    \n",
    "    # now the target specific things\n",
    "    all_ll = numpy.zeros ((targets.shape[0],targets.shape[2]))\n",
    "    for i in range(targets.shape[0]):\n",
    "        thisTarget = targets[i]\n",
    "#         print (thisTarget)\n",
    "        \n",
    "        # target specific emissions\n",
    "        e_mat_full = numpy.log (extended_binom_emission (ob_stat=thisTarget, e_mat=e_mat_geno, e_rate=e_rate))\n",
    "        # just some checks\n",
    "        assert(numpy.max(e_mat_full) < 0) \n",
    "\n",
    "        # I think we don't need these for now\n",
    "        # n_states = np.shape(e_mat)[0]\n",
    "        # n_loci = np.shape(e_mat)[1]\n",
    "\n",
    "        (newPost, fwd, bwd, tot_ll) = extended_fwd_bkwd_fast (init_d=init_d, e_prob0=e_mat_full,\n",
    "                                          t=transition_matrices, f_marg=f_marg, f_trans=f_trans,\n",
    "                                          non_roh_transitions=non_roh_transitions, full=True)\n",
    "        # newPost = old_fwd_bkwd_fast (e_prob0=e_mat, t=t_mat_full, in_val=in_val)\n",
    "        # (post, fwd, bwd, tot_ll) = new_fwd_bkwd_fast (e_mat, t_mat=None, t_mat_full, in_val, full=True)\n",
    "        # sum over hidden states\n",
    "        all_ll[i,:] = numpy.sum(numpy.exp(fwd),axis=1)\n",
    "        print (numpy.sum (numpy.exp(newPost), axis=1))\n",
    "    \n",
    "    # give it away now\n",
    "    return all_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage Full:\n",
      "Memory Usage: 137.777152 mB\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "results = analyze_targets (myTarget, myRefHaps, myRecoMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTargets = -numpy.ones((12,2,3))\n",
    "\n",
    "allTargets[0] = numpy.array([[0,0,0],\n",
    "                             [1,1,2]])\n",
    "\n",
    "allTargets[1] = numpy.array([[0,0,1],\n",
    "                             [1,1,1]])\n",
    "\n",
    "allTargets[2] = numpy.array([[0,0,2],\n",
    "                             [1,1,0]])\n",
    "\n",
    "allTargets[3] = numpy.array([[0,1,0],\n",
    "                             [1,0,2]])\n",
    "\n",
    "allTargets[4] = numpy.array([[0,1,1],\n",
    "                             [1,0,1]])\n",
    "\n",
    "allTargets[5] = numpy.array([[0,1,2],\n",
    "                             [1,0,0]])\n",
    "\n",
    "allTargets[6] = numpy.array([[1,0,0],\n",
    "                             [0,1,2]])\n",
    "\n",
    "allTargets[7] = numpy.array([[1,0,1],\n",
    "                             [0,1,1]])\n",
    "\n",
    "allTargets[8] = numpy.array([[1,0,2],\n",
    "                             [0,1,0]])\n",
    "\n",
    "allTargets[9] = numpy.array([[1,1,0],\n",
    "                             [0,0,2]])\n",
    "\n",
    "allTargets[10] = numpy.array([[1,1,1],\n",
    "                              [0,0,1]])\n",
    "\n",
    "allTargets[11] = numpy.array([[1,1,2],\n",
    "                              [0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage Full:\n",
      "Memory Usage: 137.834496 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.834496 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.834496 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.834496 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n",
      "Memory Usage Full:\n",
      "Memory Usage: 137.838592 mB\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# results = analyze_targets (allTargets, myRefHaps, myRecoMap, pi_s = 0, pi_l = 0)\n",
    "results = analyze_targets (allTargets, myRefHaps, myRecoMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(results[:,0])/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(results[:,1])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(results[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

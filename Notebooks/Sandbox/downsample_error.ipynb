{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot for downsampling / throwing in errors\n",
    "Plan: Input is a a HDF5, Output is a HDF5. Eventually make class that can downsample, and/or throw errors on the reads.\n",
    "\n",
    "Class is a wrapper of an HDF5, and applies the operations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harald/git/HAPSBURG\n"
     ]
    }
   ],
   "source": [
    "import allel\n",
    "import h5py  # Python Package to do the HDF5.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import socket\n",
    "import os\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket.gethostname() == \"midway2-0401.rcc.local\" or socket.gethostname() == \"midway2-0402.rcc.local\":\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifyHDF5Genotypes(object):\n",
    "    \"\"\"Class for Modifying HDF4 genotypes\"\"\"\n",
    "\n",
    "    f = 0    # The hdf5 object to modify\n",
    "    original_path = \"\" # Where to find the original HDF5\n",
    "    save_path = \"\"  # Where to save the modified HDF5 to\n",
    "    output = True # Whether to print any output\n",
    "\n",
    "    def __init__(self, original_path=\"\", save_path=\"\", output=True):\n",
    "        \"\"\"pop_path: Where to load a HDF5 from\n",
    "           save_path: Where to save the new HDF5 to\"\"\"\n",
    "        self.output = output\n",
    "        \n",
    "        if output == True:\n",
    "            print(\"Heyho back old friend. I started running\")\n",
    "        \n",
    "        if len(original_path)>0:\n",
    "            self.original_path = original_path\n",
    "            self.load_data()\n",
    "        else:\n",
    "            print(\"No HDF5 Loaded! Alarm. Alarm. Alarm.\")\n",
    "\n",
    "    def load_data(self, path=\"\"):\n",
    "        \"\"\"Load the HDF5 Data\"\"\"\n",
    "        if len(path)==0:\n",
    "            path = self.original_path\n",
    "        self.f = h5py.File(h5_path, \"r\") # Load for Sanity Check. See below!\n",
    "        \n",
    "        if self.output == True:\n",
    "            print(\"Loaded HDF5\")\n",
    "            print(\"Loaded %i variants\" % np.shape(self.f[\"calldata/GT\"])[0])\n",
    "            print(\"Loaded %i individuals\" % np.shape(self.f[\"calldata/GT\"])[1])\n",
    "            print(list(self.f[\"calldata\"].keys()))\n",
    "            print(list(self.f[\"variants\"].keys()))\n",
    "            #self.f[\"samples\"] # Samples Vector\n",
    "\n",
    "    def save_data(self, path=\"\"):\n",
    "        \"\"\"Save HDF5 Data\"\"\"\n",
    "        raise NotImplementedError(\"Implement this\")\n",
    "\n",
    "\n",
    "    def create_error(self):\n",
    "        \"\"\"Create Error on the HDF5\"\"\"\n",
    "        raise NotImplementedError(\"Implement this\")\n",
    "\n",
    "    def downsample(self):\n",
    "        \"\"\"Downsample the HDF5 to fewer reads.\n",
    "        Update also the recombination and position map if needed to remove missing values\"\"\"\n",
    "        raise NotImplementedError(\"Implement this\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "h5_path = \"./Simulated/1000G_Mosaic/TSI5/ch3_4cm/data.h5\"\n",
    "\n",
    "## Load HDF5\n",
    "f = h5py.File(h5_path, \"r\") # Load for Sanity Check. See below!\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))\n",
    "#print(list(f[\"samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "m = ModifyHDF5Genotypes(original_path=\"./Simulated/1000G_Mosaic/TSI5/ch3_4cm/data.h5\", save_path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "### Import from Harald to deal with Folder Structure\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name[:7] == \"midway2\":\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sloppyROH(recoMap, target, refHaps, windowSize = 0.001):\n",
    "    \"\"\"Figure out per snp agreement between references and reads from target\n",
    "    how many reads agree with reference alleles?\"\"\"\n",
    "    refAgree = (1-refHaps) * target[0,:]\n",
    "    # how many reads agree with alternative alleles?\n",
    "    altAgree = refHaps * target[1,:]\n",
    "    # the total agreement at each SNP\n",
    "    totalAgree = refAgree + altAgree\n",
    "    \n",
    "    numSnps = np.shape(target)[1]\n",
    "    \n",
    "    # make a dict that tells you which SNPs fall in a window around the focal SNP\n",
    "    neighborhood = {}\n",
    "    for p in range(numSnps):\n",
    "        # debug print\n",
    "#         if (p % 10000 == 0):\n",
    "#             print (p)\n",
    "        # the map relative to snp p\n",
    "        relativeMap = recoMap - recoMap[p]\n",
    "        # the indices of the snps that are in the window around p\n",
    "        themIndices = numpy.nonzero(abs(relativeMap) < windowSize)\n",
    "        neighborhood[p] = themIndices\n",
    "    \n",
    "    # need total counts per snp too normalize\n",
    "    countsPerSnp = numpy.sum (target, axis=0)\n",
    "    \n",
    "    # now compute the number for every snp using the neighborhoods\n",
    "    myROH = numpy.zeros(numSnps)\n",
    "    for p in range(numSnps):\n",
    "        # debug print\n",
    "#         if (p % 10000 == 0):\n",
    "#             print (p)\n",
    "        # get your window\n",
    "        daHood = neighborhood[p]\n",
    "        # total number of reads in this window\n",
    "        totalReads = numpy.sum(countsPerSnp[daHood])\n",
    "        # get the agreement with ref haps in this window\n",
    "        neighborAgreePerSnp = totalAgree[:,daHood]\n",
    "        # total agreement with each ref hap in this window\n",
    "        totalNeighborAgree = numpy.sum (neighborAgreePerSnp, axis=2)\n",
    "        # relative to count number in window\n",
    "        relativeNeighborAgree = totalNeighborAgree / totalReads\n",
    "        # and store the max\n",
    "        myROH[p] = numpy.max(relativeNeighborAgree)\n",
    "        \n",
    "    # give it away now\n",
    "    return myROH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sloppyROHToo (recoMap, target, refHaps, windowSize = 0.001):\n",
    "    \"\"\"Figure out per snp agreement between references and reads from target\n",
    "    Hhow many reads agree with reference alleles?\"\"\"\n",
    "    refAgree = (1-refHaps) * target[0,:]\n",
    "    # how many reads agree with alternative alleles?\n",
    "    altAgree = refHaps * target[1,:]\n",
    "    # the total agreement at each SNP\n",
    "    totalAgree = refAgree + altAgree\n",
    "    \n",
    "    # what are the bounds of the window around the focal SNP\n",
    "    firstNeighbor = numpy.searchsorted (recoMap + windowSize, recoMap)\n",
    "    lastNeighbor = numpy.searchsorted (recoMap - windowSize, recoMap)\n",
    "\n",
    "    # need total counts per snp too normalize\n",
    "    countsPerSnp = numpy.sum (target, axis=0)\n",
    "    \n",
    "    # now compute the number for every snp using the neighborhoods\n",
    "    numSnps = np.shape(target)[1]\n",
    "    myROH = numpy.zeros(numSnps)\n",
    "    for p in range(numSnps):\n",
    "        # debug print\n",
    "#         if (p % 10000 == 0):\n",
    "#             print (p)\n",
    "        # get your window\n",
    "        begin = firstNeighbor[p]\n",
    "        end = lastNeighbor[p]\n",
    "        # total number of reads in this window\n",
    "        totalReads = numpy.sum(countsPerSnp[begin:end])\n",
    "        # get the agreement with ref haps in this window\n",
    "        neighborAgreePerSnp = totalAgree[:,begin:end]\n",
    "        # total agreement with each ref hap in this window\n",
    "        totalNeighborAgree = numpy.sum (neighborAgreePerSnp, axis=1)\n",
    "        # relative to count number in window\n",
    "        relativeNeighborAgree = totalNeighborAgree / totalReads\n",
    "        # and store the max\n",
    "        myROH[p] = numpy.max (relativeNeighborAgree)\n",
    "        \n",
    "    # give it away now\n",
    "    return myROH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectWindow(begin, end, totalAgree, countsPerSnp):\n",
    "    \"\"\"Collect average agreement rate in totalAgree from begin to end.\n",
    "    coutsPerSNP: The Count of every SNP\"\"\"\n",
    "    totalReads = np.sum(countsPerSnp[begin:end])\n",
    "    # get the agreement with ref haps in this window\n",
    "    totalNeighborAgree = np.sum(totalAgree[:,begin:end], axis=1)\n",
    "    # return max of agreement relative to count number in window\n",
    "    return (np.max(totalNeighborAgree / totalReads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sloppyROHThree (recoMap, target, refHaps, windowSize = 0.001):\n",
    "    \"\"\"Figure out per SNP agreement between references and reads from target\n",
    "    how many reads agree with reference alleles?\"\"\"\n",
    "    ### Asses how many reads agree with ref and alternative alleles?\n",
    "    refAgree = (1 - refHaps) * target[0,:]\n",
    "    altAgree = refHaps * target[1,:]\n",
    "    totalAgree = refAgree + altAgree     # Total Agreement at each SNP\n",
    "    \n",
    "    # what are the bounds of the window around the focal SNP\n",
    "    firstNeighbor = np.searchsorted(recoMap + windowSize, recoMap)\n",
    "    lastNeighbor = np.searchsorted(recoMap - windowSize, recoMap)\n",
    "\n",
    "    # need total counts for each SNP to normalize\n",
    "    countsPerSnp = np.sum(target, axis=0)\n",
    "    \n",
    "    # compute the number for every snp using the neighborhoods\n",
    "    myROH = np.array([collectWindow(x, y, totalAgree, countsPerSnp) for (x,y) in zip(firstNeighbor, lastNeighbor)])\n",
    "    \n",
    "    return myROH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized version of collect window\n",
    "# be sure to exlcude all but first two arguments\n",
    "vecCollectWindow = numpy.vectorize(collectWindow, excluded=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sloppyROHFour (recoMap, target, refHaps, windowSize = 0.001):\n",
    "    \"\"\"Figure out per snp agreement between references and reads from target\n",
    "    # how many reads agree with reference alleles?\"\"\"\n",
    "    refAgree = (1-refHaps) * target[0,:]\n",
    "    # how many reads agree with alternative alleles?\n",
    "    altAgree = refHaps * target[1,:]\n",
    "    # the total agreement at each SNP\n",
    "    totalAgree = refAgree + altAgree\n",
    "    \n",
    "    # what are the bounds of the window around the focal SNP\n",
    "    firstNeighbor = numpy.searchsorted (recoMap + windowSize, recoMap)\n",
    "    lastNeighbor = numpy.searchsorted (recoMap - windowSize, recoMap)\n",
    "\n",
    "    # need total counts per snp too normalize\n",
    "    countsPerSnp = numpy.sum (target, axis=0)\n",
    "    \n",
    "    # now compute the number for every snp using the neighborhoods\n",
    "    myROH = vecCollectWindow (firstNeighbor, lastNeighbor, totalAgree, countsPerSnp)\n",
    "    \n",
    "    # give it away now\n",
    "    return myROH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sloppyROH_cumsum(recoMap, target, refHaps, windowSize = 0.001):\n",
    "    \"\"\"\n",
    "    Figure out per snp agreement between references and reads from target\n",
    "    Return Max. fraction of reads agreeing with Ref Panel\n",
    "    windowsize: Extension to each side [in cM]\n",
    "    \"\"\"\n",
    "    #n_snps = len(recoMap)\n",
    "    # Calculate total Nr of Mismatches for all ref\n",
    "    refAgree = (1-refHaps) * target[0,:]\n",
    "    altAgree = refHaps * target[1,:]\n",
    "    totalAgree = refAgree + altAgree\n",
    "    \n",
    "    ### what are the bounds of the window around the focal SNP\n",
    "    firstNeighbor = np.searchsorted(recoMap + windowSize, recoMap)\n",
    "    lastNeighbor = np.searchsorted(recoMap - windowSize, recoMap)\n",
    "    lastNeighbor = np.clip(lastNeighbor, a_min=None, a_max=len(recoMap)-1) # To avoid the overshooting the last Index\n",
    "    \n",
    "    countsPerSnp = np.sum(target, axis=0)       # Calculate total counts per snp for normalization\n",
    "    \n",
    "    totalAgree_cum = np.cumsum(totalAgree, axis=1)\n",
    "    pad_zeros = np.zeros((np.shape(totalAgree)[0], 1)) # To add 0s at beginning of first axis\n",
    "    totalAgree_cum = np.concatenate([pad_zeros, totalAgree_cum], axis=1) \n",
    "    countsPerSnp_cum = np.r_[0, np.cumsum(countsPerSnp)] # Add 0 in beginning\n",
    "    \n",
    "    totalAgree_window = totalAgree_cum[:, lastNeighbor] - totalAgree_cum[:, firstNeighbor]\n",
    "    countsPerSnp_window = countsPerSnp_cum[lastNeighbor] - countsPerSnp_cum[firstNeighbor]\n",
    "    \n",
    "    agree_rate_window = totalAgree_window / countsPerSnp_window    # Average Agree Rate per Window\n",
    "    max_agree_rate_window = np.max(agree_rate_window, axis=0)   # For the \"best\" Ref Haplotype\n",
    "    return max_agree_rate_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load for Matthias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in posterior\n",
    "posterior = np.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/posterior0.csv\")\n",
    "# load some files maybe\n",
    "# recombination map (in morgan)\n",
    "recoMap = np.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/map.csv\", delimiter=',')\n",
    "print (recoMap.shape)\n",
    "# readcounts for target individual\n",
    "# first line: reads for ref; second line: reads for alt\n",
    "target = np.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/readcounts.csv\", delimiter=',')\n",
    "print (target.shape)\n",
    "numSnps = target.shape[1]\n",
    "# read in references\n",
    "refHaps = numpy.loadtxt (\"/Users/steinrue/googleDrive/misc/data_matthias/refs.csv\", delimiter=',')\n",
    "print (refHaps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(basepath):\n",
    "    \"\"\"Load relevant data from folder basepath.\n",
    "    Return posterior, recomap, target and reference haplotype\"\"\"\n",
    "\n",
    "    ### Load all Data\n",
    "    posterior = np.loadtxt(basepath + \"posterior0.csv\")\n",
    "    recoMap = np.loadtxt(basepath + \"map.csv\", delimiter=',')\n",
    "    target = np.loadtxt(basepath + \"readcounts.csv\", delimiter=',')\n",
    "    refHaps = np.loadtxt(basepath + \"refs.csv\", delimiter=',')\n",
    "    \n",
    "    ### Sanity Checks\n",
    "    numSnps = target.shape[1]\n",
    "    assert(len(posterior) == numSnps)\n",
    "    assert(len(recoMap) == numSnps)\n",
    "    assert(np.shape(refHaps)[1]==numSnps)\n",
    "    \n",
    "    return posterior, recoMap, target, refHaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "basepath = \"./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/\"\n",
    "posterior, recoMap, target, refHaps = load_data(basepath)\n",
    "print(np.shape(refHaps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myRoh = sloppyROH(recoMap, target, refHaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myRohToo = sloppyROHToo(recoMap, target, refHaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myRohThree = sloppyROHThree(recoMap, target, refHaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myRohFour = sloppyROHFour(recoMap, target, refHaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myRoh_cumsum = sloppyROH_cumsum(recoMap, target, refHaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRoh_cumsum[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sanity Check\n",
    "np.max(np.abs(myRoh_cumsum - myRohFour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(myRohFour, myRoh_cumsum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roh(target, myRoh, N=40, figsize=(16,4), darange=(5000,8000), savepath=\"\", fs=12):\n",
    "    # where do the observed reads show heterozygosity?\n",
    "    hets = (target[0,:]>0) * (target[1,:]>0)\n",
    "    # smooth it a bit (careful, this does not really use the genetic map)\n",
    "    smoothHets = np.convolve(hets, np.ones(N) / N, mode='same')\n",
    "    \n",
    "    daRange = np.arange(darange[0], darange[1]) # For the x axis\n",
    "    \n",
    "    myRoh = myRoh[daRange]\n",
    "    #myRoh = (myRoh - np.min(myRoh)) * 1 / (np.max(myRoh) - np.min(myRoh))  # Normalize\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(recoMap[daRange]*100, (hets[daRange]-0.05)*1.1, \"o\", ms=2, label=\"Heterozgyotes Up\", color=\"blue\")\n",
    "    plt.plot(recoMap[daRange]*100, myRoh, label=\"Best Local Match Rate\", color=\"red\")\n",
    "    plt.plot(recoMap[daRange]*100, 1 - np.exp(posterior[daRange]), label=\"HAPSBURG Posterior\")\n",
    "    #plt.plot(recoMap[daRange]*100, 1 - smoothHets[daRange], label=\"Smoothed Heterozygotes\", lw=2)\n",
    "    plt.plot(recoMap[daRange]*100, myRoh >0.99, label=\"Cutoff BLMR: 0.99\", lw=2, color=\"green\")\n",
    "    \n",
    "    plt.legend(loc=\"center left\", fontsize=fs)\n",
    "    # plt.plot (recoMap[daRange]*100, 1-numpy.exp(posterior[daRange])>0.8, recoMap[daRange]*100, (myRoh > th)[daRange])\n",
    "    # plt.plot (recoMap[daRange]*100, 1-numpy.exp(posterior[daRange])>0.8, recoMap[daRange]*100, (myRoh > th)[daRange], recoMap[daRange]*100, (hets[daRange]-0.1)*1.2, \"o\")\n",
    "    # plt.plot (recoMap[daRange]*100, 1-numpy.exp(posterior[daRange])>0.8, recoMap[daRange]*100, (myRoh > th)[daRange])\n",
    "    plt.xlabel(\"cM\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roh(target, myRoh_cumsum, darange=(5000, 8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some truth\n",
    "truthTable = pandas.read_csv (\"/Users/steinrue/tmp/haraldHAPSBURG/data_matthias/roh_gt.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truthTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a truth vector\n",
    "truth = numpy.zeros (numSnps)\n",
    "beginnings = numpy.searchsorted (recoMap, truthTable[\"ROH_Begin\"])\n",
    "ends = numpy.searchsorted (recoMap, truthTable[\"ROH_End\"])\n",
    "assert (len(beginnings) == len(ends))\n",
    "for i in range(len(beginnings)):\n",
    "    truth [beginnings[i]:ends[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daRange = numpy.arange(0,4000)\n",
    "plt.figure (figsize=(16,4))\n",
    "plt.plot (recoMap[daRange]*100, 1-numpy.exp(posterior[daRange]),\n",
    "          recoMap[daRange]*100, (hets[daRange]-0.1)*1.2, \"o\",\n",
    "          recoMap[daRange]*100, 1-smoothHets[daRange],\n",
    "          recoMap[daRange]*100, (truth[daRange]-0.2)*1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.corrcoef (truth, 1-numpy.exp(posterior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.corrcoef (truth, myRohFour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRoh = myRohFour = sloppyROHFour (recoMap, target, refHaps, 0.004)\n",
    "numpy.corrcoef (truth, myRohFour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.corrcoef (truth, hets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.corrcoef (truth, smoothHets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 800\n",
    "smoothHets = numpy.convolve(hets, numpy.ones (N)/N, mode='same')\n",
    "numpy.corrcoef (truth, smoothHets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daRange = numpy.arange(18000,28000)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot (recoMap[daRange]*100, 1-numpy.exp(posterior[daRange]),\n",
    "          recoMap[daRange]*100, (hets[daRange]-0.1)*1.2, \"o\",\n",
    "          recoMap[daRange]*100, (1-smoothHets[daRange])>0.967,\n",
    "          recoMap[daRange]*100, (truth[daRange]-0.2)*1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

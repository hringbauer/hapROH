{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ROH Results into one big dataframe\n",
    "Contains cleaning lines (i.e. to remove duplicates), fix flipped coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0405.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colorbar as clb\n",
    "import matplotlib.colors as cls\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "### Additional Imports from Support Packages\n",
    "sys.path.append(\"./package/hapsburg/\")\n",
    "from PackagesSupport.pp_individual_roh_csvs import extract_sub_df_geo_kw, give_df_clsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that pre-process Data\n",
    "Add \"region\" Field. Add \"color\" (based on Time) field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Post-Process Regions\n",
    "def set_regions_from_csv(df, csv_path = \"./Data/RegionDefinition/regions.csv\", \n",
    "                         output=True, sep=\",\"):\n",
    "    \"\"\"Set Region column in df, by loading coordinates from csv_path\"\"\"\n",
    "    df_regions= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_regions.iterrows():\n",
    "        region = row[\"Region\"] \n",
    "        if output:\n",
    "            print(f\"Doing {region}...\")\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = extract_sub_df_geo_kw(df, row[\"Lat_low\"], row[\"Lat_high\"], row[\"Lon_low\"], \n",
    "                                     row[\"Lon_high\"], kw, output=output)\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"region\"] = row[\"Region\"] \n",
    "    return df\n",
    "\n",
    "############################################################################\n",
    "### Post-Process Colors\n",
    "def set_colors_from_csv(df, csv_path = \"./Data/RegionDefinition/colors.csv\", \n",
    "                         output=True, sep=\",\"):\n",
    "    \"\"\"Set Color column in df, by loading colors from csv_path\"\"\"\n",
    "    df_colors= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_colors.iterrows():\n",
    "        color = row[\"Color\"] \n",
    "        ig = row[\"InternalGroup\"]\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = give_df_clsts(df, search=kw, col=\"pop\")\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"color\"] = color\n",
    "        df.loc[idx, \"clst\"] = row[\"clst\"]\n",
    "        \n",
    "        if output:\n",
    "            print(f\"Doing {ig}...\")\n",
    "            print(f\"Found {np.sum(idx)} Inds - set to color: {color}\")\n",
    "    ### Do old HunterGatherers\n",
    "    return df\n",
    "\n",
    "def set_color_hg_minage(df, color=\"blue\", min_age=10500, output=True):\n",
    "    \"\"\"Set the color for all ancient Huntergatherers.\"\"\"\n",
    "    idx = df[\"age\"] > min_age\n",
    "    df.loc[idx, \"color\"] = color\n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Inds >{min_age} BP - set to color: {color}\")\n",
    "    return df\n",
    "    \n",
    "def set_color_modern(df, color=\"white\", output=True):\n",
    "    \"\"\"Set color for all Modern Samples\"\"\"\n",
    "    idx = df[\"age\"] == 0\n",
    "    df.loc[idx, \"color\"] = color\n",
    "    df.loc[idx, \"clst\"] = \"Modern\"\n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Moderns - set to color: {color}\")\n",
    "    return df\n",
    "\n",
    "def remove_ids(df, csv_path = \"./Data/RegionDefinition/remove_ids.csv\", output=True, del_col=\"iid\"):\n",
    "    \"\"\"Remove Individuals whose del_col column contains\n",
    "    string from del_strings (list)\"\"\"\n",
    "    del_list = np.loadtxt(csv_path, dtype=\"str\", ndmin=1)\n",
    "    \n",
    "    n=len(df)\n",
    "    for ds in del_list:\n",
    "        idx =  df[del_col].str.contains(ds)\n",
    "        #iids = df[del_col][idx].values\n",
    "        #print(f\"Deleting: {iids}\")\n",
    "        df = df[~idx]\n",
    "    if output:\n",
    "        print(f\"Removed {n-len(df)} / {n} Individuals.\")\n",
    "    return df\n",
    "\n",
    "def remove_duplicates(df, cov_col=\"n_cov_snp\", id_col=\"iid\", master_col = \"Master ID\",\n",
    "                      path_master=\"./Data/ReichLabEigenstrat/Raw.v42.4/v42.4.1240K.anno\",\n",
    "                      output=True):\n",
    "    \"\"\"Remove duplicates based on merging with Master Dataframe.\n",
    "    Return Filtered Dataframe\n",
    "    id_col: Column onto which to merge\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    df_meta = pd.read_csv(path_master, sep=\"\\t\")\n",
    "    df_meta[id_col] = df_meta.filter(regex='Instance ID')\n",
    "    \n",
    "    df_meta = df_meta[[id_col, master_col]]  # Only relevant columns\n",
    "    df_merge = pd.merge(df, df_meta, on=id_col, how=\"left\")  # Merge on IID\n",
    "    df_merge = df_merge.sort_values(by=cov_col, ascending=False) # Put IIDs with most SNPs first\n",
    "    ### Fill up NaNs with IDs\n",
    "    idx = df_merge[master_col].isnull()\n",
    "    df_merge.loc[idx, master_col] = df_merge.loc[idx, id_col]\n",
    "    df_merge = df_merge.drop_duplicates(subset=master_col, keep=\"first\")\n",
    "    \n",
    "    df_merge = df_merge.drop(columns=master_col)  #Drop the Master ID Col again\n",
    "\n",
    "    if output:\n",
    "        print(f\"Removed {n- len(df_merge)} / {n} Duplicates\")\n",
    "    return df_merge\n",
    "\n",
    "############################################################################\n",
    "############################################################################\n",
    "\n",
    "def merge_in_economy_iid(df, path_economy=\"\", min_cert=3,\n",
    "                         economy_col=\"economy\", cty_col=\"certainty\",\n",
    "                         match_col = \"iid\", case=False):\n",
    "    \"\"\"Create/Set Column economy_col into dataframe df. Check for substring matches (to be future proof)\n",
    "    Return modified dataframe.\n",
    "    match_col: What columns to match\n",
    "    economy_col: What column to transfer over\n",
    "    case: Whether IID substring matching is case sensitive.\n",
    "    min_cert: Minimum certainty\"\"\"\n",
    "    df_match = pd.read_csv(path_economy)  # Load the data\n",
    "    idx_uncertain = (df_match[cty_col] < min_cert)\n",
    "    df_match.loc[idx_uncertain, economy_col] = \"Low Certainty\"\n",
    "    \n",
    "    ### Create new, empty economy column if needed\n",
    "    if not economy_col in df.columns:\n",
    "        df[economy_col] = np.nan\n",
    "    \n",
    "    ### Match all IIDs\n",
    "    for i,m in enumerate(df_match[match_col]):\n",
    "        m = m.rstrip()  # Remove all right whitespaces\n",
    "        if len(m)==0:\n",
    "            continue\n",
    "        idx = df[match_col].str.contains(m, case=case)\n",
    "        df.loc[idx, economy_col] = df_match.loc[i,economy_col]\n",
    "    return df\n",
    "\n",
    "def change_economy(df, col=\"economy\",\n",
    "                   str1=\"mixed\", new=\"Mixed\", output=True):\n",
    "    \"\"\"Change Economy assignment from str1 to new\"\"\"\n",
    "    idx = (df[col].str.contains(str1)) & (~df_t[col].isnull())\n",
    "    df.loc[idx, col] = new\n",
    "    \n",
    "    if output:\n",
    "        print(f\"Changing {np.sum(idx)} Individuals to: {new}\")\n",
    "    return df\n",
    "\n",
    "def set_economy_color(df, path_color_df=\"./Data/RegionDefinition/economy_colors.csv\", \n",
    "                      color_col=\"color\", economy_col=\"economy\"):\n",
    "    \"\"\"Set Color Based on Economy.\n",
    "    Assume color column in df exists\"\"\"\n",
    "    df_c = pd.read_csv(path_color_df)\n",
    "    dct = dict(zip(df_c[economy_col], df_c[color_col]))  # Create mapping dictionary\n",
    "    df[color_col] = df[economy_col].map(dct).fillna(df[color_col])  # Only Map hits\n",
    "    return df\n",
    "\n",
    "def set_latlon_from_csv(df, csv_path = \"./Data/Coordinates/geo_clst.csv\", \n",
    "                        output=True, sep=\"\\t\", col=\"pop\", col_match=\"clst\"):\n",
    "    \"\"\"Set Color column in df, by loading colors from csv_path\"\"\"\n",
    "    df_geo = pd.read_csv(csv_path, sep=sep)\n",
    "\n",
    "    for index, row in df_geo.iterrows():\n",
    "        lat = row[\"lat\"] \n",
    "        lon = row[\"lon\"]\n",
    "        kw = row[col_match]\n",
    "        df_t = df[df[col].str.contains(kw)]\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"lat\"] = lat\n",
    "        df.loc[idx, \"lon\"] = lon\n",
    "\n",
    "        if output:\n",
    "            print(f\"Doing {kw}...\")\n",
    "            print(f\"Found {np.sum(idx)} Inds - set GPS\")\n",
    "    ### Do old HunterGatherers\n",
    "    return df\n",
    "\n",
    "def set_islands(df, df_isl, col=\"region\", max_d=2, new_val=\"Islands\", output=True):\n",
    "    \"\"\"Set col in dataframe df that are close to df_isl lat lon\n",
    "    to new new_val. Return modified dataframe\n",
    "    max_d: Maximum Distance (in latlon space)\"\"\"\n",
    "    for index, row in df_isl.iterrows():\n",
    "        lat_close = (np.abs(df[\"lat\"] - row[\"lat\"]) < max_d)\n",
    "        lon_close = (np.abs(df[\"lon\"] - row[\"lon\"]) < max_d)\n",
    "        idx = (lat_close & lon_close)\n",
    "        \n",
    "        if output:\n",
    "            region1 = row[\"clst\"]\n",
    "            print(f\"{region1}: {np.sum(idx)}\")\n",
    "        df.loc[idx, col] = new_val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all varying Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Reich Data: 1923\n",
      "Loaded Sardinian Data: 40\n",
      "Loaded modern Data: 1941 Individuals\n",
      "Concatenated 3904 Individual ROH Data!\n",
      "Filtered to 3811 Individuals with include_alt>0\n"
     ]
    }
   ],
   "source": [
    "### Reich Dataframe\n",
    "# Define Individuals we want to delete (Duplicates/Neanderthals)\n",
    "df_r = pd.read_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh_v42.csv\", sep=\"\\t\")\n",
    "df_r['region'] = \"all\"   # Place Holder\n",
    "print(f\"Loaded Reich Data: {len(df_r)}\")\n",
    "cols = df_r.columns # Extract key column names in right order\n",
    "\n",
    "### Sardinians from Marcus et all\n",
    "df_sard = pd.read_csv(\"./Empirical/1240k/MarcusAncs/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_sard = df_sard[df_sard[\"pop\"].str.contains(\"Sar-\")]  #Extract Sardinia Data\n",
    "df_sard[\"region\"]=\"Sardinia\"\n",
    "df_sard = df_sard[cols]\n",
    "print(f\"Loaded Sardinian Data: {len(df_sard)}\")\n",
    "\n",
    "### Human Origin Data\n",
    "df_ho = pd.read_csv(\"./Empirical/HO/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_ho[\"region\"] = df_ho[\"pop\"] # Will be later overwritten for Macro Region!\n",
    "df_ho[\"color\"] = \"gray\"\n",
    "df_ho = df_ho[cols]\n",
    "print(f\"Loaded modern Data: {len(df_ho)} Individuals\")\n",
    "\n",
    "### Concatenate the Dataframes\n",
    "df_all = pd.concat([df_r, df_sard, df_ho])\n",
    "print(f\"Concatenated {len(df_all)} Individual ROH Data!\")\n",
    "\n",
    "### Filter to good individuals\n",
    "df_all =df_all[df_all[\"include_alt\"]>0] \n",
    "print(f\"Filtered to {len(df_all)} Individuals with include_alt>0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Individuals in Deletion List and also Duplicates \n",
    "(based on master ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 12 / 3811 Individuals.\n",
      "Removed 15 / 3799 Individuals.\n",
      "Removed 58 / 3784 Duplicates\n"
     ]
    }
   ],
   "source": [
    "df_all = remove_ids(df_all, csv_path=\"./Data/RegionDefinition/remove_study.csv\", del_col=\"study\")\n",
    "df_all = remove_ids(df_all, csv_path=\"./Data/RegionDefinition/remove_ids.csv\", del_col=\"iid\")\n",
    "df_all = remove_duplicates(df_all, path_master=\"./Data/ReichLabEigenstrat/Raw.v42.4/v42.4.1240K.anno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in Coordinats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing coordinates from outside source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Iberia...\n",
      "Found 244 Individuals; 214 from Geography\n",
      "Doing Balkans...\n",
      "Found 149 Individuals; 149 from Geography\n",
      "Doing Aegan...\n",
      "Found 126 Individuals; 126 from Geography\n",
      "Doing Central Europe...\n",
      "Found 191 Individuals; 184 from Geography\n",
      "Doing Black Sea...\n",
      "Found 32 Individuals; 28 from Geography\n",
      "Doing North Africa...\n",
      "Found 56 Individuals; 55 from Geography\n",
      "Doing Britain...\n",
      "Found 166 Individuals; 162 from Geography\n",
      "Doing Baltic Sea...\n",
      "Found 117 Individuals; 117 from Geography\n",
      "Doing Sardinia...\n",
      "Found 76 Individuals; 76 from Geography\n",
      "Doing Levante...\n",
      "Found 204 Individuals; 203 from Geography\n",
      "Doing Eastern Europe...\n",
      "Found 141 Individuals; 141 from Geography\n",
      "Doing Central Italy...\n",
      "Found 135 Individuals; 135 from Geography\n",
      "Doing Steppe...\n",
      "Found 553 Individuals; 553 from Geography\n",
      "Doing Patagonia...\n",
      "Found 10 Individuals; 10 from Geography\n",
      "Doing Andean...\n",
      "Found 39 Individuals; 39 from Geography\n",
      "Doing Pacific NW...\n",
      "Found 19 Individuals; 19 from Geography\n",
      "Doing Atlantic Coast...\n",
      "Found 22 Individuals; 22 from Geography\n",
      "Doing Vanuatu...\n",
      "Found 17 Individuals; 17 from Geography\n",
      "Doing East Africa...\n",
      "Found 72 Individuals; 72 from Geography\n",
      "Doing South Africa...\n",
      "Found 8 Individuals; 3 from Geography\n",
      "Doing East Steppe...\n",
      "Found 55 Individuals; 55 from Geography\n",
      "Doing Central Asia...\n",
      "Found 390 Individuals; 390 from Geography\n",
      "Doing Bering Sea...\n",
      "Found 19 Individuals; 11 from Geography\n",
      "Doing Himalaya...\n",
      "Found 14 Individuals; 14 from Geography\n",
      "Iceland: 11\n",
      "Greenland: 1\n",
      "Canary: 5\n",
      "Bahamas: 1\n",
      "Bolshoy: 7\n",
      "Aleut: 1\n",
      "Andaman: 1\n",
      "Greece_Minoan_Lassithi: 4\n",
      "Steigen: 1\n"
     ]
    }
   ],
   "source": [
    "df_geo = pd.read_csv(\"./Data/Coordinates/MittnikNatComm2018_Coordinates.csv\", sep=\"\\t\")\n",
    "df_geo.index = df_geo[\"iid\"]\n",
    "df_all.index = df_all[\"iid\"]\n",
    "df_all.update(df_geo)\n",
    "\n",
    "### Merge in group GPS\n",
    "df_all = set_latlon_from_csv(df_all, csv_path = \"./Data/RegionDefinition/geo_clst.csv\", col=\"clst\",\n",
    "                    output=False, sep=\"\\t\")\n",
    "\n",
    "### Merge in individuals GPS\n",
    "df_all = set_latlon_from_csv(df_all, csv_path = \"./Data/RegionDefinition/geo_iid.csv\", \n",
    "                             col=\"iid\", col_match=\"iid\", output=False, sep=\"\\t\")\n",
    "\n",
    "### Set the regions from .csv\n",
    "csv_path = \"./Data/RegionDefinition/regions.csv\"\n",
    "df_t = set_regions_from_csv(df_all, csv_path)\n",
    "\n",
    "### Set the Islands\n",
    "df_isl = pd.read_csv(\"./Data/RegionDefinition/islands_gps.csv\", sep=\"\\t\")\n",
    "df_t = set_islands(df_t, df_isl, col=\"region\", new_val=\"Islands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Economies (Mode of Food Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing 460 Individuals to: Agriculture\n",
      "Changing 5 Individuals to: Pastoralism\n",
      "Changing 23 Individuals to: Foraging\n",
      "Found 1941 Moderns - set to color: gainsboro\n"
     ]
    }
   ],
   "source": [
    "df_t[\"color\"]= \"gray\" # Make Tabula Rasa\n",
    "csv_path = \"./Data/RegionDefinition/colors.csv\"\n",
    "#df_t = set_colors_from_csv(df_t, csv_path)\n",
    "#df_t = set_color_hg_minage(df_t, color=\"purple\")\n",
    "\n",
    "### Set it based on Food Economy\n",
    "df_t = merge_in_economy_iid(df_t, path_economy=\"./Data/RegionDefinition/economy_clst_v3.csv\", match_col='clst')   # Do the Individual Matches (overwriting)\n",
    "df_t = merge_in_economy_iid(df_t, path_economy=\"./Data/RegionDefinition/economy_iid_v3.csv\", match_col='iid')   # Do the Individual Matches (overwriting)\n",
    "df_t = change_economy(df_t, col='economy', str1='Agriculture mixed', new='Agriculture', output=True)\n",
    "df_t = change_economy(df_t, col='economy', str1='Pastoralism mixed', new='Pastoralism', output=True)\n",
    "df_t = change_economy(df_t, col='economy', str1='Foraging mixed', new='Foraging', output=True)\n",
    "df_t = set_economy_color(df_t, path_color_df=\"./Data/RegionDefinition/economy_colors_v3.csv\")\n",
    "df_t = set_color_modern(df_t, color=\"gainsboro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Summary Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3726 Individual ROH to: ./Empirical/roh_all_inds_final_v42.1.csv\n"
     ]
    }
   ],
   "source": [
    "savepath=\"./Empirical/roh_all_inds_final_v42.1.csv\"\n",
    "if len(savepath)>0:\n",
    "    df_t.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "    print(f\"Saved {len(df_all)} Individual ROH to: {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Empirical/roh_all_inds_final_v42.1.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"age\"]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agriculture        1119\n",
       "Pastoralism         345\n",
       "Foraging            240\n",
       "Low Certainty        66\n",
       "Aceramic Farmer      13\n",
       "Not Assigned          1\n",
       "Name: economy, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t[\"economy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pop</th>\n",
       "      <th>max_roh</th>\n",
       "      <th>sum_roh&gt;4</th>\n",
       "      <th>n_roh&gt;4</th>\n",
       "      <th>sum_roh&gt;8</th>\n",
       "      <th>n_roh&gt;8</th>\n",
       "      <th>sum_roh&gt;12</th>\n",
       "      <th>n_roh&gt;12</th>\n",
       "      <th>sum_roh&gt;20</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>age</th>\n",
       "      <th>study</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>n_cov_snp</th>\n",
       "      <th>include_alt</th>\n",
       "      <th>region</th>\n",
       "      <th>color</th>\n",
       "      <th>economy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOO004.A0101</th>\n",
       "      <td>BOO004.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>32.012301</td>\n",
       "      <td>153.249483</td>\n",
       "      <td>15</td>\n",
       "      <td>94.091290</td>\n",
       "      <td>5</td>\n",
       "      <td>74.916696</td>\n",
       "      <td>3</td>\n",
       "      <td>58.141296</td>\n",
       "      <td>...</td>\n",
       "      <td>36.366667</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>2.730692</td>\n",
       "      <td>777001</td>\n",
       "      <td>1</td>\n",
       "      <td>Islands</td>\n",
       "      <td>blue</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO005.A0101</th>\n",
       "      <td>BOO005.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>23.379206</td>\n",
       "      <td>145.998818</td>\n",
       "      <td>14</td>\n",
       "      <td>102.499722</td>\n",
       "      <td>7</td>\n",
       "      <td>73.517417</td>\n",
       "      <td>4</td>\n",
       "      <td>44.828009</td>\n",
       "      <td>...</td>\n",
       "      <td>36.366667</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>2.690273</td>\n",
       "      <td>717504</td>\n",
       "      <td>1</td>\n",
       "      <td>Islands</td>\n",
       "      <td>blue</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO001.A0101</th>\n",
       "      <td>BOO001.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>35.236603</td>\n",
       "      <td>180.272104</td>\n",
       "      <td>17</td>\n",
       "      <td>131.149401</td>\n",
       "      <td>8</td>\n",
       "      <td>102.846979</td>\n",
       "      <td>5</td>\n",
       "      <td>35.236603</td>\n",
       "      <td>...</td>\n",
       "      <td>36.366667</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>1.126532</td>\n",
       "      <td>615153</td>\n",
       "      <td>1</td>\n",
       "      <td>Islands</td>\n",
       "      <td>blue</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO003.A0101</th>\n",
       "      <td>BOO003.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>18.153601</td>\n",
       "      <td>181.349129</td>\n",
       "      <td>23</td>\n",
       "      <td>92.981807</td>\n",
       "      <td>8</td>\n",
       "      <td>43.635599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.366667</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>1.006430</td>\n",
       "      <td>609521</td>\n",
       "      <td>1</td>\n",
       "      <td>Islands</td>\n",
       "      <td>blue</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO006.A0101</th>\n",
       "      <td>BOO006.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>26.702786</td>\n",
       "      <td>113.137105</td>\n",
       "      <td>9</td>\n",
       "      <td>95.024791</td>\n",
       "      <td>5</td>\n",
       "      <td>76.246792</td>\n",
       "      <td>3</td>\n",
       "      <td>76.246792</td>\n",
       "      <td>...</td>\n",
       "      <td>36.366667</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>0.995680</td>\n",
       "      <td>602052</td>\n",
       "      <td>1</td>\n",
       "      <td>Islands</td>\n",
       "      <td>blue</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO002.A0101</th>\n",
       "      <td>BOO002.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>13.262600</td>\n",
       "      <td>116.166475</td>\n",
       "      <td>16</td>\n",
       "      <td>63.287080</td>\n",
       "      <td>6</td>\n",
       "      <td>26.148099</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.366667</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>0.750120</td>\n",
       "      <td>537219</td>\n",
       "      <td>1</td>\n",
       "      <td>Islands</td>\n",
       "      <td>blue</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       iid             pop    max_roh   sum_roh>4  n_roh>4  \\\n",
       "iid                                                                          \n",
       "BOO004.A0101  BOO004.A0101  Russia_Bolshoy  32.012301  153.249483       15   \n",
       "BOO005.A0101  BOO005.A0101  Russia_Bolshoy  23.379206  145.998818       14   \n",
       "BOO001.A0101  BOO001.A0101  Russia_Bolshoy  35.236603  180.272104       17   \n",
       "BOO003.A0101  BOO003.A0101  Russia_Bolshoy  18.153601  181.349129       23   \n",
       "BOO006.A0101  BOO006.A0101  Russia_Bolshoy  26.702786  113.137105        9   \n",
       "BOO002.A0101  BOO002.A0101  Russia_Bolshoy  13.262600  116.166475       16   \n",
       "\n",
       "               sum_roh>8  n_roh>8  sum_roh>12  n_roh>12  sum_roh>20  ...  \\\n",
       "iid                                                                  ...   \n",
       "BOO004.A0101   94.091290        5   74.916696         3   58.141296  ...   \n",
       "BOO005.A0101  102.499722        7   73.517417         4   44.828009  ...   \n",
       "BOO001.A0101  131.149401        8  102.846979         5   35.236603  ...   \n",
       "BOO003.A0101   92.981807        8   43.635599         3    0.000000  ...   \n",
       "BOO006.A0101   95.024791        5   76.246792         3   76.246792  ...   \n",
       "BOO002.A0101   63.287080        6   26.148099         2    0.000000  ...   \n",
       "\n",
       "                    lon     age                             study  \\\n",
       "iid                                                                 \n",
       "BOO004.A0101  36.366667  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO005.A0101  36.366667  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO001.A0101  36.366667  3745.0  LamnidisNatureCommunications2018   \n",
       "BOO003.A0101  36.366667  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO006.A0101  36.366667  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO002.A0101  36.366667  3475.0  LamnidisNatureCommunications2018   \n",
       "\n",
       "                        clst  mean_cov n_cov_snp  include_alt   region  color  \\\n",
       "iid                                                                             \n",
       "BOO004.A0101  Russia_Bolshoy  2.730692    777001            1  Islands   blue   \n",
       "BOO005.A0101  Russia_Bolshoy  2.690273    717504            1  Islands   blue   \n",
       "BOO001.A0101  Russia_Bolshoy  1.126532    615153            1  Islands   blue   \n",
       "BOO003.A0101  Russia_Bolshoy  1.006430    609521            1  Islands   blue   \n",
       "BOO006.A0101  Russia_Bolshoy  0.995680    602052            1  Islands   blue   \n",
       "BOO002.A0101  Russia_Bolshoy  0.750120    537219            1  Islands   blue   \n",
       "\n",
       "                  economy  \n",
       "iid                        \n",
       "BOO004.A0101  Agriculture  \n",
       "BOO005.A0101  Agriculture  \n",
       "BOO001.A0101  Agriculture  \n",
       "BOO003.A0101  Agriculture  \n",
       "BOO006.A0101  Agriculture  \n",
       "BOO002.A0101  Agriculture  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t[df_t[\"clst\"]==\"Russia_Bolshoy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho = pd.read_csv(\"./Empirical/HO/combined_roh05.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[df_ho[\"iid\"].str.contains(\"Ju_hoan_North\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[df_ho[\"pop\"].str.contains(\"Hadza\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

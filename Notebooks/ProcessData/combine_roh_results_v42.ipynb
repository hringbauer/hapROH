{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ROH Results into one big dataframe\n",
    "Contains cleaning lines (i.e. to remove duplicates), fix flipped coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0407.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colorbar as clb\n",
    "import matplotlib.colors as cls\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "### Additional Imports from Support Packages\n",
    "sys.path.append(\"./package/hapsburg/\")\n",
    "from PackagesSupport.pp_individual_roh_csvs import extract_sub_df_geo_kw, give_df_clsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that pre-process Data\n",
    "Add \"region\" Field. Add \"color\" (based on Time) field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Post-Process Regions\n",
    "def set_regions_from_csv(df, csv_path = \"./Data/RegionDefinition/regions.csv\", \n",
    "                         output=True, sep=\",\"):\n",
    "    \"\"\"Set Region column in df, by loading coordinates from csv_path\"\"\"\n",
    "    df_regions= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_regions.iterrows():\n",
    "        region = row[\"Region\"] \n",
    "        if output:\n",
    "            print(f\"Doing {region}...\")\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = extract_sub_df_geo_kw(df, row[\"Lat_low\"], row[\"Lat_high\"], row[\"Lon_low\"], \n",
    "                                     row[\"Lon_high\"], kw, output=output)\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"region\"] = row[\"Region\"] \n",
    "    return df\n",
    "\n",
    "############################################################################\n",
    "### Post-Process Colors\n",
    "def set_colors_from_csv(df, csv_path = \"./Data/RegionDefinition/colors.csv\", \n",
    "                         output=True, sep=\",\"):\n",
    "    \"\"\"Set Color column in df, by loading colors from csv_path\"\"\"\n",
    "    df_colors= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_colors.iterrows():\n",
    "        color = row[\"Color\"] \n",
    "        ig = row[\"InternalGroup\"]\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = give_df_clsts(df, search=kw, col=\"pop\")\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"color\"] = color\n",
    "        df.loc[idx, \"clst\"] = row[\"clst\"]\n",
    "        \n",
    "        if output:\n",
    "            print(f\"Doing {ig}...\")\n",
    "            print(f\"Found {np.sum(idx)} Inds - set to color: {color}\")\n",
    "        \n",
    "    ### Do old HunterGatherers\n",
    "    return df\n",
    "\n",
    "def set_color_hg_minage(df, color=\"blue\", min_age=10500, output=True):\n",
    "    \"\"\"Set the color for all ancient Huntergatherers.\"\"\"\n",
    "    idx = df[\"age\"] > min_age\n",
    "    df.loc[idx, \"color\"] = color\n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Inds >{min_age} BP - set to color: {color}\")\n",
    "    return df\n",
    "    \n",
    "def set_color_modern(df, color=\"white\", output=True):\n",
    "    \"\"\"Set color for all Modern Samples\"\"\"\n",
    "    idx = df[\"age\"] == 0\n",
    "    df.loc[idx, \"color\"] = color\n",
    "    df.loc[idx, \"clst\"] = \"Modern\"\n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Moderns - set to color: {color}\")\n",
    "    return df\n",
    "\n",
    "def remove_ids(df, csv_path = \"./Data/RegionDefinition/remove_ids.csv\", output=True, del_col=\"iid\"):\n",
    "    \"\"\"Remove Individuals whose del_col column contains\n",
    "    string from del_strings (list)\"\"\"\n",
    "    del_list = np.loadtxt(csv_path, dtype=\"str\")\n",
    "    \n",
    "    n=len(df)\n",
    "    for ds in del_list:\n",
    "        df = df[~df[del_col].str.contains(ds)]\n",
    "    if output:\n",
    "        print(f\"Removed {n-len(df)} / {n} Individuals in Deletion List.\")\n",
    "    return df\n",
    "\n",
    "def remove_duplicates(df, cov_col=\"n_cov_snp\", id_col=\"iid\", master_col = \"Master ID\",\n",
    "                      path_master=\"./Data/ReichLabEigenstrat/Raw.v42.4/v42.4.1240K.anno\",\n",
    "                      output=True):\n",
    "    \"\"\"Remove duplicates based on merging with Master Dataframe.\n",
    "    Return Filtered Dataframe\n",
    "    id_col: Column onto which to merge\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    df_meta = pd.read_csv(path_master, sep=\"\\t\")\n",
    "    df_meta[id_col] = df_meta.filter(regex='Instance ID')\n",
    "    \n",
    "    df_meta = df_meta[[id_col, master_col]]  # Only relevant columns\n",
    "    df_merge = pd.merge(df, df_meta, on=id_col, how=\"left\")  # Merge on IID\n",
    "    df_merge = df_merge.sort_values(by=cov_col, ascending=False) # Put IIDs with most SNPs first\n",
    "    ### Fill up NaNs with IDs\n",
    "    idx = df_merge[master_col].isnull()\n",
    "    df_merge.loc[idx, master_col] = df_merge.loc[idx, id_col]\n",
    "    df_merge = df_merge.drop_duplicates(subset=master_col, keep=\"first\")\n",
    "    \n",
    "    df_merge = df_merge.drop(columns=master_col)  #Drop the Master ID Col again\n",
    "\n",
    "    if output:\n",
    "        print(f\"Removed {n- len(df_merge)} / {n} Duplicates\")\n",
    "    return df_merge\n",
    "\n",
    "############################################################################\n",
    "############################################################################\n",
    "\n",
    "def merge_in_economy_iid(df, path_economy=\"\", \n",
    "                         economy_col=\"economy\",\n",
    "                         match_col = \"iid\", \n",
    "                         case=False):\n",
    "    \"\"\"Create/Set Column economy_col into dataframe df. Check for substring matches (to be future proof)\n",
    "    Return modified dataframe.\n",
    "    match_col: What columns to match\n",
    "    economy_col: What column to transfer over\n",
    "    case: Whether IID substring matching is case sensitive\"\"\"\n",
    "    df_match = pd.read_csv(path_economy)  # Load the data\n",
    "    \n",
    "    if not economy_col in df.columns:\n",
    "        df[economy_col] = np.nan\n",
    "    \n",
    "    ### Match all IIDs\n",
    "    for i,m in enumerate(df_match[match_col]):\n",
    "        m = m.rstrip()  # Remove all right whitespaces\n",
    "        idx = df[match_col].str.contains(m, case=case)\n",
    "        df.loc[idx, economy_col] = df_match.loc[i,economy_col]\n",
    "    return df\n",
    "\n",
    "def set_economy_color(df, path_color_df=\"./Data/RegionDefinition/economy_colors.csv\", \n",
    "                      color_col=\"color\", economy_col=\"economy\"):\n",
    "    \"\"\"Set Color Based on Economy.\n",
    "    Assume color column in df exists\"\"\"\n",
    "    df_c = pd.read_csv(path_color_df)\n",
    "    dct = dict(zip(df_c[economy_col], df_c[color_col]))  # Create mapping dictionary\n",
    "    df[color_col] = df[economy_col].map(dct).fillna(df[color_col])  # Only Map hits\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all varying Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Reich Data: 1923\n",
      "Loaded Sardinian Data: 40\n",
      "Loaded modern Data: 1941 Individuals\n",
      "Concatenated 3904 Individual ROH Data!\n",
      "Filtered to 3811 Individuals with include_alt>0\n"
     ]
    }
   ],
   "source": [
    "### Reich Dataframe\n",
    "# Define Individuals we want to delete (Duplicates/Neanderthals)\n",
    "df_r = pd.read_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh_v42.csv\", sep=\"\\t\")\n",
    "df_r['region'] = \"all\"   # Place Holder\n",
    "print(f\"Loaded Reich Data: {len(df_r)}\")\n",
    "cols = df_r.columns # Extract key column names in right order\n",
    "\n",
    "### Sardinians from Marcus et all\n",
    "df_sard = pd.read_csv(\"./Empirical/1240k/MarcusAncs/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_sard = df_sard[df_sard[\"pop\"].str.contains(\"Sar-\")]  #Extract Sardinia Data\n",
    "df_sard[\"region\"]=\"Sardinia\"\n",
    "df_sard = df_sard[cols]\n",
    "print(f\"Loaded Sardinian Data: {len(df_sard)}\")\n",
    "\n",
    "### Human Origin Data\n",
    "df_ho = pd.read_csv(\"./Empirical/HO/CombinedROH/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_ho[\"region\"] = df_ho[\"pop\"] # Will be later overwritten for Macro Region!\n",
    "df_ho[\"color\"] = \"gray\"\n",
    "df_ho = df_ho[cols]\n",
    "print(f\"Loaded modern Data: {len(df_ho)} Individuals\")\n",
    "\n",
    "### Concatenate the Dataframes\n",
    "df_all = pd.concat([df_r, df_sard, df_ho])\n",
    "print(f\"Concatenated {len(df_all)} Individual ROH Data!\")\n",
    "\n",
    "### Filter to good individuals\n",
    "df_all =df_all[df_all[\"include_alt\"]>0] \n",
    "print(f\"Filtered to {len(df_all)} Individuals with include_alt>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = df_all[\"clst\"].str.contains(\"India\")\n",
    "#df_all[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Individuals in Deletion List and also Duplicates \n",
    "(based on master ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 21 / 3811 Individuals in Deletion List.\n",
      "Removed 58 / 3790 Duplicates\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"./Data/RegionDefinition/remove_ids.csv\"\n",
    "df_all = remove_ids(df_all, csv_path)\n",
    "df_all = remove_duplicates(df_all, \n",
    "                           path_master=\"./Data/ReichLabEigenstrat/Raw.v42.4/v42.4.1240K.anno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in Coordinats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing coordinates from outside source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Iberia...\n",
      "Found 230 Individuals; 193 from Geography\n",
      "Doing Balkans...\n",
      "Found 159 Individuals; 111 from Geography\n",
      "Doing Aegan...\n",
      "Found 112 Individuals; 105 from Geography\n",
      "Doing Central Europe...\n",
      "Found 171 Individuals; 171 from Geography\n",
      "Doing Black Sea...\n",
      "Found 45 Individuals; 45 from Geography\n",
      "Doing North Africa...\n",
      "Found 56 Individuals; 55 from Geography\n",
      "Doing Britain...\n",
      "Found 166 Individuals; 162 from Geography\n",
      "Doing Baltic Sea...\n",
      "Found 103 Individuals; 103 from Geography\n",
      "Doing Sardinia...\n",
      "Found 76 Individuals; 76 from Geography\n",
      "Doing Levante...\n",
      "Found 185 Individuals; 184 from Geography\n",
      "Doing Vanuatu...\n",
      "Found 17 Individuals; 17 from Geography\n",
      "Doing Steppe...\n",
      "Found 586 Individuals; 586 from Geography\n",
      "Doing Patagonia...\n",
      "Found 10 Individuals; 10 from Geography\n",
      "Doing Andean...\n",
      "Found 39 Individuals; 39 from Geography\n",
      "Doing Pacific NW...\n",
      "Found 29 Individuals; 29 from Geography\n",
      "Doing Atlantic Coast...\n",
      "Found 21 Individuals; 21 from Geography\n",
      "Doing Rome...\n",
      "Found 135 Individuals; 135 from Geography\n",
      "Doing Vanuatu...\n",
      "Found 16 Individuals; 16 from Geography\n",
      "Doing East Africa...\n",
      "Found 61 Individuals; 61 from Geography\n",
      "Doing South Africa...\n",
      "Found 8 Individuals; 3 from Geography\n",
      "Doing East Steppe...\n",
      "Found 55 Individuals; 42 from Geography\n",
      "Doing Pakistan...\n",
      "Found 276 Individuals; 165 from Geography\n"
     ]
    }
   ],
   "source": [
    "df_geo = pd.read_csv(\"./Data/Coordinates/MittnikNatComm2018_Coordinates.csv\", sep=\"\\t\")\n",
    "df_geo.index = df_geo[\"iid\"]\n",
    "df_all.index = df_all[\"iid\"]\n",
    "df_all.update(df_geo)\n",
    "\n",
    "csv_path = \"./Data/RegionDefinition/regions.csv\"\n",
    "df_t = set_regions_from_csv(df_all, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1934 Moderns - set to color: yellow\n"
     ]
    }
   ],
   "source": [
    "df_t[\"color\"]= \"silver\" # Make Tabula Rasa\n",
    "csv_path = \"./Data/RegionDefinition/colors.csv\"\n",
    "#df_t = set_colors_from_csv(df_t, csv_path)\n",
    "#df_t = set_color_hg_minage(df_t, color=\"purple\")\n",
    "df_t = set_color_modern(df_t, color=\"yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Economies (Mode of Food Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = merge_in_economy_iid(df_t, path_economy=\"./Data/RegionDefinition/economy_clst.csv\", match_col='clst')   # Do the Individual Matches (overwriting)\n",
    "df_t = merge_in_economy_iid(df_t, path_economy=\"./Data/RegionDefinition/economy_iid.csv\", match_col='iid')   # Do the Individual Matches (overwriting)\n",
    "df_t = set_economy_color(df_t, path_color_df=\"./Data/RegionDefinition/economy_colors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yellow        1934\n",
       "blue           809\n",
       "silver         774\n",
       "purple         103\n",
       "gold            76\n",
       "lightblue       12\n",
       "blueviolet      11\n",
       "plum             8\n",
       "darkkhaki        5\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t[\"color\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Summary Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3732 Individual ROH to: ./Empirical/roh_all_inds_final_v42.csv\n"
     ]
    }
   ],
   "source": [
    "savepath=\"./Empirical/roh_all_inds_final_v42.csv\"\n",
    "if len(savepath)>0:\n",
    "    df_t.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "    print(f\"Saved {len(df_all)} Individual ROH to: {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t[df_t[\"clst\"].str.contains(\"Hungary_EBA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"./Data/ReichLabEigenstrat/Raw/meta.v42.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta[df_meta[\"study\"].str.contains(\"Olalde\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all[\"clst\"].str.contains(\"Serbia_EN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ROH Results into one big dataframe\n",
    "Contains cleaning lines (i.e. to remove duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colorbar as clb\n",
    "import matplotlib.colors as cls\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "### Additional Imports from Support Packages\n",
    "sys.path.append(\"./PackagesSupport/\")\n",
    "from pp_individual_roh_csvs import extract_sub_df_geo_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that pre-process Data\n",
    "Add \"region\" Field. Add \"color\" (based on Time) field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_roman_df(df, age_error=0, remove_sard=False):\n",
    "    \"\"\"Preprocess and return roman df and adds colors\"\"\"\n",
    "    color_dict = {\"Medieval/EarlyModern\":\"yellow\", \"Imperial\":\"red\", \"Iron/Republic\":\"magenta\", \n",
    "                  \"LateAntiquity\":\"orange\", \"Copper Age\":\"aquamarine\", \"Neolithic\":\"dodgerblue\", \n",
    "                  \"Mesolithic\":\"purple\", \"(not included in analyses)\":\"gray\"}\n",
    "    df[\"color\"] = df[\"clst\"].map(color_dict)\n",
    "    if age_error>0:\n",
    "        df[\"age\"]+= np.random.random(len(df))*age_error - age_error/2\n",
    "    \n",
    "    df[\"region\"]=\"Rome\" \n",
    "    ### Modify Sardinians\n",
    "    idx_sar = (df[\"clst\"] == \"(not included in analyses)\")\n",
    "    df.loc[idx_sar,\"region\"] = \"Sardinia\"\n",
    "    return df\n",
    "\n",
    "def pre_process_iberia_df(df, age_error=0):\n",
    "    \"\"\"Preprocess and return roman df and adds colors\"\"\"\n",
    "    df[\"color\"]=\"silver\"\n",
    "\n",
    "    ### WHG Coloring\n",
    "    hg_terms = [\"HG\", \"Meso\", \"ElMiron\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(hg_terms))\n",
    "    df.loc[idx, \"color\"]=\"purple\"\n",
    "    df.loc[idx, \"clst\"]=\"Mesolithic\"\n",
    "    \n",
    "    ### EN Coloring\n",
    "    en_terms = [\"Iberia_EN\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms))\n",
    "    df.loc[idx,\"color\"]=\"blue\"\n",
    "    df.loc[idx,\"clst\"]=\"Early Neolithic\"\n",
    "    \n",
    "    ### Middle Late Neoltihic\n",
    "    mn_terms = [\"MN\", \"MLN\", \"MN\", \"LN\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(mn_terms))\n",
    "    df.loc[idx,\"color\"]=\"lightblue\"\n",
    "    df.loc[idx,\"clst\"]=\"Middle/Late Neolithic\"\n",
    "    \n",
    "    ### Muslim Burials\n",
    "    en_terms = [\"SE_Iberia_c.10-16CE\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms))\n",
    "    df.loc[idx,\"color\"]=\"red\"\n",
    "    df.loc[idx,\"clst\"]=\"Muslim Period\"\n",
    "        \n",
    "    if age_error>0:\n",
    "        df[\"age\"]+= np.random.random(len(df)) * age_error - age_error/2      \n",
    "    return df\n",
    "\n",
    "def pre_process_reich_df(df, age_error=0, del_strings=[]):\n",
    "    \"\"\"Preprocess and return roman df and adds colors.\n",
    "    del_strings: iid column in df that contains this list of strings\n",
    "    gets deleted\"\"\"\n",
    "    ### Fix Geography\n",
    "    df.loc[df[\"iid\"]==\"I7554\", \"lon\"] = -3.249  # Flip Wrong Latitude Atlantic\n",
    "    df.loc[df[\"iid\"]==\"Aconcagua.SG\", \"lat\"] = -32.65  # Flip Wrong Latitude (32.64 is in Atlantic)\n",
    "    \n",
    "    ### Delete individuals\n",
    "    for ds in del_strings:\n",
    "        df = df[~df[\"iid\"].str.contains(ds)]\n",
    "    \n",
    "    ### WHG Coloring\n",
    "    hg_terms = [\"HG\", \"Meso\", \"ElMiron\", \"Iron Gates\", \"Loschbour\"]\n",
    "    idx = ((df[\"clst\"].str.contains('|'.join(hg_terms))) | (df[\"age\"]>10500)) & (df[\"age\"]>5000)\n",
    "    df.loc[idx,\"color\"]=\"purple\"\n",
    "    df.loc[idx,\"clst\"]=\"Mesolithic\"\n",
    "    \n",
    "    ### EN Coloring\n",
    "    en_terms = [\"EN\", \"Early Neol\", \"Neolithic\", \"Cardial\", \"MN\", \"LN\", \"MLN\", \"Ukraine_N\", \"Peloponnese_N\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms)) & (df[\"age\"]>5500)\n",
    "    df.loc[idx,\"color\"] = \"aqua\"\n",
    "    df.loc[idx,\"clst\"] = \"Neolithic\"\n",
    "    \n",
    "    ### Antatolia Farmers\n",
    "    en_terms = [\"Anatolia_N\", \"Anatolia Farmers\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms))\n",
    "    df.loc[idx,\"color\"]=\"blue\"\n",
    "    df.loc[idx,\"clst\"]=\"Anatolia Farmers\"\n",
    "    \n",
    "    en_terms = [\"Canaanite\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms))\n",
    "    df.loc[idx,\"color\"]=\"red\"\n",
    "    df.loc[idx,\"clst\"]=\"Canaanite\"\n",
    "    \n",
    "    en_terms = [\"Sar-Nur\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms))\n",
    "    df.loc[idx,\"color\"]=\"red\"\n",
    "    df.loc[idx,\"clst\"]=\"Nuragic\"\n",
    "    \n",
    "    en_terms = [\"skythian\", \"Skythian\"]\n",
    "    idx = df[\"clst\"].str.contains('|'.join(en_terms))\n",
    "    df.loc[idx,\"color\"]=\"orange\"\n",
    "    df.loc[idx,\"clst\"]=\"Skythian\"\n",
    "    \n",
    "    if age_error>0:\n",
    "        df[\"age\"]+= np.random.random(len(df)) * age_error - age_error/2\n",
    "    return df\n",
    "\n",
    "############################################################################\n",
    "### Post-Process Regions\n",
    "def set_regions_from_csv(csv_path, df, output=True, sep=\",\"):\n",
    "    \"\"\"Set Region coumn in df, by loading coordinates from csv_path\"\"\"\n",
    "    df_regions= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_regions.iterrows():\n",
    "        region = row[\"Region\"] \n",
    "        if output:\n",
    "            print(f\"Doing {region}...\")\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = extract_sub_df_geo_kw(df_all, row[\"Lat_low\"], row[\"Lat_high\"], row[\"Lon_low\"], \n",
    "                                     row[\"Lon_high\"], kw, output=output)\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"region\"] = row[\"Region\"] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "Have one Master Dataframe. With Region field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Roman Dataframe\n",
    "df_rome = pd.read_csv(\"./Empirical/1240k/Antonio/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_rome = pre_process_roman_df(df_rome, age_error=0, remove_sard=False)\n",
    "df_rome.drop(columns='age_range', inplace=True)\n",
    "cols = df_rome.columns # Remember the Column Names\n",
    "\n",
    "### Reich Dataframe\n",
    "# Define Individuals we want to delete (Duplicates/Neanderthals)\n",
    "del_strings = [\"Loschbour_snpAD.DG\", \"Mezmaiskaya\", \"Ishim_published.DG\", \"Vindija_snpAD\", \n",
    "               \"Kostenki14.SG\", \"Goyet\", \"Spy\", \"Denisova\", \"Altai\", \"Les_Cottes\", \"Anzick.SG\",\n",
    "               \"Russia_Karelia_HG.SG\", \"I0001\", \"I2966_all\", \"I5259_all\", \"I4450_all\",\n",
    "               \"I4105_all\", \"I4106_all\", \"I3921_all\"]\n",
    "df_r = pd.read_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_r = pre_process_iberia_df(df_r, age_error=0)\n",
    "df_r = pre_process_reich_df(df_r, del_strings=del_strings)\n",
    "df_r['region'] = \"all\"   ### Modify this\n",
    "\n",
    "### Sardinians from Marcus et all\n",
    "df_sard = pd.read_csv(\"./Empirical/1240k/MarcusAncs/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_sard = pre_process_reich_df(df_sard)\n",
    "df_sard[\"region\"]=\"Sardinia\"\n",
    "df_sard = df_sard[cols]\n",
    "\n",
    "### Iberia from Olalde19\n",
    "df_ib = pd.read_csv(\"./Empirical/Eigenstrat/Olalde19/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_ib = pre_process_iberia_df(df_ib, age_error=0)\n",
    "df_ib[\"region\"]=\"Iberia\"\n",
    "df_ib.drop(columns='age_range', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Human Origin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_rome, df_r, df_sard, df_ib])\n",
    "df_all = pre_process_reich_df(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Iberia...\n",
      "Found 159 Individuals; 143 from Geography\n",
      "Doing Balkans...\n",
      "Found 291 Individuals; 167 from Geography\n",
      "Doing Aegan...\n",
      "Found 81 Individuals; 73 from Geography\n",
      "Doing Central Europe...\n",
      "Found 244 Individuals; 244 from Geography\n",
      "Doing Black Sea...\n",
      "Found 49 Individuals; 49 from Geography\n",
      "Doing North Africa...\n",
      "Found 5 Individuals; 4 from Geography\n",
      "Doing Britain...\n",
      "Found 240 Individuals; 223 from Geography\n",
      "Doing Baltic Sea...\n",
      "Found 74 Individuals; 74 from Geography\n",
      "Doing Sardinia...\n",
      "Found 40 Individuals; 40 from Geography\n",
      "Doing Levante...\n",
      "Found 27 Individuals; 26 from Geography\n",
      "Doing Vanuatu...\n",
      "Found 19 Individuals; 19 from Geography\n",
      "Doing Steppe...\n",
      "Found 229 Individuals; 229 from Geography\n",
      "Doing Patagonia...\n",
      "Found 8 Individuals; 8 from Geography\n",
      "Doing Andean...\n",
      "Found 25 Individuals; 25 from Geography\n",
      "Doing Pacific NW...\n",
      "Found 16 Individuals; 16 from Geography\n",
      "Doing Atlantic Coast...\n",
      "Found 15 Individuals; 15 from Geography\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"./Data/RegionDefinition/regions.csv\"\n",
    "df_t = set_regions_from_csv(csv_path, df_all)\n",
    "#df_t = pre_process_iberia_df(df_t, age_error=0)  # Hack for having Iberians right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Summary Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1855 Individual ROH to: ./Empirical/roh_all_inds.csv\n"
     ]
    }
   ],
   "source": [
    "savepath=\"./Empirical/roh_all_inds.csv\"\n",
    "if len(savepath)>0:\n",
    "    df_all.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "    print(f\"Saved {len(df_all)} Individual ROH to: {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region = pd.read_csv(csv_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Lat_low</th>\n",
       "      <th>Lat_high</th>\n",
       "      <th>Lon_low</th>\n",
       "      <th>Lon_high</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iberia</td>\n",
       "      <td>35.95</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Iberia|Portugal|Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Balkans</td>\n",
       "      <td>42.20</td>\n",
       "      <td>46.9</td>\n",
       "      <td>13.05</td>\n",
       "      <td>23.9</td>\n",
       "      <td>Balkans|Serbia|Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aegan</td>\n",
       "      <td>36.30</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>40.4</td>\n",
       "      <td>Anatolia|Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central Europe</td>\n",
       "      <td>45.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>Austria|Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Sea</td>\n",
       "      <td>44.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>39.5</td>\n",
       "      <td>Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>North Africa</td>\n",
       "      <td>26.00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-11.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Britain</td>\n",
       "      <td>49.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Britain|Scot|Wales|England|Orkney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baltic Sea</td>\n",
       "      <td>53.00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Baltic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sardinia</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.3</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Sar-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Levante</td>\n",
       "      <td>30.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Levant|Israel|Canaanite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>155.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Vanuatu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Steppe</td>\n",
       "      <td>40.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Patagonia</td>\n",
       "      <td>-60.00</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-130.00</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Andean</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-130.00</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pacific NW</td>\n",
       "      <td>30.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-130.00</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atlantic Coast</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-63.00</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Region  Lat_low  Lat_high  Lon_low  Lon_high  \\\n",
       "0           Iberia    35.95      44.0   -10.00       4.0   \n",
       "1          Balkans    42.20      46.9    13.05      23.9   \n",
       "2            Aegan    36.30      41.0    18.00      40.4   \n",
       "3   Central Europe    45.00      52.0     5.00      16.9   \n",
       "4        Black Sea    44.00      55.0    25.00      39.5   \n",
       "5     North Africa    26.00      36.0   -11.00      25.0   \n",
       "6          Britain    49.00      60.0   -12.00       3.0   \n",
       "7       Baltic Sea    53.00      67.0     7.00      35.0   \n",
       "8         Sardinia    38.70      41.3     8.00       9.9   \n",
       "9          Levante    30.00      37.0    32.00      38.0   \n",
       "10         Vanuatu   -30.00      -5.0   155.00     180.0   \n",
       "11          Steppe    40.00      61.0    35.00     110.0   \n",
       "12       Patagonia   -60.00     -41.0  -130.00     -30.0   \n",
       "13          Andean   -41.00      10.0  -130.00     -63.0   \n",
       "14      Pacific NW    30.00      55.0  -130.00     -95.0   \n",
       "15  Atlantic Coast   -41.00      10.0   -63.00     -30.0   \n",
       "\n",
       "                             Keywords  \n",
       "0               Iberia|Portugal|Spain  \n",
       "1              Balkans|Serbia|Hungary  \n",
       "2                     Anatolia|Greece  \n",
       "3                 Austria|Switzerland  \n",
       "4                             Ukraine  \n",
       "5                             Morocco  \n",
       "6   Britain|Scot|Wales|England|Orkney  \n",
       "7                              Baltic  \n",
       "8                                Sar-  \n",
       "9             Levant|Israel|Canaanite  \n",
       "10                            Vanuatu  \n",
       "11                                NaN  \n",
       "12                                NaN  \n",
       "13                                NaN  \n",
       "14                                NaN  \n",
       "15                                NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r[df_r.duplicated(subset=[\"lat\", \"lon\", \"age\"], keep=False)].sort_values(by=\"age\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ROH Results into one big dataframe\n",
    "Contains cleaning lines (i.e. to remove duplicates), fix flipped coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0319.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colorbar as clb\n",
    "import matplotlib.colors as cls\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "### Additional Imports from Support Packages\n",
    "sys.path.append(\"./package/hapsburg/\")\n",
    "from PackagesSupport.pp_individual_roh_csvs import extract_sub_df_geo_kw, give_df_clsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that pre-process Data\n",
    "Add \"region\" Field. Add \"color\" (based on Time) field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Post-Process Regions\n",
    "def set_regions_from_csv(df, csv_path = \"./Data/RegionDefinition/regions.csv\", \n",
    "                         output=True, sep=\",\"):\n",
    "    \"\"\"Set Region column in df, by loading coordinates from csv_path\"\"\"\n",
    "    df_regions= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_regions.iterrows():\n",
    "        region = row[\"Region\"] \n",
    "        if output:\n",
    "            print(f\"Doing {region}...\")\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = extract_sub_df_geo_kw(df, row[\"Lat_low\"], row[\"Lat_high\"], row[\"Lon_low\"], \n",
    "                                     row[\"Lon_high\"], kw, output=output)\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"region\"] = row[\"Region\"] \n",
    "    return df\n",
    "\n",
    "############################################################################\n",
    "### Post-Process Colors\n",
    "def set_colors_from_csv(df, csv_path = \"./Data/RegionDefinition/colors.csv\", \n",
    "                         output=True, sep=\",\"):\n",
    "    \"\"\"Set Color column in df, by loading colors from csv_path\"\"\"\n",
    "    df_colors= pd.read_csv(csv_path, sep=sep)\n",
    "    for index, row in df_colors.iterrows():\n",
    "        color = row[\"Color\"] \n",
    "        ig = row[\"InternalGroup\"]\n",
    "        kw = str(row[\"Keywords\"]).split(\"|\") # produce list from Keywords\n",
    "        df_t = give_df_clsts(df, search=kw, col=\"pop\")\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"color\"] = color\n",
    "        df.loc[idx, \"clst\"] = row[\"clst\"]\n",
    "        \n",
    "        if output:\n",
    "            print(f\"Doing {ig}...\")\n",
    "            print(f\"Found {np.sum(idx)} Inds - set to color: {color}\")\n",
    "        \n",
    "    ### Do old HunterGatherers\n",
    "    return df\n",
    "\n",
    "def set_color_hg_minage(df, color=\"blue\", min_age=10500, output=True):\n",
    "    \"\"\"Set the color for all ancient Huntergatherers.\"\"\"\n",
    "    idx = df[\"age\"] > min_age\n",
    "    df.loc[idx, \"color\"] = color\n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Inds >{min_age} BP - set to color: {color}\")\n",
    "    return df\n",
    "    \n",
    "def set_color_modern(df, color=\"white\", output=True):\n",
    "    \"\"\"Set color for all Modern Samples\"\"\"\n",
    "    idx = df[\"age\"] == 0\n",
    "    df.loc[idx, \"color\"] = color\n",
    "    df.loc[idx, \"clst\"] = \"Modern\"\n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Moderns - set to color: {color}\")\n",
    "    return df\n",
    "\n",
    "def remove_ids(df, csv_path = \"./Data/RegionDefinition/remove_ids.csv\", output=True, del_col=\"iid\"):\n",
    "    \"\"\"Remove Individuals whose del_col column contains\n",
    "    string from del_strings (list)\"\"\"\n",
    "    del_list = np.loadtxt(csv_path, dtype=\"str\")\n",
    "    \n",
    "    n=len(df)\n",
    "    for ds in del_list:\n",
    "        df = df[~df[del_col].str.contains(ds)]\n",
    "    if output:\n",
    "        print(f\"Removed {n-len(df)} / {n} Individuals in Deletion List.\")\n",
    "    return df\n",
    "\n",
    "def remove_duplicates(df, cov_col=\"n_cov_snp\", id_col=\"iid\", master_col = \"Master ID\",\n",
    "                      path_master=\"./Data/ReichLabEigenstrat/Raw.v42.4/v42.4.1240K.anno\",\n",
    "                      output=True):\n",
    "    \"\"\"Remove duplicates based on merging with Master Dataframe.\n",
    "    Return Filtered Dataframe\n",
    "    id_col: Column onto which to merge\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    df_meta = pd.read_csv(path_master, sep=\"\\t\")\n",
    "    df_meta[id_col] = df_meta.filter(regex='Instance ID')\n",
    "    \n",
    "    df_meta = df_meta[[id_col, master_col]]  # Only relevant columns\n",
    "    df_merge = pd.merge(df, df_meta, on=id_col, how=\"left\")  # Merge on IID\n",
    "    df_merge = df_merge.sort_values(by=cov_col, ascending=False) # Put IIDs with most SNPs first\n",
    "    ### Fill up NaNs with IDs\n",
    "    idx = df_merge[master_col].isnull()\n",
    "    df_merge.loc[idx, master_col] = df_merge.loc[idx, id_col]\n",
    "    df_merge = df_merge.drop_duplicates(subset=master_col, keep=\"first\")\n",
    "    \n",
    "    df_merge = df_merge.drop(columns=master_col)  #Drop the Master ID Col again\n",
    "\n",
    "    if output:\n",
    "        print(f\"Removed {n- len(df_merge)} / {n} Duplicates\")\n",
    "    return df_merge\n",
    "\n",
    "############################################################################\n",
    "############################################################################\n",
    "\n",
    "def merge_in_economy_iid(df, path_economy=\"\", \n",
    "                         economy_col=\"economy\",\n",
    "                         match_col = \"iid\", \n",
    "                         case=False):\n",
    "    \"\"\"Create/Set Column economy_col into dataframe df. Check for substring matches (to be future proof)\n",
    "    Return modified dataframe.\n",
    "    match_col: What columns to match\n",
    "    economy_col: What column to transfer over\n",
    "    case: Whether IID substring matching is case sensitive\"\"\"\n",
    "    df_match = pd.read_csv(path_economy)  # Load the data\n",
    "    \n",
    "    if not economy_col in df.columns:\n",
    "        df[economy_col] = np.nan\n",
    "    \n",
    "    ### Match all IIDs\n",
    "    for i,m in enumerate(df_match[match_col]):\n",
    "        m = m.rstrip()  # Remove all right whitespaces\n",
    "        idx = df[match_col].str.contains(m, case=case)\n",
    "        df.loc[idx, economy_col] = df_match.loc[i,economy_col]\n",
    "    return df\n",
    "\n",
    "def set_economy_color(df, path_color_df=\"./Data/RegionDefinition/economy_colors.csv\", \n",
    "                      color_col=\"color\", economy_col=\"economy\"):\n",
    "    \"\"\"Set Color Based on Economy.\n",
    "    Assume color column in df exists\"\"\"\n",
    "    df_c = pd.read_csv(path_color_df)\n",
    "    dct = dict(zip(df_c[economy_col], df_c[color_col]))  # Create mapping dictionary\n",
    "    df[color_col] = df[economy_col].map(dct).fillna(df[color_col])  # Only Map hits\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all varying Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Reich Data: 1923\n",
      "Loaded Sardinian Data: 40\n",
      "Loaded modern Data: 1941 Individuals\n",
      "Concatenated 3904 Individual ROH Data!\n",
      "Filtered to 3811 Individuals with include_alt>0\n"
     ]
    }
   ],
   "source": [
    "### Reich Dataframe\n",
    "# Define Individuals we want to delete (Duplicates/Neanderthals)\n",
    "df_r = pd.read_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh_v42.csv\", sep=\"\\t\")\n",
    "df_r['region'] = \"all\"   # Place Holder\n",
    "print(f\"Loaded Reich Data: {len(df_r)}\")\n",
    "cols = df_r.columns # Extract key column names in right order\n",
    "\n",
    "### Sardinians from Marcus et all\n",
    "df_sard = pd.read_csv(\"./Empirical/1240k/MarcusAncs/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_sard = df_sard[df_sard[\"pop\"].str.contains(\"Sar-\")]  #Extract Sardinia Data\n",
    "df_sard[\"region\"]=\"Sardinia\"\n",
    "df_sard = df_sard[cols]\n",
    "print(f\"Loaded Sardinian Data: {len(df_sard)}\")\n",
    "\n",
    "### Human Origin Data\n",
    "df_ho = pd.read_csv(\"./Empirical/HO/combined_roh05.csv\", sep=\"\\t\")\n",
    "df_ho[\"region\"] = df_ho[\"pop\"] # Will be later overwritten for Macro Region!\n",
    "df_ho[\"color\"] = \"gray\"\n",
    "df_ho = df_ho[cols]\n",
    "print(f\"Loaded modern Data: {len(df_ho)} Individuals\")\n",
    "\n",
    "### Concatenate the Dataframes\n",
    "df_all = pd.concat([df_r, df_sard, df_ho])\n",
    "print(f\"Concatenated {len(df_all)} Individual ROH Data!\")\n",
    "\n",
    "### Filter to good individuals\n",
    "df_all =df_all[df_all[\"include_alt\"]>0] \n",
    "print(f\"Filtered to {len(df_all)} Individuals with include_alt>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = df_all[\"clst\"].str.contains(\"India\")\n",
    "#df_all[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Individuals in Deletion List and also Duplicates \n",
    "(based on master ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 21 / 3811 Individuals in Deletion List.\n",
      "Removed 58 / 3790 Duplicates\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"./Data/RegionDefinition/remove_ids.csv\"\n",
    "df_all = remove_ids(df_all, csv_path)\n",
    "df_all = remove_duplicates(df_all, \n",
    "                           path_master=\"./Data/ReichLabEigenstrat/Raw.v42.4/v42.4.1240K.anno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in Coordinats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing coordinates from outside source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Iberia...\n",
      "Found 230 Individuals; 193 from Geography\n",
      "Doing Balkans...\n",
      "Found 159 Individuals; 111 from Geography\n",
      "Doing Aegan...\n",
      "Found 112 Individuals; 105 from Geography\n",
      "Doing Central Europe...\n",
      "Found 171 Individuals; 171 from Geography\n",
      "Doing Black Sea...\n",
      "Found 34 Individuals; 33 from Geography\n",
      "Doing North Africa...\n",
      "Found 56 Individuals; 55 from Geography\n",
      "Doing Britain...\n",
      "Found 166 Individuals; 162 from Geography\n",
      "Doing Baltic Sea...\n",
      "Found 103 Individuals; 103 from Geography\n",
      "Doing Sardinia...\n",
      "Found 76 Individuals; 76 from Geography\n",
      "Doing Levante...\n",
      "Found 185 Individuals; 184 from Geography\n",
      "Doing Steppe...\n",
      "Found 537 Individuals; 537 from Geography\n",
      "Doing Patagonia...\n",
      "Found 10 Individuals; 10 from Geography\n",
      "Doing Andean...\n",
      "Found 39 Individuals; 39 from Geography\n",
      "Doing Pacific NW...\n",
      "Found 29 Individuals; 29 from Geography\n",
      "Doing Atlantic Coast...\n",
      "Found 21 Individuals; 21 from Geography\n",
      "Doing Rome...\n",
      "Found 135 Individuals; 135 from Geography\n",
      "Doing Vanuatu...\n",
      "Found 16 Individuals; 16 from Geography\n",
      "Doing East Africa...\n",
      "Found 71 Individuals; 71 from Geography\n",
      "Doing South Africa...\n",
      "Found 8 Individuals; 3 from Geography\n",
      "Doing East Steppe...\n",
      "Found 55 Individuals; 55 from Geography\n",
      "Doing Central Asia...\n",
      "Found 383 Individuals; 383 from Geography\n"
     ]
    }
   ],
   "source": [
    "df_geo = pd.read_csv(\"./Data/Coordinates/MittnikNatComm2018_Coordinates.csv\", sep=\"\\t\")\n",
    "df_geo.index = df_geo[\"iid\"]\n",
    "df_all.index = df_all[\"iid\"]\n",
    "df_all.update(df_geo)\n",
    "\n",
    "### Set the regions from .csv\n",
    "csv_path = \"./Data/RegionDefinition/regions.csv\"\n",
    "df_t = set_regions_from_csv(df_all, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Economies (Mode of Food Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1934 Moderns - set to color: yellow\n"
     ]
    }
   ],
   "source": [
    "df_t[\"color\"]= \"silver\" # Make Tabula Rasa\n",
    "csv_path = \"./Data/RegionDefinition/colors.csv\"\n",
    "#df_t = set_colors_from_csv(df_t, csv_path)\n",
    "#df_t = set_color_hg_minage(df_t, color=\"purple\")\n",
    "df_t = set_color_modern(df_t, color=\"yellow\")\n",
    "\n",
    "### Set it based on Food Economy\n",
    "df_t = merge_in_economy_iid(df_t, path_economy=\"./Data/RegionDefinition/economy_clst.csv\", match_col='clst')   # Do the Individual Matches (overwriting)\n",
    "df_t = merge_in_economy_iid(df_t, path_economy=\"./Data/RegionDefinition/economy_iid.csv\", match_col='iid')   # Do the Individual Matches (overwriting)\n",
    "df_t = set_economy_color(df_t, path_color_df=\"./Data/RegionDefinition/economy_colors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Summary Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3732 Individual ROH to: ./Empirical/roh_all_inds_final_v42.csv\n"
     ]
    }
   ],
   "source": [
    "savepath=\"./Empirical/roh_all_inds_final_v42.csv\"\n",
    "if len(savepath)>0:\n",
    "    df_t.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "    print(f\"Saved {len(df_all)} Individual ROH to: {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_latlon_from_csv(df, csv_path = \"./Data/Coordinates/geo_clst.csv\", \n",
    "                        output=True, sep=\"\\t\", col=\"pop\"):\n",
    "    \"\"\"Set Color column in df, by loading colors from csv_path\"\"\"\n",
    "    df_geo = pd.read_csv(csv_path, sep=sep)\n",
    "\n",
    "    for index, row in df_geo.iterrows():\n",
    "        lat = row[\"lat\"] \n",
    "        lon = row[\"lon\"]\n",
    "        kw = row[\"clst\"]\n",
    "        df_t = df[df[col].str.contains(kw)]\n",
    "        print(kw)\n",
    "        print(len(df_t))\n",
    "        idx = df[\"iid\"].isin(df_t[\"iid\"]) # Get Indices of Sub Dataframe\n",
    "        df.loc[idx, \"lat\"] = lat\n",
    "        df.loc[idx, \"lon\"] = lon\n",
    "\n",
    "        if output:\n",
    "            print(f\"Doing {kw}...\")\n",
    "            print(f\"Found {np.sum(idx)} Inds - set GPS\")\n",
    "    ### Do old HunterGatherers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pop</th>\n",
       "      <th>max_roh</th>\n",
       "      <th>sum_roh&gt;4</th>\n",
       "      <th>n_roh&gt;4</th>\n",
       "      <th>sum_roh&gt;8</th>\n",
       "      <th>n_roh&gt;8</th>\n",
       "      <th>sum_roh&gt;12</th>\n",
       "      <th>n_roh&gt;12</th>\n",
       "      <th>sum_roh&gt;20</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>age</th>\n",
       "      <th>study</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>n_cov_snp</th>\n",
       "      <th>include_alt</th>\n",
       "      <th>region</th>\n",
       "      <th>color</th>\n",
       "      <th>economy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1.SG</th>\n",
       "      <td>C1.SG</td>\n",
       "      <td>Nepal_Chokhopani_2700BP.SG</td>\n",
       "      <td>13.058001</td>\n",
       "      <td>61.822600</td>\n",
       "      <td>7</td>\n",
       "      <td>45.668692</td>\n",
       "      <td>4</td>\n",
       "      <td>26.106102</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>JeongPNAS2016</td>\n",
       "      <td>Nepal_Chokhopani_2700BP.SG</td>\n",
       "      <td>7.182</td>\n",
       "      <td>1178495</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S35.SG</th>\n",
       "      <td>S35.SG</td>\n",
       "      <td>Nepal_Samzdong_1500BP.SG</td>\n",
       "      <td>17.873500</td>\n",
       "      <td>55.456002</td>\n",
       "      <td>7</td>\n",
       "      <td>17.873500</td>\n",
       "      <td>1</td>\n",
       "      <td>17.873500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>JeongPNAS2016</td>\n",
       "      <td>Nepal_Samzdong_1500BP.SG</td>\n",
       "      <td>3.720</td>\n",
       "      <td>1135160</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S10.SG</th>\n",
       "      <td>S10.SG</td>\n",
       "      <td>Nepal_Samdzong_1500BP.SG</td>\n",
       "      <td>19.573301</td>\n",
       "      <td>57.669193</td>\n",
       "      <td>6</td>\n",
       "      <td>33.694798</td>\n",
       "      <td>2</td>\n",
       "      <td>33.694798</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>JeongPNAS2016</td>\n",
       "      <td>Nepal_Samdzong_1500BP.SG</td>\n",
       "      <td>3.263</td>\n",
       "      <td>1124932</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M63.SG</th>\n",
       "      <td>M63.SG</td>\n",
       "      <td>Nepal_Mebrak_2125BP.SG</td>\n",
       "      <td>22.859901</td>\n",
       "      <td>43.045801</td>\n",
       "      <td>4</td>\n",
       "      <td>33.257801</td>\n",
       "      <td>2</td>\n",
       "      <td>22.859901</td>\n",
       "      <td>1</td>\n",
       "      <td>22.859901</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>JeongPNAS2016</td>\n",
       "      <td>Nepal_Mebrak_2125BP.SG</td>\n",
       "      <td>1.024</td>\n",
       "      <td>750057</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           iid                         pop    max_roh  sum_roh>4  n_roh>4  \\\n",
       "iid                                                                         \n",
       "C1.SG    C1.SG  Nepal_Chokhopani_2700BP.SG  13.058001  61.822600        7   \n",
       "S35.SG  S35.SG    Nepal_Samzdong_1500BP.SG  17.873500  55.456002        7   \n",
       "S10.SG  S10.SG    Nepal_Samdzong_1500BP.SG  19.573301  57.669193        6   \n",
       "M63.SG  M63.SG      Nepal_Mebrak_2125BP.SG  22.859901  43.045801        4   \n",
       "\n",
       "        sum_roh>8  n_roh>8  sum_roh>12  n_roh>12  sum_roh>20  ...        lon  \\\n",
       "iid                                                           ...              \n",
       "C1.SG   45.668692        4   26.106102         2    0.000000  ...  83.982202   \n",
       "S35.SG  17.873500        1   17.873500         1    0.000000  ...  83.982202   \n",
       "S10.SG  33.694798        2   33.694798         2    0.000000  ...  83.982202   \n",
       "M63.SG  33.257801        2   22.859901         1   22.859901  ...  83.982202   \n",
       "\n",
       "           age          study                        clst mean_cov n_cov_snp  \\\n",
       "iid                                                                            \n",
       "C1.SG   2775.0  JeongPNAS2016  Nepal_Chokhopani_2700BP.SG    7.182   1178495   \n",
       "S35.SG  1500.0  JeongPNAS2016    Nepal_Samzdong_1500BP.SG    3.720   1135160   \n",
       "S10.SG  1500.0  JeongPNAS2016    Nepal_Samdzong_1500BP.SG    3.263   1124932   \n",
       "M63.SG  2125.0  JeongPNAS2016      Nepal_Mebrak_2125BP.SG    1.024    750057   \n",
       "\n",
       "        include_alt  region   color economy  \n",
       "iid                                          \n",
       "C1.SG             1     all  silver     NaN  \n",
       "S35.SG            1     all  silver     NaN  \n",
       "S10.SG            1     all  silver     NaN  \n",
       "M63.SG            1     all  silver     NaN  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_df_clsts(df_t, search=[\"Nepal\"], col=\"clst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russia_Bolshoy\n",
      "6\n",
      "Doing Russia_Bolshoy...\n",
      "Found 6 Inds - set GPS\n",
      "Iceland_Pre_Christian\n",
      "11\n",
      "Doing Iceland_Pre_Christian...\n",
      "Found 11 Inds - set GPS\n",
      "Russia_Srubnaya_Alakul\n",
      "8\n",
      "Doing Russia_Srubnaya_Alakul...\n",
      "Found 8 Inds - set GPS\n",
      "Nepal_Chokhopani\n",
      "1\n",
      "Doing Nepal_Chokhopani...\n",
      "Found 1 Inds - set GPS\n",
      "Nepal_Samzdong\n",
      "1\n",
      "Doing Nepal_Samzdong...\n",
      "Found 1 Inds - set GPS\n",
      "Nepal_Mebrak\n",
      "1\n",
      "Doing Nepal_Mebrak...\n",
      "Found 1 Inds - set GPS\n"
     ]
    }
   ],
   "source": [
    "df_tt = set_latlon_from_csv(df_t, csv_path = \"./Data/Coordinates/geo_clst.csv\", col=\"clst\",\n",
    "                    output=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pop</th>\n",
       "      <th>max_roh</th>\n",
       "      <th>sum_roh&gt;4</th>\n",
       "      <th>n_roh&gt;4</th>\n",
       "      <th>sum_roh&gt;8</th>\n",
       "      <th>n_roh&gt;8</th>\n",
       "      <th>sum_roh&gt;12</th>\n",
       "      <th>n_roh&gt;12</th>\n",
       "      <th>sum_roh&gt;20</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>age</th>\n",
       "      <th>study</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>n_cov_snp</th>\n",
       "      <th>include_alt</th>\n",
       "      <th>region</th>\n",
       "      <th>color</th>\n",
       "      <th>economy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOO004.A0101</th>\n",
       "      <td>BOO004.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>32.012301</td>\n",
       "      <td>153.249483</td>\n",
       "      <td>15</td>\n",
       "      <td>94.091290</td>\n",
       "      <td>5</td>\n",
       "      <td>74.916696</td>\n",
       "      <td>3</td>\n",
       "      <td>58.141296</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>2.730692</td>\n",
       "      <td>777001</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO005.A0101</th>\n",
       "      <td>BOO005.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>23.379206</td>\n",
       "      <td>145.998818</td>\n",
       "      <td>14</td>\n",
       "      <td>102.499722</td>\n",
       "      <td>7</td>\n",
       "      <td>73.517417</td>\n",
       "      <td>4</td>\n",
       "      <td>44.828009</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>2.690273</td>\n",
       "      <td>717504</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO001.A0101</th>\n",
       "      <td>BOO001.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>35.236603</td>\n",
       "      <td>180.272104</td>\n",
       "      <td>17</td>\n",
       "      <td>131.149401</td>\n",
       "      <td>8</td>\n",
       "      <td>102.846979</td>\n",
       "      <td>5</td>\n",
       "      <td>35.236603</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>1.126532</td>\n",
       "      <td>615153</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO003.A0101</th>\n",
       "      <td>BOO003.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>18.153601</td>\n",
       "      <td>181.349129</td>\n",
       "      <td>23</td>\n",
       "      <td>92.981807</td>\n",
       "      <td>8</td>\n",
       "      <td>43.635599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>1.006430</td>\n",
       "      <td>609521</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO006.A0101</th>\n",
       "      <td>BOO006.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>26.702786</td>\n",
       "      <td>113.137105</td>\n",
       "      <td>9</td>\n",
       "      <td>95.024791</td>\n",
       "      <td>5</td>\n",
       "      <td>76.246792</td>\n",
       "      <td>3</td>\n",
       "      <td>76.246792</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>0.995680</td>\n",
       "      <td>602052</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOO002.A0101</th>\n",
       "      <td>BOO002.A0101</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>13.262600</td>\n",
       "      <td>116.166475</td>\n",
       "      <td>16</td>\n",
       "      <td>63.287080</td>\n",
       "      <td>6</td>\n",
       "      <td>26.148099</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.982202</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>LamnidisNatureCommunications2018</td>\n",
       "      <td>Russia_Bolshoy</td>\n",
       "      <td>0.750120</td>\n",
       "      <td>537219</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>silver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       iid             pop    max_roh   sum_roh>4  n_roh>4  \\\n",
       "iid                                                                          \n",
       "BOO004.A0101  BOO004.A0101  Russia_Bolshoy  32.012301  153.249483       15   \n",
       "BOO005.A0101  BOO005.A0101  Russia_Bolshoy  23.379206  145.998818       14   \n",
       "BOO001.A0101  BOO001.A0101  Russia_Bolshoy  35.236603  180.272104       17   \n",
       "BOO003.A0101  BOO003.A0101  Russia_Bolshoy  18.153601  181.349129       23   \n",
       "BOO006.A0101  BOO006.A0101  Russia_Bolshoy  26.702786  113.137105        9   \n",
       "BOO002.A0101  BOO002.A0101  Russia_Bolshoy  13.262600  116.166475       16   \n",
       "\n",
       "               sum_roh>8  n_roh>8  sum_roh>12  n_roh>12  sum_roh>20  ...  \\\n",
       "iid                                                                  ...   \n",
       "BOO004.A0101   94.091290        5   74.916696         3   58.141296  ...   \n",
       "BOO005.A0101  102.499722        7   73.517417         4   44.828009  ...   \n",
       "BOO001.A0101  131.149401        8  102.846979         5   35.236603  ...   \n",
       "BOO003.A0101   92.981807        8   43.635599         3    0.000000  ...   \n",
       "BOO006.A0101   95.024791        5   76.246792         3   76.246792  ...   \n",
       "BOO002.A0101   63.287080        6   26.148099         2    0.000000  ...   \n",
       "\n",
       "                    lon     age                             study  \\\n",
       "iid                                                                 \n",
       "BOO004.A0101  83.982202  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO005.A0101  83.982202  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO001.A0101  83.982202  3745.0  LamnidisNatureCommunications2018   \n",
       "BOO003.A0101  83.982202  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO006.A0101  83.982202  3475.0  LamnidisNatureCommunications2018   \n",
       "BOO002.A0101  83.982202  3475.0  LamnidisNatureCommunications2018   \n",
       "\n",
       "                        clst  mean_cov n_cov_snp  include_alt  region   color  \\\n",
       "iid                                                                             \n",
       "BOO004.A0101  Russia_Bolshoy  2.730692    777001            1     all  silver   \n",
       "BOO005.A0101  Russia_Bolshoy  2.690273    717504            1     all  silver   \n",
       "BOO001.A0101  Russia_Bolshoy  1.126532    615153            1     all  silver   \n",
       "BOO003.A0101  Russia_Bolshoy  1.006430    609521            1     all  silver   \n",
       "BOO006.A0101  Russia_Bolshoy  0.995680    602052            1     all  silver   \n",
       "BOO002.A0101  Russia_Bolshoy  0.750120    537219            1     all  silver   \n",
       "\n",
       "             economy  \n",
       "iid                   \n",
       "BOO004.A0101     NaN  \n",
       "BOO005.A0101     NaN  \n",
       "BOO001.A0101     NaN  \n",
       "BOO003.A0101     NaN  \n",
       "BOO006.A0101     NaN  \n",
       "BOO002.A0101     NaN  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tt[df_tt[\"clst\"]==\"Russia_Bolshoy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho = pd.read_csv(\"./Empirical/HO/combined_roh05.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pop</th>\n",
       "      <th>max_roh</th>\n",
       "      <th>sum_roh&gt;4</th>\n",
       "      <th>n_roh&gt;4</th>\n",
       "      <th>sum_roh&gt;8</th>\n",
       "      <th>n_roh&gt;8</th>\n",
       "      <th>sum_roh&gt;12</th>\n",
       "      <th>n_roh&gt;12</th>\n",
       "      <th>sum_roh&gt;20</th>\n",
       "      <th>...</th>\n",
       "      <th>study</th>\n",
       "      <th>clst_alt</th>\n",
       "      <th>period_alt</th>\n",
       "      <th>include_alt</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>med_cov</th>\n",
       "      <th>n_cov_snp_read</th>\n",
       "      <th>full_iid</th>\n",
       "      <th>n_cov_snp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Ju_hoan_North_4</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>13.635399</td>\n",
       "      <td>55.448484</td>\n",
       "      <td>8</td>\n",
       "      <td>24.811300</td>\n",
       "      <td>2</td>\n",
       "      <td>13.635399</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HGDP01036</td>\n",
       "      <td>551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Ju_hoan_North_1</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>14.452398</td>\n",
       "      <td>45.814887</td>\n",
       "      <td>5</td>\n",
       "      <td>27.202696</td>\n",
       "      <td>2</td>\n",
       "      <td>27.202696</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HGDP00991</td>\n",
       "      <td>552765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Ju_hoan_North_2</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>17.709100</td>\n",
       "      <td>41.982499</td>\n",
       "      <td>5</td>\n",
       "      <td>17.709100</td>\n",
       "      <td>1</td>\n",
       "      <td>17.709100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HGDP00992</td>\n",
       "      <td>552658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Ju_hoan_North_0</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>18.166298</td>\n",
       "      <td>27.997798</td>\n",
       "      <td>3</td>\n",
       "      <td>18.166298</td>\n",
       "      <td>1</td>\n",
       "      <td>18.166298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HGDP00987</td>\n",
       "      <td>552123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Ju_hoan_North_3</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>9.546202</td>\n",
       "      <td>13.647597</td>\n",
       "      <td>2</td>\n",
       "      <td>9.546202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ju_hoan_North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HGDP01032</td>\n",
       "      <td>551614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 iid            pop    max_roh  sum_roh>4  n_roh>4  sum_roh>8  \\\n",
       "407  Ju_hoan_North_4  Ju_hoan_North  13.635399  55.448484        8  24.811300   \n",
       "477  Ju_hoan_North_1  Ju_hoan_North  14.452398  45.814887        5  27.202696   \n",
       "500  Ju_hoan_North_2  Ju_hoan_North  17.709100  41.982499        5  17.709100   \n",
       "622  Ju_hoan_North_0  Ju_hoan_North  18.166298  27.997798        3  18.166298   \n",
       "820  Ju_hoan_North_3  Ju_hoan_North   9.546202  13.647597        2   9.546202   \n",
       "\n",
       "     n_roh>8  sum_roh>12  n_roh>12  sum_roh>20    ...      \\\n",
       "407        2   13.635399         1         0.0    ...       \n",
       "477        2   27.202696         2         0.0    ...       \n",
       "500        1   17.709100         1         0.0    ...       \n",
       "622        1   18.166298         1         0.0    ...       \n",
       "820        1    0.000000         0         0.0    ...       \n",
       "\n",
       "                     study       clst_alt  period_alt  include_alt  \\\n",
       "407  Lazaridis et al. 2014  Ju_hoan_North         NaN            1   \n",
       "477  Lazaridis et al. 2014  Ju_hoan_North         NaN            1   \n",
       "500  Lazaridis et al. 2014  Ju_hoan_North         NaN            1   \n",
       "622  Lazaridis et al. 2014  Ju_hoan_North         NaN            1   \n",
       "820  Lazaridis et al. 2014  Ju_hoan_North         NaN            1   \n",
       "\n",
       "              clst  mean_cov  med_cov n_cov_snp_read   full_iid  n_cov_snp  \n",
       "407  Ju_hoan_North       NaN      NaN            NaN  HGDP01036     551020  \n",
       "477  Ju_hoan_North       NaN      NaN            NaN  HGDP00991     552765  \n",
       "500  Ju_hoan_North       NaN      NaN            NaN  HGDP00992     552658  \n",
       "622  Ju_hoan_North       NaN      NaN            NaN  HGDP00987     552123  \n",
       "820  Ju_hoan_North       NaN      NaN            NaN  HGDP01032     551614  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ho[df_ho[\"iid\"].str.contains(\"Ju_hoan_North\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pop</th>\n",
       "      <th>max_roh</th>\n",
       "      <th>sum_roh&gt;4</th>\n",
       "      <th>n_roh&gt;4</th>\n",
       "      <th>sum_roh&gt;8</th>\n",
       "      <th>n_roh&gt;8</th>\n",
       "      <th>sum_roh&gt;12</th>\n",
       "      <th>n_roh&gt;12</th>\n",
       "      <th>sum_roh&gt;20</th>\n",
       "      <th>...</th>\n",
       "      <th>study</th>\n",
       "      <th>clst_alt</th>\n",
       "      <th>period_alt</th>\n",
       "      <th>include_alt</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>med_cov</th>\n",
       "      <th>n_cov_snp_read</th>\n",
       "      <th>full_iid</th>\n",
       "      <th>n_cov_snp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Hadza_3</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>16.240204</td>\n",
       "      <td>264.950700</td>\n",
       "      <td>31</td>\n",
       "      <td>187.566915</td>\n",
       "      <td>17</td>\n",
       "      <td>68.000203</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>End08</td>\n",
       "      <td>549841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Hadza_2</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>18.397104</td>\n",
       "      <td>120.681022</td>\n",
       "      <td>18</td>\n",
       "      <td>38.452709</td>\n",
       "      <td>3</td>\n",
       "      <td>18.397104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bar13</td>\n",
       "      <td>540831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Hadza_4</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>12.667095</td>\n",
       "      <td>66.326388</td>\n",
       "      <td>10</td>\n",
       "      <td>29.600291</td>\n",
       "      <td>3</td>\n",
       "      <td>12.667095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bar04</td>\n",
       "      <td>545031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Hadza_0</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>8.227205</td>\n",
       "      <td>17.779204</td>\n",
       "      <td>3</td>\n",
       "      <td>8.227205</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bar08</td>\n",
       "      <td>543902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Hadza_1</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>5.499005</td>\n",
       "      <td>14.886808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lazaridis et al. 2014</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Hadza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bar10</td>\n",
       "      <td>543967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         iid    pop    max_roh   sum_roh>4  n_roh>4   sum_roh>8  n_roh>8  \\\n",
       "64   Hadza_3  Hadza  16.240204  264.950700       31  187.566915       17   \n",
       "203  Hadza_2  Hadza  18.397104  120.681022       18   38.452709        3   \n",
       "355  Hadza_4  Hadza  12.667095   66.326388       10   29.600291        3   \n",
       "743  Hadza_0  Hadza   8.227205   17.779204        3    8.227205        1   \n",
       "802  Hadza_1  Hadza   5.499005   14.886808        3    0.000000        0   \n",
       "\n",
       "     sum_roh>12  n_roh>12  sum_roh>20    ...                      study  \\\n",
       "64    68.000203         5         0.0    ...      Lazaridis et al. 2014   \n",
       "203   18.397104         1         0.0    ...      Lazaridis et al. 2014   \n",
       "355   12.667095         1         0.0    ...      Lazaridis et al. 2014   \n",
       "743    0.000000         0         0.0    ...      Lazaridis et al. 2014   \n",
       "802    0.000000         0         0.0    ...      Lazaridis et al. 2014   \n",
       "\n",
       "    clst_alt  period_alt  include_alt   clst  mean_cov  med_cov  \\\n",
       "64     Hadza         NaN            1  Hadza       NaN      NaN   \n",
       "203    Hadza         NaN            1  Hadza       NaN      NaN   \n",
       "355    Hadza         NaN            1  Hadza       NaN      NaN   \n",
       "743    Hadza         NaN            1  Hadza       NaN      NaN   \n",
       "802    Hadza         NaN            1  Hadza       NaN      NaN   \n",
       "\n",
       "    n_cov_snp_read full_iid  n_cov_snp  \n",
       "64             NaN    End08     549841  \n",
       "203            NaN    Bar13     540831  \n",
       "355            NaN    Bar04     545031  \n",
       "743            NaN    Bar08     543902  \n",
       "802            NaN    Bar10     543967  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ho[df_ho[\"pop\"].str.contains(\"Hadza\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hadza, Khomani, Ju_Huan_North"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Individual ROH csv files into Summary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0403.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import matplotlib.colors as cls\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "sys.path.append(\"./PackagesSupport/\")\n",
    "from pp_individual_roh_csvs import create_combined_ROH_df, give_iid_paths, pp_individual_roh\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenstrat ROH Results postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load IIDs\n",
    "### Load Metafile from D. Reich:\n",
    "def load_eigenstrat_anno(path=\"./Data/ReichLabEigenstrat/Raw/v37.2.1240K.clean4.anno\", anc_only=True):\n",
    "    \"\"\"Load annotated Eigenstrat (from D. Reich's group)\"\"\"\n",
    "    df_anno = pd.read_csv(path, sep=\"\\t\", engine=\"python\")\n",
    "    coverage = pd.to_numeric(df_anno[\"Coverage\"], errors='coerce')\n",
    "    df_anno[\"coverage\"]=coverage\n",
    "\n",
    "    # Convert the Ages as well\n",
    "    ages = df_anno[\"Average of 95.4% date range in calBP (defined as 1950 CE)  \"]\n",
    "    df_anno[\"ages\"] = pd.to_numeric(ages, errors='coerce')  #\n",
    "\n",
    "    ### Convert Longitude and Latitude\n",
    "    lat = df_anno[\"Lat.\"]\n",
    "    lon = df_anno[\"Long.\"]\n",
    "    df_anno[\"lat\"] = pd.to_numeric(lat, errors='coerce')\n",
    "    df_anno[\"lon\"] = pd.to_numeric(lon, errors='coerce')\n",
    "    df_anno[\"iid\"] = df_anno[\"Instance ID\"]\n",
    "    \n",
    "    df_anc = df_anno[df_anno[\"ages\"]>0]\n",
    "\n",
    "    print(f\"Loaded {len(df_anc)} / {len(df_anno)} ancient Indivdiuals.\")\n",
    "    print(f\"Without Coverage: {np.sum(np.isnan(coverage))}\")\n",
    "    if anc_only:\n",
    "        df_anno=df_anc\n",
    "    return df_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2106 / 5081 ancient Indivdiuals.\n",
      "Without Coverage: 2581\n",
      "1099\n"
     ]
    }
   ],
   "source": [
    "df_anno = load_eigenstrat_anno()\n",
    "df_ana = df_anno[df_anno[\"coverage\"]>0.5]\n",
    "print(len(df_ana))\n",
    "df_ana = df_ana[:10]  # how many individuals to extract\n",
    "\n",
    "### Create Paths\n",
    "paths = give_iid_paths(df_ana[\"iid\"], base_folder=\"./Empirical/Eigenstrat/Reichall/\", suffix='_roh_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Paths for rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if the Paths are actually there (stand alone!)\n",
    "def create_rerun_csv(meta_path, base_folder, suffix=\"_roh_full.csv\", save_path=\"\", min_cov=0.5):\n",
    "    \"\"\"Ceck for Paths that have not been created (from meta in meta_path, files in base_folder with suffix)\n",
    "    and save \"\"\"\n",
    "    df_anno = pd.read_csv(meta_path)\n",
    "    df_ana = df_anno[df_anno[\"mean_cov\"]>0.5]\n",
    "\n",
    "    ### Create Paths\n",
    "    paths = give_iid_paths(df_ana[\"iid\"], base_folder=base_folder, suffix=suffix)\n",
    "\n",
    "    not_there = []\n",
    "    idcs = []\n",
    "\n",
    "    for i, p in enumerate(paths):\n",
    "        if not os.path.exists(p):\n",
    "            not_there.append(p)\n",
    "            idcs.append(i)\n",
    "\n",
    "    print(f\"Did not find {len(not_there)} / {len(paths)} paths\")\n",
    "    \n",
    "    df_rerun = pd.DataFrame({\"iid\":df_ana[\"iid\"].values[idcs], \"coverage\":2.00})\n",
    "    if len(save_path)>0:\n",
    "        df_rerun.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {len(df_rerun)} rerun iids to {save_path}!\")\n",
    "    return df_rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find 0 / 1099 paths\n"
     ]
    }
   ],
   "source": [
    "df_rerun = create_rerun_csv(meta_path=\"./Data/ReichLabEigenstrat/Raw/meta.csv\", base_folder=\"./Empirical/Eigenstrat/Reichall/\", \n",
    "                 save_path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IPY10.SG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        iid  coverage\n",
       "0  IPY10.SG       2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find 235 / 1099 paths\n",
      "Saved 235 rerun iids to ./PackagesSupport/cluster_runs/ES_callROH/rerun.csv!\n"
     ]
    }
   ],
   "source": [
    "df_rerun = create_rerun_csv(meta_path=\"./Data/ReichLabEigenstrat/Raw/meta.csv\", base_folder=\"./Empirical/Eigenstrat/Reichall/\", \n",
    "                 save_path=\"./PackagesSupport/cluster_runs/ES_callROH/rerun.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load to test whether everything has been loaded\n",
    "df_test = pd.read_csv(\"./PackagesSupport/cluster_runs/ES_callROH/rerun.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Metafile for the top 100 IIDs to rerun \n",
    "Idea: Save these Posteriors for more detailed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1098 Individuals\n",
      "Saved 100 rerun iids to ./PackagesSupport/cluster_runs/ES_callROH/rerun_top100.csv!\n"
     ]
    }
   ],
   "source": [
    "save_path=\"./PackagesSupport/cluster_runs/ES_callROH/rerun_top100.csv\"\n",
    "\n",
    "df1 = pd.read_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh.csv\", '\\t')\n",
    "print(f\"Loaded {len(df1)} Individuals\")\n",
    "\n",
    "df_rerun = pd.DataFrame({\"iid\":df1[\"iid\"].values[:100], \"coverage\":2.00})   \n",
    "### AAAAnd save\n",
    "df_rerun.to_csv(save_path, index=False)\n",
    "print(f\"Saved {len(df_rerun)} rerun iids to {save_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Loschbour_published.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loschbour_snpAD.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stuttgart_published.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UstIshim_snpAD.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ust_Ishim_published.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vindija_snpAD.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Altai_published.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Altai_snpAD.DG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Goyet_final.SG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Les_Cottes_final.SG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      iid  coverage\n",
       "0  Loschbour_published.DG       2.0\n",
       "1      Loschbour_snpAD.DG       2.0\n",
       "2  Stuttgart_published.DG       2.0\n",
       "3       UstIshim_snpAD.DG       2.0\n",
       "4  Ust_Ishim_published.DG       2.0\n",
       "5        Vindija_snpAD.DG       2.0\n",
       "6      Altai_published.DG       2.0\n",
       "7          Altai_snpAD.DG       2.0\n",
       "8          Goyet_final.SG       2.0\n",
       "9     Les_Cottes_final.SG       2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rerun.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ROH data from Individuals and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n"
     ]
    }
   ],
   "source": [
    "meta_path=\"./Data/ReichLabEigenstrat/Raw/meta.csv\"\n",
    "df_anno = pd.read_csv(meta_path)\n",
    "df_ana = df_anno[df_anno[\"mean_cov\"]>0.5]\n",
    "print(len(df_ana))\n",
    "df_ana = df_ana[:20]  # how many individuals to extract\n",
    "iids = df_ana[\"iid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 / 2106 Individuals from Meta\n",
      "Saved to: ./Empirical/Eigenstrat/Reichall/combined_roh_test.csv\n"
     ]
    }
   ],
   "source": [
    "df1 = pp_individual_roh(iids, meta_path=\"./Data/ReichLabEigenstrat/Raw/meta.csv\", base_folder=\"./Empirical/Eigenstrat/Reichall/\",\n",
    "                        save_path=\"./Empirical/Eigenstrat/Reichall/combined_roh_test.csv\", output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Process Marcus ancients\n",
    "Two folders: One with readcounts (\"./Empirical/1240k/MarcusAncs/\") and one with \n",
    "pseudohaploid mode (\"./Empirical/1240k/MarcusAncsPH/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Get the relevant IIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1002 Ancients\n",
      "Nr. high coverage ancients: 517\n"
     ]
    }
   ],
   "source": [
    "meta_path = \"./Data/Marcus2019_1240k/meta_rev_final.csv\"\n",
    "min_cov=0.5\n",
    "anc_sardind= 85\n",
    "anc_ind =  1087\n",
    "meta_df = pd.read_csv(meta_path)\n",
    "df_anno = meta_df[anc_sardind:anc_ind]\n",
    "print(f\"Loaded {len(df_anno)} Ancients\")\n",
    "\n",
    "df1 = df_anno[(df_anno[\"mean_cov\"] > min_cov) & (df_anno[\"include_alt\"] > 0)]\n",
    "print(f\"Nr. high coverage ancients: {len(df1)}\")\n",
    "iis = df1[\"iid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create the combined Result File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df1 = pp_individual_roh(iids, meta_path=\"./Data/Marcus2019_1240k/meta_rev_final.csv\", base_folder=\"./Empirical/1240k/MarcusAncsPH/\",\n",
    "                        save_path=\"./Empirical/1240k/MarcusAncsPH/combined_roh_test.csv\", output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

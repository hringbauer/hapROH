{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare 1000 Genome Reference dataset with full data\n",
    "WARNING: NEEDS 60GB OF RAM\n",
    "\n",
    "UPDATED September 21 to include saving of the X chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0402.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import allel\n",
    "import h5py  # Python Package to do the HDF5.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "#sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "sys.path.insert(0,\"./package/\")  # hack to get local package first in path\n",
    "from hapsburg.PackagesSupport.h5_python.h5_functions import merge_in_ld_map, save_data_h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vcf_to_biallelic(in_path, out_path):\n",
    "    \"\"\"Filters .vcf File to biallelic SNPs\"\"\"\n",
    "    !bcftools view -Oz -o $out_path -m2 -M2 -v snps $in_path \n",
    "    print(\"Finished BCF tools filtering to biallelic variants.\")\n",
    "\n",
    "def vcf_to_hdf5(in_path, out_path, path_vcf100g=\"\"):\n",
    "    \"\"\"Transform Full VCF to full HDF5\"\"\"\n",
    "    allel.vcf_to_hdf5(input=in_path, output=out_path, compression=\"gzip\") # Takes 10 Minutes ####chunk_length=1000000, chunk_width=1, garbage performance\n",
    "    \n",
    "def download_1kg(path_source=\"\", path_target=\"\"):\n",
    "    \"\"\"cluster: Whether program is run on cluster\"\"\"\n",
    "    tbi_s = path_source + \".tbi\"\n",
    "    tbi_t = path_target + \".tbi\"\n",
    "    \n",
    "    !scp $path_source $path_target # Only Download the .vcf (not the .tbi)\n",
    "    !scp $tbi_s $tbi_t             # Download the tbi\n",
    "    print(f\"Transfer complete. To {path_target}\")\n",
    "    \n",
    "def downsample_af(path_h5, path_save, maf=0.002, batch=1000000):\n",
    "    \"\"\"Loads hdf5 at path_h5, and filters to loci >maf.\n",
    "    Save h5 at path_save. Assumes everything is in standard format\"\"\"\n",
    "\n",
    "    f = h5py.File(path_h5, \"r\") # Load for Sanity Check. See below!\n",
    "\n",
    "    ### Calculate the AFs\n",
    "    k = np.shape(f[\"calldata/GT\"])[0]\n",
    "    \n",
    "    idcs = [] # the list of list of idx in each batch\n",
    "    ### Work in batches\n",
    "    for i in range(int(k/batch)+1):\n",
    "        print(f\"Doing batch {i}...\")\n",
    "        gt = f[\"calldata/GT\"][i*batch:(i+1)*batch,:,:]  \n",
    "        n = np.shape(gt)[1]*2 # number of haplotypes\n",
    "        gt = np.sum(gt==0, axis=1)\n",
    "        gt = np.sum(gt, axis=1)\n",
    "        p_der = 1 - gt/n\n",
    "        idx = p_der > maf # Filter\n",
    "        idcs.append(idx)\n",
    "        \n",
    "    idx = np.concatenate(idcs)\n",
    "    print(f\"Downsampling to {np.sum(idx)}/{len(idx)} Markers with MAF >{maf}\")\n",
    "\n",
    "    gt = f[\"calldata/GT\"][:,:,:][idx] # Extract the Ind\n",
    "    ref=f[\"variants/REF\"][:][idx]\n",
    "    alt=f[\"variants/ALT\"][:][idx,0] # only save the first alt allele\n",
    "    pos=f[\"variants/POS\"][:][idx]\n",
    "    rec=f[\"variants/MAP\"][:][idx]\n",
    "    samples=f[\"samples\"][:]\n",
    "    f.close()\n",
    "    \n",
    "    print(\"Saving new HDF...\")\n",
    "    save_data_h5(gt=gt, ad=[],\n",
    "                 ref=ref, alt=alt,\n",
    "                 pos=pos, rec=rec,\n",
    "                 samples=samples,\n",
    "                 path=path_save,\n",
    "                 compression='gzip',\n",
    "                 ad_group=False, gt_type='int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Function piping together everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = \"X\" # Will fill in X for Chromosome Numbers\n",
    "path_vcf_source = f\"/project2/jnovembre/data/external_public/1kg_phase3/haps/ALL.chr{ch}.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz\"\n",
    "path_vcf_here = f\"./Data/1000Genomes/AutosomeVCF/Full/chr{ch}.vcf.gz\"\n",
    "path_vcf_filter = f\"./Data/1000Genomes/AutosomeVCF/SNPs/chr{ch}.vcf.gz\"\n",
    "path_h5 = f\"./Data/1000Genomes/HDF5/FULLHDF5/chr{ch}.hdf5\"\n",
    "path_h5_maf = f\"./Data/1000Genomes/HDF5/FULLHDF5/maf02_chr{ch}.hdf5\"\n",
    "path_snp1240k = \"./Data/1000Genomes/Markers/MinMyc.snp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer complete. To ./Data/1000Genomes/AutosomeVCF/Full/chrX.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "### The functions of the pipeline\n",
    "download_1kg(path_vcf_source, path_vcf_here)  ## Takes about 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished BCF tools filtering to biallelic variants.\n",
      "CPU times: user 22.1 s, sys: 4.87 s, total: 26.9 s\n",
      "Wall time: 26min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filter_vcf_to_biallelic(in_path=path_vcf_here, out_path=path_vcf_filter)  ## Takes about 30 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 13s, sys: 27.2 s, total: 9min 40s\n",
      "Wall time: 9min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vcf_to_hdf5(path_vcf_filter, path_h5)            ## Takes about 10 for long Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the Chromosome Number from X to 23.\n",
    "# Takes ca. \n",
    "with h5py.File(path_h5, 'r+') as f:     # open the file\n",
    "    data = f['variants/CHROM']       # load the data\n",
    "    data[:] = str(23)                      # assign new values to data\n",
    "    f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifting LD Map from eigenstrat to HDF5...\n",
      "Loaded 3223936 variants.\n",
      "Loaded 2504 individuals.\n",
      "Loaded 49704 Chr.23 1240K SNPs.\n",
      "Intersection 47897 out of 3223936 HDF5 SNPs\n",
      "Interpolating 3176039 variants.\n",
      "Finished Chromosome 23.\n",
      "Adding map to HDF5...\n",
      "We did it. Finished.\n",
      "CPU times: user 10.3 s, sys: 803 ms, total: 11.1 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merge_in_ld_map(path_h5=path_h5, path_snp1240k=path_snp1240k, chs=[23,], write_mode=\"a\")  \n",
    "## Takes about 10 seconds, mode a for new LD Map; r+ for changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing batch 0...\n",
      "Doing batch 1...\n",
      "Doing batch 2...\n",
      "Doing batch 3...\n",
      "Downsampling to 3143608/3223936 Markers with MAF >0.01\n",
      "Saving new HDF...\n",
      "Successfully saved 2504 individuals to: ./Data/1000Genomes/HDF5/FULLHDF5/maf02_chrX.hdf5\n",
      "CPU times: user 7min 22s, sys: 35.4 s, total: 7min 58s\n",
      "Wall time: 8min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "downsample_af(path_h5, path_h5_maf, maf=0.01) ## Takes about 10 Minute, mode a for new LD Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the full Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to AF SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3143608 variants\n",
      "Loaded 2504 individuals\n",
      "['GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "### Test the Final HDF5 just created\n",
    "ch = 3\n",
    "path_load = f\"./Data/1000Genomes/HDF5/FULLHDF5/maf1_chrX.hdf5\"\n",
    "\n",
    "f = h5py.File(path_load, \"r\") # Load for Sanity Check. See below!\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"samples\"][:].astype(\"str\")==\"iid0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading the new hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3143608 variants\n",
      "Loaded 2504 individuals\n",
      "['GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "### Test the Final HDF5 just created\n",
    "ch = \"X\"\n",
    "path_load = f\"./Data/1000Genomes/HDF5/FULLHDF5/maf1_chrX.hdf5\" # /maf02_chrX.hdf5\n",
    "\n",
    "f = h5py.File(path_load, \"r\") # Load for Sanity Check. See below!\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = f[\"calldata/GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17395\n",
       "1     2605\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(gt[:100,:100,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3143608,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = f[\"variants/MAP\"]\n",
    "np.shape(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2363635, 1.2363635, 1.2363636, 1.2363636, 1.2363639, 1.2363639,\n",
       "       1.2363639, 1.236364 , 1.236364 , 1.2363641, 1.2363641, 1.2363642,\n",
       "       1.2363644, 1.2363645, 1.2363645, 1.2363647, 1.2363647, 1.2363647,\n",
       "       1.2363648, 1.236365 , 1.236365 , 1.2363652, 1.2363654, 1.2363656,\n",
       "       1.2363658, 1.2363658, 1.2363658, 1.2363662, 1.2363664, 1.2363665,\n",
       "       1.2363665, 1.2363667, 1.2363667, 1.2363669, 1.236367 , 1.236367 ,\n",
       "       1.236367 , 1.2363671, 1.2363672, 1.2363672, 1.2363673, 1.2363673,\n",
       "       1.2363675, 1.2363675, 1.2363676, 1.2363676, 1.2363678, 1.236368 ,\n",
       "       1.236368 , 1.236368 , 1.2363681, 1.2363682, 1.2363687, 1.2363689,\n",
       "       1.236369 , 1.2363691, 1.2363691, 1.2363695, 1.2363695, 1.2363696,\n",
       "       1.23637  , 1.2363701, 1.2363702, 1.2363702, 1.2363703, 1.2363703,\n",
       "       1.2363704, 1.2363706, 1.2363706, 1.2363707, 1.2363708, 1.2363708,\n",
       "       1.2363709, 1.236371 , 1.236371 , 1.2363713, 1.236372 , 1.236372 ,\n",
       "       1.2363725, 1.2363727, 1.2363734, 1.2363734, 1.2363737, 1.2363738,\n",
       "       1.236374 , 1.236374 , 1.2363741, 1.2363743, 1.2363743, 1.2363744,\n",
       "       1.2363746, 1.2363746, 1.2363746, 1.2363747, 1.2363747, 1.2363749,\n",
       "       1.2363749, 1.236375 , 1.2363751, 1.2363752], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[2000000:2000000+100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do experiments about loading time of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = []\n",
    "s = np.shape(f[\"calldata/GT\"])\n",
    "ts = [10,50,100,500,1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "for i in ts:\n",
    "    print(f\"Doing {i} Loci\")\n",
    "    t = time() \n",
    "    idx = np.random.choice(s[0], size=i, replace=False)\n",
    "    idx=  np.sort(idx)\n",
    "    gt = f[\"calldata/GT\"][idx,:,:]\n",
    "    e = time()\n",
    "    res.append(e-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allele Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3223936 variants\n",
      "Loaded 2504 individuals\n",
      "['GT']\n",
      "['ALT', 'CHROM', 'FILTER_PASS', 'ID', 'MAP', 'POS', 'QUAL', 'REF']\n",
      "CPU times: user 45.5 s, sys: 10.5 s, total: 56.1 s\n",
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Test the Final HDF5 just created\n",
    "path_load = f\"./Data/1000Genomes/HDF5/FULLHDF5/chrX.hdf5\" # /maf02_chrX.hdf5\n",
    "\n",
    "f = h5py.File(path_load, \"r\") # Load for Sanity Check. See below!\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))\n",
    "\n",
    "gt = f[\"calldata/GT\"][:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt1 = np.sum(gt==0, axis=1)\n",
    "gt2 = np.sum(gt1, axis=1)\n",
    "p_der = 1 - gt2/(np.shape(gt)[1]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3143608, 2504, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    476559356\n",
       "-1    156060650\n",
       " 1     12167194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(gt[:,:100,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 201)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.hist(p_der, ec=\"k\", bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"variants/ALT\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b5edb7b78a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try loading 1e6 genotypes - check how much data is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.534832000732422\n",
      "62.49126052856445\n"
     ]
    }
   ],
   "source": [
    "print(psutil.virtual_memory().used / (1024.0 ** 3))\n",
    "print(psutil.virtual_memory().total / (1024.0 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 1.26 s, total: 20.4 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt = f[\"calldata/GT\"][:1000000,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.221786499023438\n",
      "62.49126052856445\n"
     ]
    }
   ],
   "source": [
    "print(psutil.virtual_memory().used / (1024.0 ** 3))\n",
    "print(psutil.virtual_memory().total / (1024.0 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5732585, 2504, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(f[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"calldata/GT\"][:100,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading eigenstrat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_snp1240k = \"./Data/1000Genomes/Markers/MinMyc.snp\"\n",
    "df = pd.read_csv(path_snp1240k,  delimiter=r\"\\s+\", header=None)\n",
    "df.columns=[\"SNP\", \"ch\", \"maf\", \"pos\", \"ref\", \"alt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     98657\n",
       "1     93166\n",
       "3     81416\n",
       "6     78867\n",
       "5     74004\n",
       "4     71634\n",
       "8     63916\n",
       "7     62595\n",
       "10    61131\n",
       "11    57163\n",
       "12    56133\n",
       "9     52765\n",
       "23    49704\n",
       "13    40441\n",
       "14    37903\n",
       "16    36000\n",
       "15    35991\n",
       "18    35327\n",
       "24    32670\n",
       "17    30733\n",
       "20    30377\n",
       "19    19273\n",
       "21    16727\n",
       "22    16420\n",
       "Name: ch, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ch\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_vcf = \"./Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Program: bcftools (Tools for variant calling and manipulating VCFs and BCFs)\n",
      "Version: 1.9 (using htslib 1.9)\n",
      "\n",
      "Usage:   bcftools [--version|--version-only] [--help] <command> <argument>\n",
      "\n",
      "Commands:\n",
      "\n",
      " -- Indexing\n",
      "    index        index VCF/BCF files\n",
      "\n",
      " -- VCF/BCF manipulation\n",
      "    annotate     annotate and edit VCF/BCF files\n",
      "    concat       concatenate VCF/BCF files from the same set of samples\n",
      "    convert      convert VCF/BCF files to different formats and back\n",
      "    isec         intersections of VCF/BCF files\n",
      "    merge        merge VCF/BCF files files from non-overlapping sample sets\n",
      "    norm         left-align and normalize indels\n",
      "    plugin       user-defined plugins\n",
      "    query        transform VCF/BCF into user-defined formats\n",
      "    reheader     modify VCF/BCF header, change sample names\n",
      "    sort         sort VCF/BCF file\n",
      "    view         VCF/BCF conversion, view, subset and filter VCF/BCF files\n",
      "\n",
      " -- VCF/BCF analysis\n",
      "    call         SNP/indel calling\n",
      "    consensus    create consensus sequence by applying VCF variants\n",
      "    cnv          HMM CNV calling\n",
      "    csq          call variation consequences\n",
      "    filter       filter VCF/BCF files using fixed thresholds\n",
      "    gtcheck      check sample concordance, detect sample swaps and contamination\n",
      "    mpileup      multi-way pileup producing genotype likelihoods\n",
      "    roh          identify runs of autozygosity (HMM)\n",
      "    stats        produce VCF/BCF stats\n",
      "\n",
      " Most commands accept VCF, bgzipped VCF, and BCF with the file type detected\n",
      " automatically even when streaming from a pipe. Indexed VCF and BCF will work\n",
      " in all situations. Un-indexed VCF and BCF and streams will work in most but\n",
      " not all situations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -f '%CHROM %POS %REF %ALT\\n' file.bcf | head -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code to change hdf5 gt to int9\n",
    "%%time\n",
    "\n",
    "out_folder = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240bool0/chr\"\n",
    "\n",
    "def create_int_h5(org_folder = \"./Data/1000Genomes/HDF5/FULLHDF5/chr\",\n",
    "                  out_folder = \"./Data/1000Genomes/HDF5/FULLHDF5.int8/chr\",\n",
    "                  ch=4):\n",
    "    \"\"\"Create a int8 genotype hdf5 from full hdf5\"\"\"\n",
    "    load_path = org_folder + str(ch) + \".h5\"\n",
    "    save_path = out_folder + str(ch) + \".h5\" \n",
    "\n",
    "    # Make Directory if not already there\n",
    "    if not os.path.exists(os.path.dirname(save_path)):   \n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "    #os.remove(save_path)  # For previous whoopsie\n",
    "    m = ModifyHDF5Genotypes(original_path=load_path, save_path=save_path)\n",
    "    m.downsample_gt(frac=1.0, ad=False, mult_alt=True, gt_type=\"int8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

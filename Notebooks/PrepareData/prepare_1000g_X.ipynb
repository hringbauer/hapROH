{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Prepare 1000 Genomes Data\n",
    "This notebooks prepares the downsampled HDF5 for 1240k Data.\n",
    "Requires bcftools binary.\n",
    "Atm, only runs on Harald's local machine (where BCFtools is installed)\n",
    "Runtime on one CPU: Ca. 15 Min for Chr. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0401.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import allel\n",
    "import h5py  # Python Package to do the HDF5.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce SNP file (file used for downsampling)\n",
    "Needs to be run only once on each setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare downsampled X hdf5s\n",
    "Prepare a 1000 Genome X hdf5 file. Include Recombination Map\n",
    "Input: 1000 Genome vcf file, Recombination Map from a 1240k Eigenstrat\n",
    "## Standalone from here onward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 0: Download the Data\n",
    "- Step 1: Produce hdf5 file for all markers\n",
    "- Step 2: Extract Positions. Match with Eigenstrat File Positions\n",
    "- Step 3: Create new vcf based on subset of Individuals and Markers\n",
    "- Step 4: Transfer to hdf5. \n",
    "- Step 5: Merge in Linkage Map\n",
    "- Step 6: Quality Check? (Control ref/alt against hdf5 we have for Sardinians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 0: Download the Data and produce SNP file\n",
    "def produce_variant_file_X(snp_path, save_path):\n",
    "    \"\"\"Produces txt file listing names of all 1240k SNPs\"\"\"\n",
    "    df_snp = pd.read_csv(snp_path, header=None,\n",
    "                                 sep=r\"\\s+\", engine=\"python\")\n",
    "    df_snp.columns = [\"SNP\", \"chr\", \"map\",\n",
    "                      \"pos\", \"ref\", \"alt\"]  # Set the Columns\n",
    "\n",
    "    df_snp = df_snp[df_snp[\"chr\"]==23]\n",
    "    df_snp = df_snp[2:] # Remove the first two SNPs (isolated on X)\n",
    "    print(f\"Loaded {len(df_snp)} X SNPs.\")\n",
    "    \n",
    "    df_save = df_snp[[\"chr\", \"pos\"]].copy()\n",
    "    df_save.loc[:,\"chr\"] = \"X\"\n",
    "    df_save.to_csv(save_path, sep=\"\\t\", header=False, index=False)\n",
    "    print(f\"Successfully saved to {save_path}. Length: {len(df_save)}\")\n",
    "    \n",
    "### Step 1: Produce hdf5 file for all markers\n",
    "def vcf_to_hdf5(in_path, out_path):\n",
    "    \"\"\"Transform Full VCF to full HDF5\"\"\"\n",
    "    allel.vcf_to_hdf5(input=in_path, output=out_path, compression=\"gzip\") # Takes 10 Minutes\n",
    "    \n",
    "### Step 2: Extract Positions. Match with Eigenstrat File Positions\n",
    "### Load HDF5\n",
    "\n",
    "def merge_positions():\n",
    "    \"\"\"Creates the Filter File to filter SNPs for\"\"\"\n",
    "    f_full = h5py.File(path_hdf5temp, \"r\") # Load for Sanity Check. See below!\n",
    "    print(\"Loaded %i variants\" % np.shape(f_full[\"calldata/GT\"])[0])\n",
    "    print(\"Loaded %i individuals\" % np.shape(f_full[\"calldata/GT\"])[1])\n",
    "    print(list(f_full[\"calldata\"].keys()))\n",
    "    print(list(f_full[\"variants\"].keys()))\n",
    "    #print(list(f[\"samples\"].keys()))\n",
    "\n",
    "    ### Load Eigenstrat\n",
    "    df_snp = pd.read_csv(snp1240k_path, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "    df_snp.columns = [\"SNP\", \"chr\", \"map\", \"pos\", \"ref\", \"alt\"]\n",
    "    df_snp = df_snp[df_snp[\"chr\"] == ch]\n",
    "    print(f\"Loaded {len(df_snp)} Chr.{ch} SNPs.\")\n",
    "\n",
    "    ### Prepare SNP File for Eigenstrat filtering \n",
    "    found = np.isin(f_full[\"variants/POS\"], df_snp[\"pos\"])\n",
    "    print(f\"Intersection: {np.sum(found)} out of {len(found)} SNPS\")\n",
    "    variants = f_full[\"variants/ID\"][found]\n",
    "\n",
    "    dots = np.where(variants == \".\")[0]\n",
    "    print(f\"Found {len(dots)} unnamed SNPs\")\n",
    "    variants = np.delete(variants, dots)\n",
    "\n",
    "    np.savetxt(snp_filter_path, variants, fmt=\"%s\")\n",
    "    print(f\"Successfully saved to {snp_filter_path}. Length: {len(variants)}\")\n",
    "    \n",
    "def save_1240kmarkers():\n",
    "    \"\"\"Save all 1240 Markers in csv\"\"\"\n",
    "    df_snp = pd.read_csv(snp1240k_path, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "    df_snp.columns = [\"SNP\", \"chr\", \"map\", \"pos\", \"ref\", \"alt\"]\n",
    "    df_snp = df_snp[df_snp[\"chr\"] == ch]\n",
    "    print(f\"Loaded {len(df_snp)} Chr.{ch} SNPs.\")\n",
    "\n",
    "    df_save = df_snp[[\"chr\", \"pos\"]]\n",
    "    df_save.to_csv(marker_path, sep=\"\\t\", header=None, index=False)\n",
    "    print(f\"Saved {len(df_save)} 1240k Markers on Chr. {ch} to {marker_path}\")\n",
    "    \n",
    "### Step 3: Create new vcf based on subset of Individuals and Markers\n",
    "def plink_new_vcf():\n",
    "    \"\"\"Extract 1240k \n",
    "    SNPs with Plink\"\"\"\n",
    "    !plink --vcf $path_vcf100g --extract $snp_filter_path --keep-fam $ind_path --recode vcf --out $out_vcf_path0 --biallelic-only strict --keep-allele-order\n",
    "\n",
    "### Step 3b\n",
    "def bctools_new_vcf0():\n",
    "    \"\"\"Same as PLINK, but with bcftools \n",
    "    [small hack with marker strings, so LEGACY code and replaced by bcftools_new_vcf]\"\"\"\n",
    "    str_ex = \"ID=@\" + snp_filter_path\n",
    "    #!echo bcftools view -Oz -o $out_vcf_path_gz -S $ind_path -i $str_ex -m2 -M2 -v snps $path_vcf100g\n",
    "    !bcftools view -Oz -o $out_vcf_path_gz -S $ind_path -i $str_ex -m2 -M2 -v snps $path_vcf100g\n",
    "    print(\"Finished BCF tools runs.\")\n",
    "    \n",
    "def bctools_new_vcf(filter_iids=True, cluster=False):\n",
    "    \"\"\"Same as PLINK, but with bcftools and directly via Marker Positions.\n",
    "    filter_iids: Whether to use the .csv with Indivdiduals to extract\"\"\"\n",
    "    if filter_iids==True:\n",
    "        if cluster==False:\n",
    "            !bcftools view -Oz -o $out_vcf_path_gz -S $ind_path -T $marker_path -m2 -M2 -v snps $path_vcf100g\n",
    "        elif cluster==True:\n",
    "            !module load bcftools; bcftools view -Oz -o $out_vcf_path_gz -S $ind_path -T $marker_path -m2 -M2 -v snps $path_vcf100g     \n",
    "    elif filter_iids==False:\n",
    "        if cluster==False:\n",
    "            !bcftools view -Oz -o $out_vcf_path_gz -T $marker_path -m2 -M2 -v snps $path_vcf100g\n",
    "        elif cluster==True:\n",
    "            !module load bcftools; bcftools view -Oz -o $out_vcf_path_gz -T $marker_path -m2 -M2 -v snps $path_vcf100g\n",
    "    print(\"Finished BCF tools runs.\")\n",
    "\n",
    "### Step 4: Transfer to hdf5.\n",
    "#allel.vcf_to_hdf5(input=out_vcf_path, output=path_hdf5final, compression=\"gzip\") # Takes 1s\n",
    " \n",
    "### Step 5: Merge in Linkage Map\n",
    "### Load HDF5\n",
    "def merge_in_ld_map(ch=23):\n",
    "    \"\"\"Merge in ld_map into HDF5!\"\"\"\n",
    "    f = h5py.File(path_hdf5final, \"r\") # Load for Sanity Check. See below!\n",
    "    print(\"Merging in LD Map into HDF5...\")\n",
    "    print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "    print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "    print(list(f[\"calldata\"].keys()))\n",
    "    print(list(f[\"variants\"].keys()))\n",
    "    #print(list(f[\"samples\"].keys()))\n",
    "\n",
    "    ### Load Eigenstrat\n",
    "    df_snp = pd.read_csv(snp1240k_path, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "    df_snp.columns = [\"SNP\", \"chr\", \"map\", \"pos\", \"ref\", \"alt\"]\n",
    "    df_snp = df_snp[df_snp[\"chr\"] == ch]\n",
    "    print(f\"Loaded {len(df_snp)} Chr.{ch} SNPs.\")\n",
    "\n",
    "    ### Intersect SNP positions\n",
    "    its, i1, i2 = np.intersect1d(f[\"variants/POS\"], df_snp[\"pos\"], return_indices=True)\n",
    "\n",
    "    l = len(f[\"variants/POS\"])\n",
    "    print(f\"Intersection {len(i2)} out of {l}\")\n",
    "\n",
    "    ### Extract \n",
    "    rec = np.zeros(len(f[\"variants/POS\"]))\n",
    "    rec[i1] = df_snp[\"map\"].values[i2]  # Fill in the values in Recombination map\n",
    "    ids0 = np.where(rec == 0)[0] # The 0 Values which should be filled in\n",
    "    rec[ids0] = (rec[ids0-1] + rec[ids0+1]) / 2.0 # Interpolate\n",
    "\n",
    "    ### Make sure that sorted\n",
    "    assert(np.all(np.diff(rec)>=0))  # Assert the Recombination Map is sorted! (no 0 left and no funky stuff)\n",
    "\n",
    "    f.close()\n",
    "    with h5py.File(path_hdf5final, 'a') as f0:\n",
    "        group = f0[\"variants\"]\n",
    "        group.create_dataset('MAP', (l,), dtype='f')   \n",
    "        f0[\"variants/MAP\"][:] = rec[:]\n",
    "\n",
    "    print(f\"Finished Chromosome {ch}\")\n",
    "    \n",
    "### Step 6: Delete the Data:\n",
    "def del_temp_data():\n",
    "    !rm $path_vcf100g # Delete the full 1000 genome .vcf\n",
    "    !rm $out_vcf_path_gz # Delete the extracted .vcf\n",
    "    #!rm $path_hdf5temp # The originally intermediate hdf5 (for 1240k intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Important Parameters and paths\n",
    "ch = 3 # Which Chromosome to use:\n",
    "\n",
    "# Path of the 1000 Genome VCF:\n",
    "p1, p2 = \"\", \"\"\n",
    "file_vcf100g, path_vcf100g = \"\", \"\"\n",
    "out_vcf_path0, out_vcf_path = \"\", \"\"\n",
    "path_hdf5temp, path_hdf5final = \"\", \"\"\n",
    "\n",
    "snp1240k_path, ind_path = \"\", \"\"   # Where to find the 1240k SNPs\n",
    "snp_filter_path = \"\"\n",
    "\n",
    "def prepare_paths_X():\n",
    "    \"\"\"Prepares all the Paths need for processing Steps.\n",
    "    ch: Which Chromosomes to use\"\"\"\n",
    "    global file_vcf100g, path_vcf100g, out_vcf_path0, out_vcf_path, path_hdf5temp, path_hdf5final\n",
    "    global snp1240k_path, ind_path, snp_filter_path, out_vcf_path_gz, marker_path\n",
    "    # Path of the 1000 Genome VCF:\n",
    "    path_vcf100g = \"./Data/1000Genomes/X_VCF/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz\"\n",
    "    print(f\"Full Input path:\\n{path_vcf100g}\")\n",
    "    out_vcf_path0 = \"./Data/1000Genomes/X_VCF/Subset/1240all/chrX\"\n",
    "    out_vcf_path = out_vcf_path0 + \".vcf\"\n",
    "    out_vcf_path_gz = out_vcf_path + \".gz\"\n",
    "    path_hdf5temp = \"./Data/1000Genomes/HDF5/FULLHDF5/cr\" + \"X\" + \".hdf5\"\n",
    "    path_hdf5final = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chrX.hdf5\"\n",
    "    snp1240k_path = \"./Data/1000Genomes/Markers/MinMyc.snp\"   # Where to find the 1240k SNPs\n",
    "    ind_path = \"./Data/1000Genomes/Individuals/NO_EXIST.csv\"  # non-existing place-holder (sanity check)\n",
    "    marker_path = \"./Data/1000Genomes/Markers/1240k/chrX.csv\"\n",
    "    \n",
    "    for path in [out_vcf_path, path_hdf5final]:\n",
    "        path_dir = os.path.dirname(path)\n",
    "    \n",
    "        if not os.path.exists(path_dir):\n",
    "            os.makedirs(path_dir)\n",
    "            print(f\"Created new directory: {path_dir}\")\n",
    "    \n",
    "    ### Path of SNP Filter\n",
    "    snp_filter_path = \"../Data/1000Genomes/Markers/variants1240k\" + str(ch) + \".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do all steps to extract X reference panel\n",
    "(one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49702 X SNPs.\n",
      "Successfully saved to ./Data/1000Genomes/Markers/1240k/chrX.csv. Length: 49702\n"
     ]
    }
   ],
   "source": [
    "produce_variant_file_X(snp_path = \"./Data/1000Genomes/Markers/MinMyc.snp\",\n",
    "                       save_path = \"./Data/1000Genomes/Markers/1240k/chrX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Input path:\n",
      "./Data/1000Genomes/X_VCF/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "prepare_paths_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W::hts_idx_load2] The index file is older than the data file: ./Data/1000Genomes/X_VCF/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz.tbi\n",
      "Finished BCF tools runs.\n",
      "CPU times: user 11.6 s, sys: 1.78 s, total: 13.4 s\n",
      "Wall time: 7min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Takes about 8 min\n",
    "bctools_new_vcf(filter_iids=False, cluster=True)  # Important, turn off filter individuals here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 403 ms, total: 10.7 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vcf_to_hdf5(in_path=out_vcf_path_gz, out_path=path_hdf5final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging in LD Map into HDF5...\n",
      "Loaded 47898 variants\n",
      "Loaded 2504 individuals\n",
      "['GT']\n",
      "['ALT', 'CHROM', 'FILTER_PASS', 'ID', 'POS', 'QUAL', 'REF']\n",
      "Loaded 49704 Chr.23 SNPs.\n",
      "Intersection 47895 out of 47898\n",
      "Finished Chromosome 23\n",
      "CPU times: user 9.13 s, sys: 285 ms, total: 9.41 s\n",
      "Wall time: 9.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merge_in_ld_map(ch=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file at: ./Data/1000Genomes/HDF5/1240kHDF5/all1240/chrX.hdf5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final file at: {path_hdf5final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del_temp_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Metafile with Sex [Standalone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/1000Genomes/Individuals/meta_df_all.csv', sep=\"\\t\")\n",
    "pop_path = \"./Data/1000Genomes/integrated_call_samples_v3.20130502.ALL.panel\" # Population Information\n",
    "df_pops = pd.read_csv(pop_path, sep=\"\\t\")\n",
    "print(f\"Loaded {np.shape(df_i)[0]} Population Data\")\n",
    "\n",
    "df_m = pd.merge(df, df_pops[[\"sample\", \"gender\"]], on=\"sample\", how=\"left\")\n",
    "\n",
    "savepath=\"./Data/1000Genomes/Individuals/meta_df_all_sex.tsv\"\n",
    "df_m.to_csv(savepath, sep=\"\\t\")\n",
    "print(f\"Save {len(df_m)} Meta Data rows to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load hdf5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HDF5\n",
      "Loaded 47900 variants\n",
      "Loaded 2504 individuals\n",
      "['GT']\n",
      "['ALT', 'CHROM', 'FILTER_PASS', 'ID', 'MAP', 'POS', 'QUAL', 'REF']\n"
     ]
    }
   ],
   "source": [
    "path_load = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chrX.hdf5\"\n",
    "#path_load = \"./Data/SA_1240kHDF5/IPK12_downsample_ph.h5\"\n",
    "f = h5py.File(path_load, \"r\") # Load for Sanity Check. See below!\n",
    "        \n",
    "print(\"Loaded HDF5\")\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.071651, 0.145112, 0.208504, 0.208896, 0.208974, 0.209002,\n",
       "       0.209031, 0.20918 , 0.209643, 0.209646], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"variants/MAP\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1],\n",
       "       [ 1, -1],\n",
       "       [ 0,  0],\n",
       "       [ 0, -1],\n",
       "       [ 1,  0],\n",
       "       [ 0, -1],\n",
       "       [ 0,  0],\n",
       "       [ 0, -1],\n",
       "       [ 0,  1],\n",
       "       [ 0, -1]], dtype=int8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"calldata/GT\"][303,1000:1010,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = np.sum(f[\"calldata/GT\"][:]==-1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47825,     0,     0, ...,     0,     0,     0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(missing[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

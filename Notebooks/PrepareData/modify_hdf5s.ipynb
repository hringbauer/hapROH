{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot for downsampling / throwing in errors\n",
    "Plan: Input is a a HDF5, Output is a HDF5. Eventually make class that can downsample, and/or throw errors on the reads.\n",
    "\n",
    "Class is a wrapper of an HDF5, and applies the operations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midway jnovmbre partition detected.\n",
      "/project/jnovembre/hringbauer/HAPSBURG\n"
     ]
    }
   ],
   "source": [
    "import allel\n",
    "import h5py  # Python Package to do the HDF5.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import socket\n",
    "import os\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket.gethostname() == \"midway2-0401.rcc.local\" or socket.gethostname() == \"midway2-0402.rcc.local\":\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifyHDF5Genotypes(object):\n",
    "    \"\"\"Class for Modifying HDF5 genotypes and\n",
    "    saving new HDF5s. Can downsample/throw down error/Create Readcound.\n",
    "    Plan: Also do contamination\"\"\"\n",
    "\n",
    "    f = 0    # The hdf5 object to modify\n",
    "    original_path = \"\" # Where to find the original HDF5\n",
    "    save_path = \"\"  # Where to save the modified HDF5 to\n",
    "    output = True # Whether to print any output\n",
    "    gt_new = []\n",
    "\n",
    "    def __init__(self, original_path=\"\", save_path=\"\", output=True):\n",
    "        \"\"\"pop_path: Where to load a HDF5 from\n",
    "           save_path: Where to save the new HDF5 to\"\"\"\n",
    "        self.output = output\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        if output == True:\n",
    "            print(\"Heyho back old friend. I started running\")\n",
    "        \n",
    "        if len(original_path)>0:\n",
    "            self.original_path = original_path\n",
    "            self.load_data()\n",
    "        else:\n",
    "            print(\"No HDF5 Loaded! Alarm. Alarm. Alarm.\")\n",
    "\n",
    "    def load_data(self, path=\"\"):\n",
    "        \"\"\"Load the HDF5 Data\"\"\"\n",
    "        if len(path)==0:\n",
    "            path = self.original_path\n",
    "        self.f = h5py.File(path, \"r\") # Load for Sanity Check. See below!\n",
    "        \n",
    "        if self.output == True:\n",
    "            print(\"Loaded HDF5\")\n",
    "            print(\"Loaded %i variants\" % np.shape(self.f[\"calldata/GT\"])[0])\n",
    "            print(\"Loaded %i individuals\" % np.shape(self.f[\"calldata/GT\"])[1])\n",
    "            print(list(self.f[\"calldata\"].keys()))\n",
    "            print(list(self.f[\"variants\"].keys()))\n",
    "            #self.f[\"samples\"] # Samples Vector\n",
    "        \n",
    "        ### Sanity Check whether both Genotypes are there and nothing else\n",
    "        assert(np.min(self.f[\"calldata/GT\"]) == 0)\n",
    "        assert(np.max(self.f[\"calldata/GT\"]) == 1)\n",
    "\n",
    "    def save_data(self, gt, ad, ref, alt, pos, rec, samples, path):\n",
    "        \"\"\"Create a new HDF5 File with Input Data.\n",
    "        gt: Genotype data [l,k,2]\n",
    "        ad: Allele depth [l,k,2]\n",
    "        ref: Reference Allele [l]\n",
    "        alt: Alternate Allele [l]\n",
    "        pos: Position  [l]\n",
    "        m: Map position [l]\n",
    "        samples: Sample IDs [k]\"\"\"\n",
    "\n",
    "        l, k, _ = np.shape(gt)  # Nr loci and Nr of Individuals\n",
    "\n",
    "        if os.path.exists(path):  # Do a Deletion of existing File there\n",
    "            os.remove(path)\n",
    "\n",
    "        dt = h5py.special_dtype(vlen=str)  # To have no problem with saving\n",
    "\n",
    "        with h5py.File(path, 'w') as f0:\n",
    "            # Create all the Groups\n",
    "            f_map = f0.create_dataset(\"variants/MAP\", (l,), dtype='f')\n",
    "            f_ad = f0.create_dataset(\"calldata/AD\", (l, k, 2), dtype='i')\n",
    "            f_ref = f0.create_dataset(\"variants/REF\", (l,), dtype=dt)\n",
    "            f_alt = f0.create_dataset(\"variants/ALT\", (l,), dtype=dt)\n",
    "            f_pos = f0.create_dataset(\"variants/POS\", (l,), dtype='i')\n",
    "            f_gt = f0.create_dataset(\"calldata/GT\", (l, k, 2), dtype='i')\n",
    "            f_samples = f0.create_dataset(\"samples\", (k,), dtype=dt)\n",
    "\n",
    "            # Save the Data\n",
    "            f_map[:] = rec\n",
    "            f_ad[:] = ad\n",
    "            f_ref[:] = ref.astype(\"S1\")\n",
    "            f_alt[:] = alt.astype(\"S1\")\n",
    "            f_pos[:] = pos\n",
    "            f_gt[:] = gt\n",
    "            f_samples[:] = np.array(samples).astype(\"S10\")\n",
    "\n",
    "        if self.output == True:\n",
    "            print(f\"Successfully saved {k} individuals to: {path}\")\n",
    "\n",
    "    def create_error_gt(self, freq_flips=0.01):\n",
    "        \"\"\"Create Error on the HDF5 of genotypes.\n",
    "        freq_flips: How often to do flip of genotyps\"\"\"\n",
    "        f = self.f\n",
    "        gt = f[\"calldata/GT\"]\n",
    "        \n",
    "        switch = np.random.random(np.shape(gt)) < freq_flips\n",
    "        \n",
    "        if self.output == True:\n",
    "            print(f\"Swapping frac of SNPs: {np.mean(switch):.6f}\")\n",
    "\n",
    "        ### Switch the Genotypes\n",
    "        gt_new = (gt + switch) %2\n",
    "        ### Debugging\n",
    "        #print(np.mean(gt_new != gt))\n",
    "        #print(np.unique(gt_new))\n",
    "        \n",
    "        self.save_data(gt_new, f[\"calldata/AD\"], f[\"variants/REF\"][:], f[\"variants/ALT\"][:], f[\"variants/POS\"], \n",
    "                       f[\"variants/MAP\"], f[\"samples\"][:], self.save_path)\n",
    "            \n",
    "    def downsample_gt(self, frac=0.9):\n",
    "        \"\"\"Downsample the HDF5 to fewer reads.\n",
    "        Update also the recombination and position map if needed to remove missing values\n",
    "        frac: To what fraction of markers one downsamples\"\"\"\n",
    "        f = self.f\n",
    "        gt = f[\"calldata/GT\"]\n",
    "        \n",
    "        ### Decide on SNPs\n",
    "        l, n, _ = np.shape(gt)\n",
    "        survive = np.random.random(l) < frac\n",
    "        print(f\"Fraction Loci surviving {np.mean(survive):.6f}\")\n",
    "        \n",
    "        ### Downsample\n",
    "        gt_new = gt[survive,:,:]   #\n",
    "        r_map_new = f[\"variants/MAP\"][survive]\n",
    "        ad_new = f[\"calldata/AD\"][survive,:,:]\n",
    "        ref_new = f[\"variants/REF\"][survive]\n",
    "        alt_new = f[\"variants/ALT\"][survive]\n",
    "        pos_new = f[\"variants/POS\"][survive]\n",
    "        \n",
    "        ### Downsample where needed  \n",
    "        self.save_data(gt_new, ad_new, ref_new, alt_new, pos_new, r_map_new, f[\"samples\"], self.save_path)\n",
    "        \n",
    "    def generate_binomial_rc(self, mean_rc=1):\n",
    "        \"\"\"Generate Readcount Data from GT data.\n",
    "        mean_rc: The Mean total Readcount per site\"\"\"\n",
    "        \n",
    "        f = self.f\n",
    "        gt = f[\"calldata/GT\"]\n",
    "        \n",
    "        ### Create the Poisson Readcounts with the right mean\n",
    "        rc_full = poisson_readcounts(gt, mean_rc, output=self.output) \n",
    "        \n",
    "        self.save_data(gt, rc_full, f[\"variants/REF\"][:], f[\"variants/ALT\"][:], f[\"variants/POS\"], \n",
    "               f[\"variants/MAP\"], f[\"samples\"][:], self.save_path)\n",
    "        \n",
    "    def generate_lambda_rc(self, mean_rc = 1, norm_counts=True,\n",
    "                           lambda_path = \"./Data/1000Genomes/Coverage/mean_cov1240k_Marcus.csv\"):\n",
    "        \"\"\"Generate Readcount Data from GT data.\n",
    "        Use Table found at lambda_path for Lambdas \n",
    "        (relative. mean coverages, normed to 1 genome-wide)\n",
    "        norm_counts: Whether to normalize on overlapping Readcounts\"\"\"\n",
    "        \n",
    "        df_lambda = load_lambda(lambda_path, output=self.output)  ### Load the Lambda Data\n",
    "        \n",
    "        f = self.f\n",
    "        gt = f[\"calldata/GT\"]\n",
    "        l, n, _ = np.shape(gt)\n",
    "        \n",
    "        pos_f = f[\"variants/POS\"][:]  # The Position of the Original \n",
    "        _, i1, i2 = np.intersect1d(pos_f, df_lambda[\"Pos\"], return_indices=True)\n",
    "        \n",
    "        if self.output==True:\n",
    "            print(f\"Found {len(i1)} / {l} Loci in Lambda Table\")\n",
    "        \n",
    "        lambdas = df_lambda[\"Lambda\"].values[i2]\n",
    "        if norm_counts == True: # Normalize to extracted lambdas\n",
    "            lambdas = lambdas / np.mean(lambdas)\n",
    "            \n",
    "        mean_cov = lambdas * mean_rc  # Extract the Means that Intersect\n",
    "        gt = gt[i1,:,:]  # Downsample to Loci intersecting the Lambda Table \n",
    "        \n",
    "        ### Do the Binomial Readcount Sampling\n",
    "        rc_full = poisson_readcounts(gt, mean_cov[:,None], output=self.output) \n",
    "        \n",
    "        i1 = list(i1)  # So that it works with HDF5\n",
    "        self.save_data(gt, rc_full, f[\"variants/REF\"][i1], f[\"variants/ALT\"][i1], f[\"variants/POS\"][i1], \n",
    "               f[\"variants/MAP\"][i1], f[\"samples\"][:], self.save_path)\n",
    "        \n",
    "    def copy_rohinfo(self, load_path=\"\", save_path=\"\", file=\"roh_info.csv\"):\n",
    "        \"\"\"Copy in the ROH Info from folder of load path into folder of save_path.\n",
    "        file: Which file to copy (roh_info by default)\"\"\"\n",
    "        if len(load_path) == 0:\n",
    "            load_path = self.original_path\n",
    "            \n",
    "        if len(save_path) ==0 :\n",
    "            save_path = self.save_path\n",
    "            \n",
    "        save_path = os.path.dirname(save_path) + \"/\" + file\n",
    "        load_path = os.path.dirname(load_path) + \"/\" + file\n",
    "        \n",
    "        ### Copy the file\n",
    "        !cp $load_path $save_path  \n",
    "        \n",
    "##########################################\n",
    "#### Some Small Helper Functions\n",
    "\n",
    "def load_lambda(loadpath, ch=3, output=True):\n",
    "    \"\"\"Load and return the Lambda Vector\n",
    "    for Chromosome ch, and from path loadpath\"\"\"\n",
    "    df_lambda = pd.read_csv(loadpath)\n",
    "    mean = np.mean(df_lambda[\"Lambda\"])\n",
    "    assert(np.isclose(mean, 1))  # Sanity Check if Valid Lambda Vector\n",
    "    l=len(df_lambda)\n",
    "    df_lambda = df_lambda[df_lambda[\"Ch\"]==ch]\n",
    "    if output==True:\n",
    "        print(f\"Extracted {len(df_lambda)} / {l} Loci on Chr.{ch}\")\n",
    "    return df_lambda\n",
    "\n",
    "def poisson_readcounts(gt, mean_rc, output=True):\n",
    "    \"\"\"Create and return Poisson Readcount array.\n",
    "    gt: Underlying Genotype Matrix [l, n, 2]\n",
    "    mean_rc: Mean Readcount Vector\"\"\"\n",
    "    l, n, _ = np.shape(gt)\n",
    "    rc_tot = np.random.poisson(lam=mean_rc, size = (l,n))  # Draw Full Readcounts\n",
    "\n",
    "    p = np.mean(gt, axis=2) # Get the Mean Allele Frequency per locus and individual\n",
    "    assert(np.max(p)<=1) ### Sanity Check whether allele freqs are right\n",
    "    assert(np.min(p)>=0)\n",
    "\n",
    "    rc_der = np.random.binomial(n=rc_tot, p=p)  # The derived Readcount (Binomial Sampling)\n",
    "    rc_ref = rc_tot - rc_der  # The Ref Readcount\n",
    "\n",
    "    rc_full = np.stack([rc_ref, rc_der], axis=2)\n",
    "    assert(np.shape(rc_full) == np.shape(gt))  # CHeck whether data was created properly\n",
    "\n",
    "    if output == True:\n",
    "        print(f\"Mean Readcount: {np.mean(rc_tot):.4f}\")\n",
    "    \n",
    "    return rc_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data hdf5s with various levels of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Error Frac: 0.001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.000995\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/001/data.h5\n",
      "Doing Error Frac: 0.0019306977288832496\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001930\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0019/data.h5\n",
      "Doing Error Frac: 0.003727593720314938\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.003720\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0037/data.h5\n",
      "Doing Error Frac: 0.0071968567300115215\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.007202\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0072/data.h5\n",
      "Doing Error Frac: 0.013894954943731374\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.013919\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0139/data.h5\n",
      "Doing Error Frac: 0.026826957952797246\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.026827\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0268/data.h5\n",
      "Doing Error Frac: 0.0517947467923121\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.051829\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0518/data.h5\n",
      "Doing Error Frac: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.100071\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/1/data.h5\n",
      "Doing Error Frac: 0.001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.000997\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/001/data.h5\n",
      "Doing Error Frac: 0.0019306977288832496\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001934\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0019/data.h5\n",
      "Doing Error Frac: 0.003727593720314938\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.003734\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0037/data.h5\n",
      "Doing Error Frac: 0.0071968567300115215\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.007216\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0072/data.h5\n",
      "Doing Error Frac: 0.013894954943731374\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.013894\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0139/data.h5\n",
      "Doing Error Frac: 0.026826957952797246\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.026819\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0268/data.h5\n",
      "Doing Error Frac: 0.0517947467923121\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.051788\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0518/data.h5\n",
      "Doing Error Frac: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.100087\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/1/data.h5\n",
      "Doing Error Frac: 0.001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.000996\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/001/data.h5\n",
      "Doing Error Frac: 0.0019306977288832496\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001928\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/0019/data.h5\n",
      "Doing Error Frac: 0.003727593720314938\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.003727\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/0037/data.h5\n",
      "Doing Error Frac: 0.0071968567300115215\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.007189\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/0072/data.h5\n",
      "Doing Error Frac: 0.013894954943731374\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.013909\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/0139/data.h5\n",
      "Doing Error Frac: 0.026826957952797246\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.026789\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/0268/data.h5\n",
      "Doing Error Frac: 0.0517947467923121\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.051761\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/0518/data.h5\n",
      "Doing Error Frac: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.099903\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/error/1/data.h5\n",
      "Doing Error Frac: 0.001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001010\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/001/data.h5\n",
      "Doing Error Frac: 0.0019306977288832496\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001931\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/0019/data.h5\n",
      "Doing Error Frac: 0.003727593720314938\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.003738\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/0037/data.h5\n",
      "Doing Error Frac: 0.0071968567300115215\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.007220\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/0072/data.h5\n",
      "Doing Error Frac: 0.013894954943731374\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.013887\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/0139/data.h5\n",
      "Doing Error Frac: 0.026826957952797246\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.026838\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/0268/data.h5\n",
      "Doing Error Frac: 0.0517947467923121\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.051753\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/0518/data.h5\n",
      "Doing Error Frac: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.099921\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/error/1/data.h5\n",
      "Doing Error Frac: 0.001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.000994\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/001/data.h5\n",
      "Doing Error Frac: 0.0019306977288832496\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001927\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/0019/data.h5\n",
      "Doing Error Frac: 0.003727593720314938\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.003718\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/0037/data.h5\n",
      "Doing Error Frac: 0.0071968567300115215\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.007184\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/0072/data.h5\n",
      "Doing Error Frac: 0.013894954943731374\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.013973\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/0139/data.h5\n",
      "Doing Error Frac: 0.026826957952797246\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.026892\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/0268/data.h5\n",
      "Doing Error Frac: 0.0517947467923121\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.051796\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/0518/data.h5\n",
      "Doing Error Frac: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.100099\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/error/1/data.h5\n",
      "Doing Error Frac: 0.001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.000995\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/001/data.h5\n",
      "Doing Error Frac: 0.0019306977288832496\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.001921\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/0019/data.h5\n",
      "Doing Error Frac: 0.003727593720314938\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.003759\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/0037/data.h5\n",
      "Doing Error Frac: 0.0071968567300115215\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.007220\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/0072/data.h5\n",
      "Doing Error Frac: 0.013894954943731374\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.013928\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/0139/data.h5\n",
      "Doing Error Frac: 0.026826957952797246\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.026693\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/0268/data.h5\n",
      "Doing Error Frac: 0.0517947467923121\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.051701\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/0518/data.h5\n",
      "Doing Error Frac: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Swapping frac of SNPs: 0.099886\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/error/1/data.h5\n"
     ]
    }
   ],
   "source": [
    "error_vec = np.logspace(-3,-1, 8)\n",
    "org_folder = \"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "lengths = [0, 2, 4, 6, 8, 10]\n",
    "\n",
    "for l in lengths:\n",
    "    for e in error_vec:\n",
    "        print(f\"Doing Error Frac: {e}\")\n",
    "        org_folder1 = org_folder + \"ch3_\" + str(l) + \"cm/\"\n",
    "        load_path = org_folder1 + \"data.h5\" \n",
    "        \n",
    "        e_print = str(round(e, 4)).split(\".\")[1] # Extract four digits after decimal\n",
    "        \n",
    "        ### To do save 4 digits error data file\n",
    "        save_path = org_folder1 + \"error/\" + e_print + \"/data.h5\"   \n",
    "        \n",
    "        # Make Directory if not already there\n",
    "        if not os.path.exists(os.path.dirname(save_path)):   \n",
    "            os.makedirs(os.path.dirname(save_path))\n",
    "        \n",
    "        #os.remove(save_path)  # For previous whoopsie\n",
    "        m = ModifyHDF5Genotypes(original_path=load_path, save_path=save_path)\n",
    "            \n",
    "        m.create_error_gt(freq_flips=e)\n",
    "        m.copy_rohinfo()   # Copy the ROH Info!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data hdf5s with various levels of missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Missing Fraction: 0.1\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.099959\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/1/data.h5\n",
      "Doing Missing Fraction: 0.2\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.200703\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/2/data.h5\n",
      "Doing Missing Fraction: 0.30000000000000004\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.304178\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/3/data.h5\n",
      "Doing Missing Fraction: 0.4\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.403428\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/4/data.h5\n",
      "Doing Missing Fraction: 0.5\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.500013\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/5/data.h5\n",
      "Doing Missing Fraction: 0.6\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.600860\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/6/data.h5\n",
      "Doing Missing Fraction: 0.7000000000000001\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.699016\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/7/data.h5\n",
      "Doing Missing Fraction: 0.8\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.795949\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/8/data.h5\n",
      "Doing Missing Fraction: 0.9\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 0.899114\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/9/data.h5\n",
      "Doing Missing Fraction: 1.0\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Fraction Loci surviving 1.000000\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/CHB/ch3_0cm/missing/0/data.h5\n"
     ]
    }
   ],
   "source": [
    "missing_vec = np.linspace(0.1, 1.0, 10)\n",
    "#missing_vec = np.linspace(0.3, 1.0, 8)\n",
    "#missing_vec = np.array([0.1, 0.2])\n",
    "org_folder = \"./Simulated/1000G_Mosaic/CHB/\"\n",
    "#lengths = [2, 4, 6, 8, 10]\n",
    "lengths = [0,]\n",
    "\n",
    "for l in lengths:\n",
    "    for m in missing_vec:\n",
    "        print(f\"Doing Missing Fraction: {m}\")\n",
    "        org_folder1 = org_folder + \"ch3_\" + str(l) + \"cm/\"\n",
    "        load_path = org_folder1 + \"data.h5\" \n",
    "        \n",
    "        m_print = str(round(m, 4)).split(\".\")[1] # Extract four digits after decimal\n",
    "        \n",
    "        ### To do save 4 digits error data file\n",
    "        save_path = org_folder1 + \"missing/\" + m_print + \"/data.h5\"   \n",
    "        \n",
    "        # Make Directory if not already there\n",
    "        if not os.path.exists(os.path.dirname(save_path)):   \n",
    "            os.makedirs(os.path.dirname(save_path))\n",
    "        \n",
    "        #os.remove(save_path)  # For previous whoopsie\n",
    "        modh5 = ModifyHDF5Genotypes(original_path=load_path, save_path=save_path)\n",
    "            \n",
    "        modh5.downsample_gt(frac=m)\n",
    "        modh5.copy_rohinfo()   # Copy the ROH Info!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data hdf5s with Readcounts around Poisson mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisson_mean_hdf5s(lengths, mean_rcs, org_folder=\"./Simulated/1000G_Mosaic/TSI5/\", output=False):\n",
    "    \"\"\"Create Downsampled HDF5s with Poisson Mean Readcount Data.\n",
    "    lengths: Block Lengths Array [in CM]\n",
    "    mean_rcs: Mean Readcount Array\n",
    "    org_folder: The original Folder\"\"\" \n",
    "\n",
    "    for mean_rc in mean_rcs:\n",
    "        print(f\"Simulating Mean RC: {mean_rc}x \")\n",
    "        for l in lengths:\n",
    "            print(f\"Doing block length: {l} cM\")\n",
    "            original_path = org_folder + \"ch3_\" + str(l) + \"cm/data.h5\"\n",
    "            #save_path = org_folder + \"rc\" + str(mean_rc) + \"/ch3_\" + str(l) + \"cm/data.h5\"\n",
    "            save_path = org_folder + \"lambda_rc\" + str(mean_rc) + \"/ch3_\" + str(l) + \"cm/data.h5\"\n",
    "\n",
    "            if not os.path.exists(os.path.dirname(save_path)):   \n",
    "                print(f\"Creating DIR: {save_path}\")\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "            m = ModifyHDF5Genotypes(original_path = original_path, save_path = save_path, output=output)\n",
    "            #m.generate_binomial_rc(mean_rc = mean_rc)\n",
    "            m.generate_lambda_rc(mean_rc = mean_rc)\n",
    "            m.copy_rohinfo()\n",
    "\n",
    "    print(\"Once more: Finished the Job.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating Mean RC: 0.1x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.1/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.1/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.1/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.1/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.1/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.1/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.2x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.2/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.2/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.2/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.2/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.2/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.2/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.30000000000000004x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.30000000000000004/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.30000000000000004/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.30000000000000004/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.30000000000000004/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.30000000000000004/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.30000000000000004/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.4x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.4/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.4/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.4/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.4/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.4/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.4/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.5x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.5/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.5/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.5/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.5/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.5/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.5/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.6x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.7000000000000001x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.8x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.8/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.8/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.8/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.8/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.8/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.8/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 0.9x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.9/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.9/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.9/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.9/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.9/ch3_8cm/data.h5\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.9/ch3_10cm/data.h5\n",
      "Simulating Mean RC: 1.0x \n",
      "Doing block length: 0 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_0cm/data.h5\n",
      "Doing block length: 2 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_2cm/data.h5\n",
      "Doing block length: 4 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/data.h5\n",
      "Doing block length: 6 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_6cm/data.h5\n",
      "Doing block length: 8 cM\n",
      "Doing block length: 10 cM\n",
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_10cm/data.h5\n",
      "Once more: Finished the Job.\n"
     ]
    }
   ],
   "source": [
    "lengths = [0, 2, 4, 6, 8, 10] # The Block Lengths to simulate\n",
    "mean_rcs = np.linspace(0.1, 1, 10)\n",
    "#lengths =[8]\n",
    "#mean_rcs = [1.]\n",
    "\n",
    "org_folder = \"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "create_poisson_mean_hdf5s(lengths=lengths, mean_rcs=mean_rcs, org_folder=org_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_2cm/roh_info.csv\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_2cm/roh_info.csv\n"
     ]
    }
   ],
   "source": [
    "m = ModifyHDF5Genotypes(original_path=\"./Simulated/1000G_Mosaic/TSI5/ch3_2cm/data.h5\", save_path=\"./Simulated/1000G_Mosaic/TSI5/ch3_2cm/data_shitty.h5\")\n",
    "#m.downsample_gt(frac=0.8)\n",
    "#m.create_error_gt(freq_flips=0.01)\n",
    "m.copy_rohinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Readcount Data from Genotype Data: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DIR: ./Simulated/1000G_Mosaic/TSI5/rc/ch3_4cm/data.h5\n",
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Mean Readcount: 2.0003\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/rc/ch3_4cm/data.h5\n"
     ]
    }
   ],
   "source": [
    "original_path=\"./Simulated/1000G_Mosaic/TSI5/ch3_4cm/data.h5\"\n",
    "save_path=\"./Simulated/1000G_Mosaic/TSI5/rc/ch3_4cm/data.h5\"\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.dirname(save_path)):   \n",
    "    print(f\"Creating DIR: {save_path}\")\n",
    "    os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "m = ModifyHDF5Genotypes(original_path = original_path, save_path = save_path)\n",
    "m.generate_binomial_rc(mean_rc=2)\n",
    "m.copy_rohinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Readcount Data from Genotypes Data: Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heyho back old friend. I started running\n",
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Extracted 81079 / 1145647 Loci on Chr.3\n",
      "Found 77650 / 77652 Loci in Lambda Table\n",
      "Mean Readcount: 1.9995\n",
      "Successfully saved 100 individuals to: ./Simulated/1000G_Mosaic/TSI5/lambda_rc/ch3_4cm/data.h5\n"
     ]
    }
   ],
   "source": [
    "original_path=\"./Simulated/1000G_Mosaic/TSI5/ch3_4cm/data.h5\"\n",
    "save_path=\"./Simulated/1000G_Mosaic/TSI5/lambda_rc/ch3_4cm/data.h5\"\n",
    "\n",
    "if not os.path.exists(os.path.dirname(save_path)):   \n",
    "    print(f\"Creating DIR: {save_path}\")\n",
    "    os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "m = ModifyHDF5Genotypes(original_path = original_path, save_path = save_path)\n",
    "m.generate_lambda_rc(mean_rc = 2)\n",
    "m.copy_rohinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "#path = \"./Simulated/1000G_Mosaic/TSI5/rc0.2/ch3_4cm/data.h5\"\n",
    "path = \"./Simulated/1000G_Mosaic/TSI5/ch3_10cm/data.h5\"\n",
    "\n",
    "f = h5py.File(path, \"r\") # Load for Sanity Check. See below!\n",
    "        \n",
    "print(\"Loaded HDF5\")\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Lambda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 81079 / 1145647 Loci on Chr.3\n"
     ]
    }
   ],
   "source": [
    "ch=3\n",
    "loadpath = \"./Data/1000Genomes/Coverage/mean_cov1240k_Marcus.csv\"\n",
    "\n",
    "df_lambda = load_lambda(loadpath, ch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_f = f[\"variants/POS\"][:]\n",
    "_, i1, i2 = np.intersect1d(pos_f, df_lambda[\"Pos\"], return_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HDF5\n",
      "Loaded 77650 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "path = \"./Simulated/1000G_Mosaic/TSI5/lambda_rc/ch3_4cm/data.h5\"\n",
    "\n",
    "f = h5py.File(path, \"r\") # Load for Sanity Check. See below!\n",
    "        \n",
    "print(\"Loaded HDF5\")\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/AD\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/AD\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = f[\"calldata/AD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.375369456536567"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_cov = np.sum(ad, axis=2)\n",
    "np.var(tot_cov[:, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

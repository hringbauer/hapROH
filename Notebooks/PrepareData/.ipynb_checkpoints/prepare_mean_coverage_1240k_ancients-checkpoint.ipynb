{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare 1240k Coverage Means\n",
    "Calculate the Proportionality Factors for the 1240k SNPs.\n",
    "For this, load all the Sardinian ancients, and process them\n",
    "\n",
    "Save the resulting list as position of all Markers/REF/ALT/Mean_Coverage csv (with Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import socket\n",
    "import os as os\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"Run on Harald's laptop!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load ancient 1240k Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AD', 'GT']\n",
      "['AA', 'AF', 'AFR_AF', 'ALT', 'AMR_AF', 'CHROM', 'EAS_AF', 'EUR_AF', 'ID', 'POS', 'REF', 'SAS_AF']\n",
      "4616\n",
      "(1145647, 4616, 2)\n",
      "Nr Ancient Sardinians: 85\n",
      "Nr Ancient Samples: 1087\n"
     ]
    }
   ],
   "source": [
    "####### Load all the neccessary files\n",
    "### Set the right Paths\n",
    "ancsard_git_path = \"../../../ancient-sardinia/\"  # Where to find the Ancient-Sardinia git Folder\n",
    "\n",
    "h5path = ancsard_git_path + \"output/h5_rev/mod_reich_sardinia_ancients_rev_mrg_dedup_3trm_anno.h5\"\n",
    "meta_path = ancsard_git_path + \"output/meta/meta_rev_final.csv\"\n",
    "save_snp_inds_path = ancsard_git_path + \"output/snp_filter/snps_okay_ancients.npy\"\n",
    "save_params_path = ancsard_git_path + \"output/snp_filter/snps_filter_cutoffs.csv\"\n",
    "param_path = ancsard_git_path + \"data/meta/parameters/ancsard_params.csv\"\n",
    "\n",
    "#### Load the key Data\n",
    "f = h5py.File(h5path, \"r\") # Load for Sanity Check. See below!\n",
    "list(f.keys())\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))\n",
    "\n",
    "meta_df = pd.read_csv(meta_path)\n",
    "print(len(meta_df))\n",
    "print(np.shape(f[\"calldata/GT\"]))\n",
    "\n",
    "assert(len(meta_df)==np.shape(f[\"calldata/GT\"])[1])\n",
    "\n",
    "#######################################################\n",
    "################################### Load the Parameters\n",
    "df_prs = pd.read_csv(param_path)\n",
    "anc_sardind = df_prs[\"n_ancsard\"][0]     # The highest ancsard index\n",
    "anc_ind = df_prs[\"n_anc\"][0]\n",
    "\n",
    "print(f\"Nr Ancient Sardinians: {anc_sardind}\")\n",
    "print(f\"Nr Ancient Samples: {anc_ind}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Mean Coverage per Locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_avg_depths(f, anc_ind, add_ancients=30):\n",
    "    \"\"\"f HDF5. anc_ind: Number of all ancient Individuals.\n",
    "    add_ancients: Number of African ancient individuals \n",
    "    (which have slightly different Coverage)\"\"\"\n",
    "\n",
    "    gt = f[\"calldata/AD\"]    # Load the Genotypes\n",
    "    gt_depth = np.mean(gt[:,:(anc_ind-add_ancients),:], axis=1)  # Calculate mean Read Depth per Site [l,2] Array\n",
    "    gt_depthboth = np.mean(gt_depth, axis=1)  # The mean Depth over both Haplotypes\n",
    "\n",
    "    ### Cut out the not covered markers\n",
    "    depth_neg = gt_depthboth < 0\n",
    "    #iid_neg = np.where(depth_neg)[0]\n",
    "    #gt_depthboth[depth_neg] Is all -1\n",
    "    depths = gt_depthboth[~depth_neg]\n",
    "    return depths, ~depth_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1144809 Loci Coverages\n",
      "CPU times: user 33.7 s, sys: 1.61 s, total: 35.3 s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "depths, depth_idcs = give_avg_depths(f, anc_ind)\n",
    "print(f\"Loaded {np.sum(depth_idcs)} Loci Coverages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the Data Table and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_depths = np.zeros(len(depth_idcs))  # Initialize the Coverages\n",
    "all_depths[depth_idcs] = depths         # Set the Depths that worked (the rest remains 0)\n",
    "norm_depths = all_depths / np.mean(all_depths)   # Normalize to get proportionality constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = f[\"variants/POS\"]\n",
    "refs = f[\"variants/REF\"]\n",
    "alts =  f[\"variants/ALT\"]\n",
    "ch = f[\"variants/CHROM\"]\n",
    "\n",
    "df = pd.DataFrame({\"Pos\":pos, \"Alt\":alts, \"Ref\" : refs, \"Lambda\" : norm_depths, \"Ch\": ch})\n",
    "#df[\"Ch\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to ../../Data/1000Genomes/Coverage/mean_cov1240k_Marcus.csv\n"
     ]
    }
   ],
   "source": [
    "### Save the Dataframe\n",
    "savepath = \"../../Data/1000Genomes/Coverage/mean_cov1240k_Marcus.csv\"  # Where to save the df to\n",
    "\n",
    "### Prepare the Folder\n",
    "savefolder = os.path.dirname(savepath)\n",
    "if not os.path.exists(savefolder):\n",
    "    print(f\"Creating new path: {savefolder}\")\n",
    "    os.makedirs(savefolder)\n",
    "\n",
    "df.to_csv(savepath, index=False)\n",
    "print(f\"Successfully saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6685279563213835"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(df[\"Lambda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

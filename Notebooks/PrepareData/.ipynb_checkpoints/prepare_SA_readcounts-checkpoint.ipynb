{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Readcount Data I got from David for the South Americans\n",
    "@ Author: Harald Ringbauer, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0401.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import h5py  # Python Package to do the HDF5.\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_rc(path_ind = \"../fromDavid/MA577_1240k_all.cnts\"):\n",
    "    path_ind = \"../fromDavid/MA577_1240k_all.cnts\"\n",
    "    df_rc = pd.read_csv(path_ind, header=None, sep=\" \")\n",
    "    df_rc.columns=[\"chr\",\"pos\", \"ref\", \"alt\", \"A\", \"G\", \"C\", \"T\"]\n",
    "    print(f\"Loaded {len(df_rc)} Markers\")\n",
    "    return df_rc\n",
    "\n",
    "def creat_count_col(df_rc):\n",
    "    \"\"\"Add Fields for ref and alt Count\"\"\"\n",
    "    df_rc[\"ref_count\"]=0\n",
    "    df_rc[\"alt_count\"]=0\n",
    "\n",
    "    for a in [\"A\", \"G\", \"C\", \"T\"]:\n",
    "        idcs = df_rc[\"ref\"]==a\n",
    "        df_rc.loc[idcs,\"ref_count\"]=df_rc[a]\n",
    "\n",
    "        idcs = df_rc[\"alt\"]==a\n",
    "        df_rc.loc[idcs,\"alt_count\"]=df_rc[a]\n",
    "    return df_rc\n",
    "\n",
    "def save_hdf5(gt, ad, ref, alt, pos, ch, samples, path):\n",
    "    \"\"\"Create a new HDF5 File with Input Data.\n",
    "    gt: Genotype data [l,k,2]\n",
    "    ad: Allele depth [l,k,2]\n",
    "    ref: Reference Allele [l]\n",
    "    alt: Alternate Allele [l]\n",
    "    pos: Position  [l]\n",
    "    m: Map position [l]\n",
    "    ch: Which chromosome [l]\n",
    "    samples: Sample IDs [k]\"\"\"\n",
    "\n",
    "    l, k, _ = np.shape(gt)  # Nr loci and Nr of Individuals\n",
    "\n",
    "    if os.path.exists(path):  ### Do a Deletion of existing File there\n",
    "        os.remove(path)\n",
    "\n",
    "    dt = h5py.special_dtype(vlen=str)  # To have no problem with saving\n",
    "\n",
    "    with h5py.File(path, 'w') as f0:\n",
    "        ### Create all the Groups\n",
    "        #f_map = f0.create_dataset(\"variants/MAP\", (l,), dtype='f')\n",
    "        f_ch = f0.create_dataset(\"variants/CHROM\", (l,), dtype='i')\n",
    "        f_ad = f0.create_dataset(\"calldata/AD\", (l, k, 2), dtype='i')\n",
    "        f_ref = f0.create_dataset(\"variants/REF\", (l,), dtype=dt)\n",
    "        f_alt = f0.create_dataset(\"variants/ALT\", (l,), dtype=dt)\n",
    "        f_pos = f0.create_dataset(\"variants/POS\", (l,), dtype='i')\n",
    "        f_gt = f0.create_dataset(\"calldata/GT\", (l, k, 2), dtype='i')\n",
    "        f_samples = f0.create_dataset(\"samples\", (k,), dtype=dt)\n",
    "\n",
    "        ### Save the Data\n",
    "        #f_map[:] = rec\n",
    "        f_ch[:] = ch\n",
    "        f_ad[:] = ad\n",
    "        f_ref[:] = ref.astype(\"S1\")\n",
    "        f_alt[:] = alt.astype(\"S1\")\n",
    "        f_pos[:] = pos\n",
    "        f_gt[:] = gt\n",
    "        f_samples[:] = np.array(samples).astype(\"S10\")\n",
    "\n",
    "    print(f\"Successfully saved {k} individuals to: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do single Indivudal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_to_hdf_1ind(path_ind, path_h5=\"./Data/SA_1240kHDF5/MA577_1240k.h5\", iid=\"MA577_1240k\"):\n",
    "    \"\"\"Produce HDF5 File from Readcount Data\"\"\"\n",
    "    df_rc= get_df_from_rc(path_ind=\"../fromDavid/MA577_1240k_all.cnts\")\n",
    "    df_rc = creat_count_col(df_rc)\n",
    "    l = len(df_rc)\n",
    "    k = 1\n",
    "\n",
    "    ###\n",
    "    gt = -np.ones((l,k,2), dtype=\"int8\") # No genotypes\n",
    "    ad = df_rc[[\"ref_count\", \"alt_count\"]].values[:,None,:] # None for n=1 axis\n",
    "    ref = df_rc[\"ref\"].values\n",
    "    alt = df_rc[\"alt\"].values\n",
    "    pos = df_rc[\"pos\"].values\n",
    "    ch = df_rc[\"chr\"].values\n",
    "    samples=[iid,]\n",
    "\n",
    "    save_hdf5(gt, ad, ref, alt, pos, ch, samples, path_h5)\n",
    "    print(f\"Successfully saved to {path_h5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do multiple individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_to_hdf_mul_ind(base_folder, iids, path_hdf5):\n",
    "    \"\"\"Create HDF5s with Readcounts from multiple Individuals\"\"\"\n",
    "    ### Same as for 1 Individual, but as a Loop\n",
    "    paths = [os.path.join(base_folder, iid + \"_1240k_all.cnts\") for iid in iids]\n",
    "    df_rcs = [get_df_from_rc(path_ind=p) for p in paths]\n",
    "    df_rcs = [creat_count_col(df_rc) for df_rc in df_rcs]\n",
    "\n",
    "    ### Sanity Check if all Datasets are identical\n",
    "    lens = [len(df_rc) for df_rc in df_rcs]\n",
    "    assert(len(set(lens))==1) \n",
    "\n",
    "    ### Get Fields that are same for all Individuals (i.e. Array)\n",
    "    df_rc = df_rcs[0]\n",
    "    ref = df_rc[\"ref\"].values\n",
    "    alt = df_rc[\"alt\"].values\n",
    "    pos = df_rc[\"pos\"].values\n",
    "    ch = df_rc[\"chr\"].values\n",
    "\n",
    "    # Get Fields that are a matrix\n",
    "    l = len(df_rc)\n",
    "    k = len(df_rcs)\n",
    "    gt = -np.ones((l, k, 2), dtype=\"int8\") # No genotypes filled in!\n",
    "\n",
    "    ad = [df_rc[[\"ref_count\", \"alt_count\"]].values for df_rc in df_rcs]   # None for n=1 axis\n",
    "    ad = np.stack(ad, axis=1)          # Combine the allele Depths (along axis 1 for individuals)\n",
    "    assert(np.shape(ad)==np.shape(gt)) # Sanity Check\n",
    "    save_hdf5(gt, ad, ref, alt, pos, ch, iids, path_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 907683 Markers\n",
      "Loaded 907683 Markers\n",
      "Loaded 907683 Markers\n",
      "Loaded 907683 Markers\n",
      "Loaded 907683 Markers\n",
      "Successfully saved 5 individuals to: ./Data/SA_1240kHDF5/SA_inds_5.h5\n"
     ]
    }
   ],
   "source": [
    "### Run for the first 5 Individuals\n",
    "rc_to_hdf_mul_ind(base_folder=\"../fromDavid/\", iids=[\"IPY10\", \"IPK12\", \"MA577\", \"894\", \"895\"], \n",
    "                  path_hdf5=\"./Data/SA_1240kHDF5/SA_inds_5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HDF5\n",
      "Loaded 907683 variants\n",
      "Loaded 5 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'CHROM', 'POS', 'REF']\n"
     ]
    }
   ],
   "source": [
    "path_load = \"./Data/SA_1240kHDF5/SA_inds_5.h5\"\n",
    "f = h5py.File(path_load, \"r\") # Load for Sanity Check. See below!\n",
    "        \n",
    "print(\"Loaded HDF5\")\n",
    "print(\"Loaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "print(list(f[\"calldata\"].keys()))\n",
    "print(list(f[\"variants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(907683, 5, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(f[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3],\n",
       "       [ 1,  0],\n",
       "       [ 1,  0],\n",
       "       [ 4,  0],\n",
       "       [ 6,  0],\n",
       "       [ 0,  2],\n",
       "       [ 0,  6],\n",
       "       [ 3,  0],\n",
       "       [ 0,  8],\n",
       "       [ 0, 14]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"calldata/AD\"][:10,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     77218\n",
       "1     74716\n",
       "3     63082\n",
       "6     61135\n",
       "5     56089\n",
       "4     53931\n",
       "8     49916\n",
       "10    49208\n",
       "7     48464\n",
       "11    45757\n",
       "12    44218\n",
       "9     41707\n",
       "13    30798\n",
       "16    29942\n",
       "14    29933\n",
       "15    29024\n",
       "18    27515\n",
       "17    25846\n",
       "20    25154\n",
       "19    16650\n",
       "22    14323\n",
       "21    13057\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(f[\"variants\"][\"CHROM\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(f[\"samples\"][:]==\"MA577_1240\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid=\"MA577_1240\"\n",
    "\n",
    "samples = f[\"samples\"][:]\n",
    "assert(len(samples) == np.shape(f[\"calldata/GT\"])[1])  # Sanity Check\n",
    "\n",
    "id_obs = np.where(samples == iid)[0]\n",
    "if len(id_obs) == 0:\n",
    "    raise RuntimeError(f\"Individual {iid} not found in Samples Field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IPY10', 'IPK12', 'MA577', '894', '895'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"samples\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'IPY10', 'IPK12', 'MA577', '894', '895'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

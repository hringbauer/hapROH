{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Sardinian Autosomes\n",
    "Also scan for stretches of Homoyzgotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os   # For creating folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some Helper Functions\n",
    "# The same as over in prepare_Sardinian_X (or very similar)\n",
    "\n",
    "def load_h5(path):\n",
    "    \"\"\"Load and return the HDF5 File from Path\"\"\"\n",
    "    f = h5py.File(path, \"r\") # Load for Sanity Check. See below!\n",
    "    print(\"\\nLoaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "    print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "    print(list(f[\"calldata\"].keys()))\n",
    "    print(list(f[\"variants\"].keys()))\n",
    "    print(f\"HDF5 loaded from {path}\")\n",
    "    return f\n",
    "\n",
    "def merge_2hdf(f, g, ch=1):\n",
    "    \"\"\" Merge two HDF 5 f and g. Return Indices of Overlap Individuals.\n",
    "    f is Sardinian HDF5, \n",
    "    g the Reference HDF5\n",
    "    ch: Integer, which Chromosome to use\"\"\"\n",
    "    \n",
    "    pos1 = f[\"variants/POS\"]\n",
    "    pos2 = g[\"variants/POS\"]\n",
    "\n",
    "    ### Check if in both Datasets\n",
    "    b, i1, i2 = np.intersect1d(pos1, pos2, return_indices=True)\n",
    "\n",
    "    print(f\"\\nIntersection on Positions: {len(b)}\")\n",
    "\n",
    "    ### Sanity Check if Reference is the same\n",
    "    ref1 = np.array(f[\"variants/REF\"])[i1]\n",
    "    ref2 = np.array(f1000[\"variants/REF\"])[i2]\n",
    "\n",
    "    alt1 = np.array(np.array(f[\"variants/ALT\"])[i1])\n",
    "    alt2 = np.array(np.array(f1000[\"variants/ALT\"])[i2,0])\n",
    "\n",
    "    ### Downsample to Site where both Ref and Alt are the same\n",
    "    same = (ref1 == ref2)\n",
    "    print(f\"Nr of Matching Refs: {np.sum(same)} / {len(same)}\")\n",
    "\n",
    "    both_same = (ref1 == ref2) & (alt1 == alt2)\n",
    "    i11 = i1[both_same]\n",
    "    i22 = i2[both_same]\n",
    "\n",
    "    print(f\"Full Intersection Ref/Alt Identical: {len(i11)} / {len(both_same)}\")\n",
    "    return i11, i22\n",
    "\n",
    "\n",
    "def save_refs(gts, folder, cm_map, gt_individual=[]):\n",
    "    \"\"\"Save Sardinian references\n",
    "    ids: Which individuals\n",
    "    markers: Which markers\n",
    "    folders: Into which folder\n",
    "    Genotypes Individual: If given, save as well\"\"\"\n",
    "    print(f\"Nr of Markers used: {np.shape(gts)[1]}\") # Notice that 1 and 0 Dim. are shifted!\n",
    "    print(f\"Nr of individuals saved: {np.shape(gts)[0]}\")\n",
    "\n",
    "    assert(len(gt_individual)==2) # Sanity Check\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "            \n",
    "    np.savetxt(folder + \"refs.csv\", gts,\n",
    "                       delimiter=\",\",  fmt='%i')  # Save Reference Haplotypes\n",
    "\n",
    "    ### Save which individuals and markers\n",
    "    np.savetxt(folder + \"refs.csv\", gts, \n",
    "                       delimiter=\",\",  fmt='%i')\n",
    "    \n",
    "    ### Save the cmap \n",
    "    np.savetxt(folder + \"map.csv\", cm_map, delimiter=\",\",  fmt='%.8f')\n",
    "    \n",
    "    if len(gt_individual)>0:\n",
    "            np.savetxt(folder + \"hap.csv\", gt_individual, \n",
    "                       delimiter=\",\",  fmt='%i')\n",
    "    print(f\"Successfully saved to {folder}\")\n",
    "\n",
    "#######################################\n",
    "### Code for saving Haplo\n",
    "def save_haplo(folder, ref_hdf5, obs_hdf5, ids_ref, id_obs, \n",
    "               marker_ref, marker_obs, r_map, error_rate=0, only_calls=True):\n",
    "    \"\"\"Save Folder with all relevant Information.\n",
    "    Folder: Where to save to\n",
    "    ref_hdf5: Reference HDF5\n",
    "    obs_hdf5: Observed HDF5\n",
    "    ids_ref: Indices of reference Individuals to save\n",
    "    ids_obs: Indices of observed Individuals\n",
    "    marker_ref: Indices of reference Markers\n",
    "    marker_obs: Indices of observed Markers\n",
    "    error_rate: Whether to Include an Error Rate\n",
    "    only_calls: Whether to Only Include Markers with Calls\"\"\"\n",
    "    assert(len(marker_ref)==len(marker_obs))  # If reference and observe dataset are the same\n",
    "    assert(len(marker_ref)==len(r_map))  # If Linkage Map fits as well\n",
    "    \n",
    "\n",
    "    gts = ref_hdf5[\"calldata/GT\"][:, ids_ref, 0] # Extract Individuals (first haplo)\n",
    "    gts = gts[marker_ref, :].T       # Important: Swap of Dimensions!!\n",
    "    print(\"Extraction Complete!\")\n",
    "\n",
    "    gts_ind = obs_hdf5[\"calldata/GT\"][:, id_obs, :] # Extract Individuals (first haplo)\n",
    "    gts_ind = gts_ind[marker_obs, :].T \n",
    "\n",
    "    if only_calls == True:\n",
    "        called = (gts_ind[0, :] > -1)  # Only Markers with calls\n",
    "        print(f\"Markers called {np.sum(called)} / {len(called)}\")\n",
    "        gts_ind = gts_ind[:, called]\n",
    "        gts = gts[:, called]\n",
    "        r_map = r_map[called]\n",
    "        \n",
    "    if error_rate>0:    # Do some Error Shennenigans\n",
    "        e_ids = np.random.binomial(1, error_rate, \n",
    "                                    size=np.shape(gts_ind)).astype(\"bool\") # Boolean Sample Vector\n",
    "        print(f\"Introducing {np.sum(e_ids)} Random Genotype Errors\")\n",
    "        gts_ind[e_ids] = 1 - gts_ind[e_ids] # Do a Flip\n",
    "    \n",
    "    save_refs(gts, folder, r_map, gt_individual=gts_ind)\n",
    "    \n",
    "    np.savetxt(folder + \"ind.csv\", [id_obs], delimiter=\",\",  fmt='%i')   # Save which Individuals were used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 1149314 variants\n",
      "Loaded 4558 individuals\n",
      "['AD', 'GT']\n",
      "['AA', 'AF', 'AFR_AF', 'ALT', 'AMR_AF', 'CHROM', 'EAS_AF', 'EUR_AF', 'ID', 'MAP', 'POS', 'REF', 'SAS_AF']\n",
      "HDF5 loaded from ../../ancient-sardinia/output/h5/mod_reich_sardinia_ancients_mrg_dedup_3trm_anno.h5\n",
      "\n",
      "Loaded 34431 variants\n",
      "Loaded 503 individuals\n",
      "['GT']\n",
      "['ALT', 'CHROM', 'FILTER_PASS', 'ID', 'MAP', 'POS', 'QUAL', 'REF']\n",
      "HDF5 loaded from ../Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr15.hdf5\n",
      "\n",
      "Intersection on Positions: 34427\n",
      "Nr of Matching Refs: 34284 / 34427\n",
      "Full Intersection Ref/Alt Identical: 34247 / 34427\n"
     ]
    }
   ],
   "source": [
    "ch = 15        # Which Chromosome to analyze\n",
    "h5_path_sard = \"../../ancient-sardinia/output/h5/mod_reich_sardinia_ancients_mrg_dedup_3trm_anno.h5\"\n",
    "h5_path1000g = \"../Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr\" + str(ch) + \".hdf5\"\n",
    "\n",
    "meta_path = \"../../ancient-sardinia/output/meta/meta_final.csv\"\n",
    "\n",
    "fs = load_h5(h5_path_sard)\n",
    "f1000 = load_h5(h5_path1000g)\n",
    "i1, i2 = merge_2hdf(fs, f1000)\n",
    "\n",
    "meta_df = pd.read_csv(meta_path)\n",
    "assert(len(meta_df)==np.shape(fs[\"calldata/GT\"])[1])  # Sanity Check\n",
    "#map_pos, cm_map = get_rmap1240k(f1000, snp_ids=i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Sardinian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Complete!\n",
      "Markers called 13573 / 28863\n",
      "Nr of Markers used: 13573\n",
      "Nr of individuals saved: 503\n",
      "Successfully saved to ../Empirical/Sard_Chr20_1000G_ROH2/\n"
     ]
    }
   ],
   "source": [
    "folder = \"../Empirical/Sard_Chr20_1000G_ROH2/\"         # Which folder to save into\n",
    "id_obs = 3043\n",
    "ids_ref = np.arange(503)  # All 503 EUR Samples as Reference (first Chromosome)\n",
    "markers = np.arange(0, 28863) # Which Markers to Slice out\n",
    "\n",
    "### Do Downsampling if needed\n",
    "#sample = np.random.binomial(1, 0.5, size=len(markers)).astype(\"bool\") # Boolean Sample Vector\n",
    "#markers = markers[sample]\n",
    "markers_obs = i1[markers]\n",
    "markers_ref = i2[markers]\n",
    "\n",
    "r_map = np.array(f1000[\"variants/MAP\"])[markers]\n",
    "\n",
    "save_haplo(folder, f1000, fs, ids_ref, id_obs, \n",
    "               markers_ref, markers_obs, r_map, error_rate=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancient Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Complete!\n",
      "Markers called 17792 / 29247\n",
      "Nr of Markers used: 17792\n",
      "Nr of individuals saved: 503\n",
      "Successfully saved to ../Empirical/I0413_I0413_1000G_ROH/\n"
     ]
    }
   ],
   "source": [
    "iid = \"I0413\"\n",
    "\n",
    "folder  = \"../Empirical/I0413_I0413_1000G_ROH/\"  # Which folder to save into\n",
    "\n",
    "id_obs = np.where(meta_df[\"iid\"] == iid)[0][0]\n",
    "\n",
    "ids_ref = np.arange(503)  # All 503 EUR Samples as Reference (first Chromosome)\n",
    "markers = np.arange(5000, len(i1)) # Which Markers to Slice out\n",
    "\n",
    "### Do Downsampling if needed\n",
    "#sample = np.random.binomial(1, 0.5, size=len(markers)).astype(\"bool\") # Boolean Sample Vector\n",
    "#markers = markers[sample]\n",
    "markers_obs = i1[markers]\n",
    "markers_ref = i2[markers]\n",
    "\n",
    "r_map = np.array(f1000[\"variants/MAP\"])[markers]\n",
    "\n",
    "save_haplo(folder, f1000, fs, ids_ref, id_obs, \n",
    "               markers_ref, markers_obs, r_map, error_rate=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>label</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>x_contam</th>\n",
       "      <th>mt_contam</th>\n",
       "      <th>age</th>\n",
       "      <th>study</th>\n",
       "      <th>clst_alt</th>\n",
       "      <th>period_alt</th>\n",
       "      <th>include_alt</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>med_cov</th>\n",
       "      <th>n_cov_snp</th>\n",
       "      <th>full_iid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>I0413</td>\n",
       "      <td>Europe_EN</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7138.0</td>\n",
       "      <td>Lazaridis et al. 2016</td>\n",
       "      <td>Europe</td>\n",
       "      <td>EN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iberia-EN</td>\n",
       "      <td>1.729239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678257.0</td>\n",
       "      <td>I0413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        iid      label   lat  lon  x_contam  mt_contam     age  \\\n",
       "1002  I0413  Europe_EN  42.5  0.5       NaN        NaN  7138.0   \n",
       "\n",
       "                      study clst_alt period_alt  include_alt       clst  \\\n",
       "1002  Lazaridis et al. 2016   Europe         EN          1.0  Iberia-EN   \n",
       "\n",
       "      mean_cov  med_cov  n_cov_snp full_iid  \n",
       "1002  1.729239      1.0   678257.0    I0413  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[meta_df[\"iid\"] == \"I0413\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [-1, -1],\n",
       "       [ 1,  1],\n",
       "       [ 1,  1],\n",
       "       [-1, -1],\n",
       "       [ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [ 0,  0],\n",
       "       [ 1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(fs[\"calldata/GT\"][:20,10,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

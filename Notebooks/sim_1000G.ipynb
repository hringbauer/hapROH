{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate a 1000 Genome Individual.\n",
    "Idea: Create artifical Individual, that copies short diploid blocks, and sometimes haploid blocks\n",
    "Record the start and end position of these runs.\n",
    "\n",
    "Goal: Have a class in the end\n",
    "\n",
    "Author: Harald Ringbauer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load the data: All that is needed: Linkage Map as well as reference Haplotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py   # For Processing HDF5s\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5(path):\n",
    "        \"\"\"Load and return the HDF5 File from Path\"\"\"\n",
    "        f = h5py.File(path, \"r\")  # Load for Sanity Check. See below!\n",
    "        print(\"\\nLoaded %i variants\" % np.shape(f[\"calldata/GT\"])[0])\n",
    "        print(\"Loaded %i individuals\" % np.shape(f[\"calldata/GT\"])[1])\n",
    "        # print(list(f[\"calldata\"].keys()))\n",
    "        # print(list(f[\"variants\"].keys()))\n",
    "        print(f\"HDF5 loaded from {path}\")\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = str(3)  # Which Chromosome to analyze\n",
    "path1000G = \"../Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr\" + ch + \".hdf5\"  # Path of 1000G (without chromosome part)\n",
    "pop_path = \"../Data/1000Genomes/integrated_call_samples_v3.20130502.ALL.panel\" # Population Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 77658 variants\n",
      "Loaded 503 individuals\n",
      "HDF5 loaded from ../Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr3.hdf5\n",
      "(77658, 503, 2)\n",
      "Loaded 503 Population Data.\n"
     ]
    }
   ],
   "source": [
    "f = load_h5(path=path1000G)\n",
    "\n",
    "list(f.keys())\n",
    "list(f[\"variants\"])\n",
    "print(np.shape(f[\"calldata/GT\"]))\n",
    "\n",
    "### Load the Individual Names and merge in Population Data\n",
    "meta_df = pd.read_csv(pop_path, sep=\"\\t\")\n",
    "\n",
    "iids = np.array(f[\"samples\"]).astype(\"str\")\n",
    "iids0 = np.char.split(iids, sep ='_', maxsplit=1) \n",
    "iids0 = [i[0] for i in iids0]\n",
    "iid_df = pd.DataFrame({\"sample\":iids0})\n",
    "\n",
    "meta_df = pd.merge(iid_df, meta_df[[\"sample\", \"pop\", \"super_pop\"]], how=\"left\", on=\"sample\")\n",
    "\n",
    "assert(len(meta_df)==len(iids)) # Sanity Cehck\n",
    "print(f\"Loaded {np.shape(meta_df)[0]} Population Data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Copying matrix\n",
    "Imput: Only recombination Matrix\n",
    "IIDs: Which individuals to copy from\n",
    "\n",
    "Important parameters: Which individuals to copy from\n",
    "\n",
    "Chunk Lengths\n",
    "\n",
    "Beginning and end of ROH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create chunked Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunked_gts(f, chunk_length, iids):\n",
    "    \"\"\"Create Chunked indiviual from Genotype Matrix f.\n",
    "    Chunk_Lentgh: Length of the chunking\n",
    "    iids: The Individual IDs\"\"\"\n",
    "\n",
    "    k = len(iids) # Nr of Individuals to copy from\n",
    "    nr_loci, _, _ = np.shape(f[\"calldata/GT\"])\n",
    "\n",
    "    rec = np.array(f[\"variants/MAP\"]).astype(\"float\")  # Load Recombination Map in Morgan\n",
    "    ch_min, ch_max = np.min(rec)-1e-10, np.max(rec)\n",
    "\n",
    "    nr_chunks = np.ceil((ch_max - ch_min) / chunk_length).astype(\"int\")\n",
    "    copy_id = np.random.randint(k, size=nr_chunks)  # Create all copying indices\n",
    "\n",
    "    len_bins = np.arange(ch_min, ch_max, chunk_length)  # Create Length Bin Vector \n",
    "    len_bins = np.append(len_bins, ch_max)  # Append the last Value\n",
    "\n",
    "    print(\"Setting new Genotypes...\")\n",
    "      \n",
    "    gts_new = -np.ones((nr_loci, 2), dtype=\"int\") # Initialize with invalid Value\n",
    "\n",
    "    for i in range(len(len_bins)-1):  # Iterate over all Length Bins\n",
    "        c_min, c_max = len_bins[i], len_bins[i+1]\n",
    "\n",
    "        i_min, i_max = np.searchsorted(rec, [c_min, c_max])\n",
    "        #print((i_min, i_max))\n",
    "        ind = copy_id[i]\n",
    "        gts_new[i_min:i_max+1, 1] = f[\"calldata/GT\"][i_min:i_max+1, ind, 0]\n",
    "        gts_new[i_min:i_max+1, 0] = f[\"calldata/GT\"][i_min:i_max+1, ind, 1]  \n",
    "    print(\"Finished\")\n",
    "    \n",
    "    assert(nr_loci == len(rec)) # Sanity Check\n",
    "    assert(np.min(gts_new)>-1)  # Sanity Check    \n",
    "    return gts_new, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting new Genotypes...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "chunk_length = 0.005   # Chunk Length [in Morgan]\n",
    "iids = np.arange(100)\n",
    "\n",
    "gts_new, rec = create_chunked_gts(f, chunk_length, iids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Copy in ROH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations of ROH\n",
    "def copy_in_roh(f, gts, roh_begin, roh_end, id_copy):\n",
    "    \"\"\"Copy In ROH Block.\n",
    "    f: HDF where to copy from\n",
    "    gts: 2xn Matrix of Genotypes to copy ROH block in\n",
    "    id_copy: Integer Index of which Individual to copy from\n",
    "    roh_begin, roh_end: Start and End of Block to copy from [in Morgan].\n",
    "    Return: Genotype Matrix\"\"\"\n",
    "\n",
    "    rec = np.array(f[\"variants/MAP\"]).astype(\"float\")  # Load Recombination Map in Morgan\n",
    "    i_min, i_max = np.searchsorted(rec, [roh_begin, roh_end])  # Get the Indices where to begin and end ROH\n",
    "\n",
    "    print(f\"Copying in Block: {rec[i_min]:.4f}-{rec[i_max]:.4f} M\")\n",
    "    print(i_min)\n",
    "    \n",
    "    assert(np.shape(gts)[0] == len(rec)) # Sanity Check\n",
    "    \n",
    "    gts_copy = f[\"calldata/GT\"][i_min:i_max+1, id_copy, 1] # The Stretch to copy in\n",
    "    gts[i_min:i_max+1, :] = gts_copy[:, None] # Copy in the Stretch\n",
    "    \n",
    "    return gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying in Block: 0.5000-0.5502 M\n",
      "14427\n"
     ]
    }
   ],
   "source": [
    "roh_begin = 0.5 # Where to insert the ROH\n",
    "roh_end = 0.55\n",
    "id_copy = 101  # ID where to copy from\n",
    "\n",
    "gts_roh = copy_in_roh(f, gts_new, roh_begin, roh_end, id_copy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to real Individual\n",
    "Various Downsampling as well as error Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the artificial Individual\n",
    "\n",
    "### Create new HDF5\n",
    "\n",
    "\n",
    "### Fields that need to be saved:\n",
    "\"calldata/GT\"\n",
    "\"variants/POS\"\n",
    "\"variants/REF\"\n",
    "\"variants/ALT\"\n",
    "\"calldata/AD\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = h5py.File(\"mytestfile.hdf5\", \"w\")\n",
    "def save_hdf5(gt, ad, ref, alt, pos, m, samples, path):\n",
    "    \"\"\"Create a new HDF5 File with Input Data.\n",
    "    gt: Genotype data [l,k,2]\n",
    "    ad: Allele depth [l,k,2]\n",
    "    ref: Reference Allele [l]\n",
    "    alt: Alternate Allele [l]\n",
    "    pos: Position  [l]\n",
    "    m: Map position [l]\n",
    "    samples: Sample IDs [k]\"\"\"\n",
    "    \n",
    "    l, k, _ = np.shape(gt)  # Nr loci and Nr of Individuals\n",
    "    \n",
    "    # Do a Deletion of existing File there:\n",
    "    !rm $hdf5_save_path # Delete the old file which is there.\n",
    "    \n",
    "    dt = h5py.special_dtype(vlen=str)\n",
    "\n",
    "    with h5py.File(path, 'w') as f0:\n",
    "            ### Create all the Groups\n",
    "            f_map = f0.create_dataset(\"variants/MAP\", (l,), dtype='f')\n",
    "            f_ad = f0.create_dataset(\"calldata/AD\", (l, k, 2), dtype='i')\n",
    "            f_ref = f0.create_dataset(\"variants/REF\", (l,), dtype=dt)\n",
    "            f_alt = f0.create_dataset(\"variants/ALT\", (l,), dtype=dt) \n",
    "            f_pos = f0.create_dataset(\"variants/POS\", (l,), dtype='f')\n",
    "            f_gt = f0.create_dataset(\"calldata/GT\", (l, k, 2), dtype='i')\n",
    "            f_samples = f0.create_dataset(\"samples\", (k,), dtype=dt)\n",
    "            \n",
    "            ### Save the Data\n",
    "            f_map[:] = rec\n",
    "            f_ad[:] = ad\n",
    "            f_ref[:] = ref.astype(\"S1\")\n",
    "            f_alt[:] = alt.astype(\"S1\")\n",
    "            f_pos[:] = pos\n",
    "            f_gt[:] = gt\n",
    "            f_samples[:] = np.array(samples).astype(\"S10\")\n",
    "    \n",
    "    print(f\"Successfully save to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully save to: ../Simulated/1000G_Mosaic/Test/test.hdf5\n"
     ]
    }
   ],
   "source": [
    "### Create a new HDF5\n",
    "hdf5_save_path = \"../Simulated/1000G_Mosaic/Test/test.hdf5\"   ### Path for the New HDF to save to \n",
    "\n",
    "gt = gts_roh[:,None,:].astype(\"i\")\n",
    "ad = gts_roh[:,None,:].astype(\"i\")\n",
    "ref, alt = f[\"variants/REF\"], f[\"variants/ALT\"]\n",
    "pos = f[\"variants/POS\"]\n",
    "m = rec\n",
    "samples = [\"test\"]\n",
    "\n",
    "### Maybe filter for Loci here\n",
    "save_hdf5(gt, ad, ref, alt, pos, m, samples, path=hdf5_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 77658 variants\n",
      "Loaded 3 individuals\n",
      "HDF5 loaded from ../Simulated/1000G_Mosaic/TSI/ch3_5cm/data.hdf5\n"
     ]
    }
   ],
   "source": [
    "path = \"../Simulated/1000G_Mosaic/TSI/ch3_5cm/data.hdf5\"\n",
    "f_T = load_h5(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calldata', 'samples', 'variants']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_T[\"calldata/GT\"][200:500,0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0], dtype=int8)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"calldata/GT\"][200:400,2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if H5 correctly polarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 16044 variants\n",
      "Loaded 503 individuals\n",
      "HDF5 loaded from ../Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr21_new.hdf5\n"
     ]
    }
   ],
   "source": [
    "ch=21\n",
    "h5_path1000g = \"../Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr\"\n",
    "h5_path1000g = h5_path1000g + str(ch) + \"_new.hdf5\"   # Attach Part for the right Chromosome\n",
    "f = load_h5(h5_path1000g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 1105538 variants\n",
      "Loaded 2504 individuals\n",
      "HDF5 loaded from ../Data/1000Genomes/HDF5/FULLHDF5/cr21.hdf5\n"
     ]
    }
   ],
   "source": [
    "path = \"../Data/1000Genomes/HDF5/FULLHDF5/cr21.hdf5\"\n",
    "f = load_h5(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (f[\"calldata/GT\"][:,0,0] < f[\"calldata/GT\"][:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594.0\n",
      "7066.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.sum(f[\"calldata/GT\"][:,2,0])))\n",
    "print(np.mean(np.sum(f[\"calldata/GT\"][:,2,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36997\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python wrapper for PLINK\n",
    "Contains additional functions to mimic output of HAPSBURG for downstream analysis\n",
    "@Harald Ringbauer, October 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VioletQueen\n",
      "/home/harald/git/HAPSBURG\n",
      "CPU Count: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./PackagesSupport/h5_python/\")\n",
    "from h5_functions import hdf5_to_vcf, load_h5   # Import Function to convert hdf5 to vcf\n",
    "sys.path.append(\"./PackagesSupport/parallel_runs/\")\n",
    "from helper_functions import split_up_roh_df, prepare_path  # To split up ground truth ROH\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PLINK core function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_plink(path_vcf, output_folder, window_snp=50, kb=500, het=1, threshold=0.05, gap=1000, density=50):\n",
    "    \"\"\"Run PLINK ROH Caller on path_vcf, and save results in output_folder\"\"\"\n",
    "    !plink --homozyg --vcf $path_vcf --homozyg-window-snp \\\n",
    "    $window_snp --homozyg-kb $kb --homozyg-window-het $het \\\n",
    "    --homozyg-window-threshold $threshold --homozyg-gap $gap \\\n",
    "    --homozyg-density $density --out $output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to modify PLINK output for simulated Mosaic Data\n",
    "Run PLINK on simulated Mosaic Data, for each individual, and save output into PLINK output folder\n",
    "For post-processing: Need roh.csv as well as roh_gt.csv. The latter will be needed to copy over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step0: Convert HDF5 to VCF\n",
    "def create_folders(input_base_folder):\n",
    "    \"\"\"Create Folders if not existing and returns \"\"\"\n",
    "    input_h5 = os.path.join(input_base_folder, \"data.h5\")\n",
    "    input_vcf = os.path.join(input_base_folder, \"data.vcf\")\n",
    "    \n",
    "    if not os.path.exists(input_h5):\n",
    "        raise RuntimeError(f\"Create .vcf file: {input_h5}\")\n",
    "        \n",
    "    plink_folder = os.path.join(input_base_folder,\"plink_out/\")\n",
    "    if not os.path.exists(plink_folder):\n",
    "        print(f\"Creating Folder for: {plink_folder}\")\n",
    "        os.makedirs(plink_folder)\n",
    "    \n",
    "    return input_h5, input_vcf, plink_folder\n",
    "\n",
    "def post_process_plink(plink_folder, new_dict):\n",
    "    \"\"\"Post Process the PLINK Result to match Hapsburg output. Load dataframe from plink_folder,\n",
    "    modify and return data frame\"\"\"\n",
    "    path_plink_roh = plink_folder + \"roh.hom\"\n",
    "    df_plink = pd.read_csv(path_plink_roh, sep=r\"\\s+\", engine=\"python\")\n",
    "\n",
    "    df_plink[\"StartM\"] = df_plink[\"POS1\"].map(new_dict)\n",
    "    df_plink[\"EndM\"] = df_plink[\"POS2\"].map(new_dict)\n",
    "    df_plink[\"lengthM\"] = df_plink[\"EndM\"] - df_plink[\"StartM\"]\n",
    "    df_plink.rename(columns = {\"POS1\":\"Start\", \"POS2\": \"End\", \"IID\":\"iid\", \"CHR\":\"ch\"}, inplace=True)\n",
    "    df_plink[\"length\"] = df_plink[\"End\"] - df_plink[\"Start\"]\n",
    "    # Add all fields for roh.csv\n",
    "    df_plink = df_plink[[\"Start\", \"End\", \"StartM\", \"EndM\", \"length\", \"lengthM\", \"iid\", \"ch\"]]\n",
    "    return df_plink\n",
    "\n",
    "# Step 2.2: Split up results into roh.csv & roh_gt.csv\n",
    "def split_up_inferred_roh(df_t, iid, save_path):\n",
    "    \"\"\"Extract only ROH from Individual iid and saves it to save_path\"\"\"\n",
    "    df_iid = df_t[df_t[\"iid\"]==iid]\n",
    "    df_iid.to_csv(save_path, index=False)\n",
    "    \n",
    "def postprocess_iid(df_plink, input_base_folder, iids, ch=3, prefix_out=\"\"):\n",
    "    \"\"\"Split up results into roh.csv and roh_gt.csv for each IID.\n",
    "    df_plink: Data Frame with Plink results, formated correctly\"\"\"\n",
    "\n",
    "    for iid in iids:\n",
    "        output_base_folder = os.path.join(input_base_folder, \"output/\")\n",
    "        path_out = prepare_path(output_base_folder, iid, ch, prefix_out=prefix_out, logfile=False)\n",
    "\n",
    "        path_inferred = os.path.join(path_out, \"roh.csv\")\n",
    "        split_up_inferred_roh(df_plink, iid, save_path=path_inferred)   # Split up Inferred ROH\n",
    "        split_up_roh_df(input_base_folder, path_out, iid)  # Split up Ground Truth ROH\n",
    "        \n",
    "        \n",
    "#############################################\n",
    "### Combine all subfunctions\n",
    "\n",
    "def full_plink_mosaic(input_base_folder, ch=3, prefix_out=\"plink/\"):\n",
    "    \"\"\"Run PLINK on Mosaic Data Set in ./Simulated\"\"\"\n",
    "    \n",
    "    input_h5, input_vcf, plink_folder = create_folders(input_base_folder)\n",
    "    hdf5_to_vcf(input_h5, input_vcf, chrom=ch) # Convert to VCF\n",
    "    run_plink(input_vcf, plink_folder + \"roh\") # 1.1: Run PLINK on VCF\n",
    "    \n",
    "    ### Create the Mapping Dictionary\n",
    "    print(\"Creating Map Dict...\")\n",
    "    f = load_h5(path=input_h5, output=False)\n",
    "    map_dct = dict(zip(f[\"variants/POS\"], f[\"variants/MAP\"]))\n",
    "    iids = f[\"samples\"][:] # Get the IIDs\n",
    "    \n",
    "    print(\"Splitting up Plink results and GT...\")\n",
    "    df_plink =  post_process_plink(plink_folder, map_dct)\n",
    "    postprocess_iid(df_plink, input_base_folder, iids, ch, prefix_out)\n",
    "    print(f\"Finished {len(iids)} Individuals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all Individuals for Mosaic Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HDF5\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "['AD', 'GT']\n",
      "['ALT', 'MAP', 'POS', 'REF']\n",
      "Successfully saved VCF to ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/data.vcf\n",
      "PLINK v1.90b6.9 64-bit (4 Mar 2019)            www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2019 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh.log.\n",
      "Options in effect:\n",
      "  --homozyg\n",
      "  --homozyg-density 50\n",
      "  --homozyg-gap 1000\n",
      "  --homozyg-kb 500\n",
      "  --homozyg-window-het 1\n",
      "  --homozyg-window-snp 50\n",
      "  --homozyg-window-threshold 0.05\n",
      "  --out ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh\n",
      "  --vcf ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/data.vcf\n",
      "\n",
      "7704 MB RAM detected; reserving 3852 MB for main workspace.\n",
      "--vcf: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh-temporary.bed +\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh-temporary.bim +\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh-temporary.fam written.\n",
      "77652 variants loaded from .bim file.\n",
      "100 people (0 males, 0 females, 100 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh.nosex .\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 100 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "77652 variants and 100 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--homozyg: Scan complete, found 1674 ROH.\n",
      "Results saved to ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh.hom +\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh.hom.indiv +\n",
      "./Simulated/1000G_Mosaic/TSI5/ch3_6cm/plink_out/roh.hom.summary .\n",
      "Creating Map Dict...\n",
      "Splitting up Plink results and GT...\n",
      "Finished 100 Individuals!\n",
      "CPU times: user 30.7 s, sys: 1.07 s, total: 31.8 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_plink_mosaic(input_base_folder = \"./Simulated/1000G_Mosaic/TSI5/ch3_6cm\",\n",
    "                  ch=3, prefix_out=\"plink/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51: Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALT', 'MAP', 'POS', 'REF']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f[\"variants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

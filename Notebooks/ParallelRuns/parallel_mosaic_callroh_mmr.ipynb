{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel\n",
    "Import the code for calling ROHs on test cases (simulated mosaics), \n",
    "and then functions for various cases to parallelize it\n",
    "\n",
    "@Author: Harald Ringbauer, June 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0402.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./package/hapsburg/\")  # Since now we are in the Root Directory\n",
    "#from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "\n",
    "#sys.path.append(\"./Python3/create1000G_Mosaic/\")  # Since now we are in the Root Directory\n",
    "#from createMosaicsMulti import Mosaic_1000G_Multi  # Import the object that can create the Multiruns\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions and Paralellize Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_roh_df(base_path, iid, prefix_out=\"\"):\n",
    "    \"\"\"Splits up the ROH-dataframe\"\"\"\n",
    "    path = base_path + \"roh_info.csv\"\n",
    "    dft = pd.read_csv(path, sep=\"\\t\")  # Load the Meta File\n",
    "\n",
    "    save_df = dft[dft[\"iid\"] == iid]\n",
    "    save_path = base_path + \"output/\" + \\\n",
    "        iid + \"/chr\" + str(ch) + \"/\" + prefix_out + \"roh_gt.csv\"\n",
    "    save_df.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "    return\n",
    "\n",
    "def prepare_path(path_mosaic, iid, ch, prefix_out, logfile=True):\n",
    "    \"\"\"Prepare the path and pipe printing for one Individual\n",
    "    logfile: Whether to pipe output to log-file\"\"\"   \n",
    "    \n",
    "    if not os.path.exists(path_mosaic):\n",
    "            raise RuntimeError(f\"Path {path_mosaic} not Found. Check!\")\n",
    "    \n",
    "    path_log = path_mosaic + \"output/\" + iid + \"/chr\" + str(ch) + \"/\" + prefix_out\n",
    "    if not os.path.exists(path_log):\n",
    "            os.makedirs(path_log)\n",
    "    \n",
    "    #if os.path.isdir(path_log):\n",
    "    #     os.rmdir(path_log)   # From a previous whoopsie-daisy\n",
    "    \n",
    "    ##### The Log File.  For debugging comment out!!!! ####\n",
    "    if logfile == True:\n",
    "        path_log = path_log + \"hmm_run_log.txt\"\n",
    "        print(f\"Set Output Log path: {path_log}\")\n",
    "        sys.stdout = open(path_log, 'w') \n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "### Do the Read Count Analysis Function\n",
    "\n",
    "def analyze_individual_mmr(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                          path_mosaic=\"./Simulated/1000G_Mosaic/TSI/RC1.0/ch3_5cm/\",\n",
    "                          exclude_pops=[\"TSI\", ], prefix_out=\"\",\n",
    "                          cutoff_pp=0.95, windowSize=0.001, logfile=False):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on readcount data\n",
    "    and with mmr\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    prepare_path(path_mosaic, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"readcount\", post_model=\"MMR\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model and then data\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts=True, destroy_phase=False,\n",
    "                prefix_out_data=prefix_out, excluded=exclude_pops)\n",
    "    hmm.p_obj.set_folder(path_mosaic)         # Set the Folder\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "\n",
    "    ### Load and set Parameters for Postprocessing\n",
    "    hmm.load_postprocessing_model()\n",
    "    hmm.post_obj.set_params(cutoff=cutoff_pp)\n",
    "    \n",
    "    ### Run Inference and Postprocess\n",
    "    hmm.mmr_call(windowSize=windowSize, save=save)\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, iid, prefix_out)\n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "    \n",
    "def multi_run(fun, prms, processes = 4):\n",
    "    \"\"\"Implementation of running in Parallel.\n",
    "    fun: Function\n",
    "    prms: The Parameter Files\n",
    "    processes: How many Processes to use\"\"\"\n",
    "    print(f\"Running {len(prms)} jobs in parallel.\")\n",
    "    \n",
    "    with mp.Pool(processes = processes) as pool:\n",
    "        results = pool.starmap(fun, prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH with Maximal Matching Rate (MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=True\n",
    "base_path=\"./Simulated/1000G_Mosaic/CHB/\"   #TSI5/\n",
    "exclude_pops = [\"TSI\", ]\n",
    "n = 100\n",
    "prefix_out = \"mmr95/\"   #  e01/ Error saved in folder structure\n",
    "cutoff_pp = 0.95\n",
    "windowSize = 0.001\n",
    "logfile=True  # Wether to print output into logfile\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] \n",
    "mean_rcs = np.linspace(0.1, 1, 10)\n",
    "mean_rcs = mean_rcs[1:]\n",
    "#lengths = [4]\n",
    "#mean_rcs=[mean_rcs[1],]\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for m_rc in mean_rcs:\n",
    "    for l in lengths:      \n",
    "        #f = base_path + \"lambda_rc\" + str(m_rc) + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        f = base_path + \"lambda_rc\" + f\"{m_rc:.1f}\" + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, \n",
    "                       cutoff_pp, windowSize, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0]) == 11)  # The MMR function takes 13 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5400 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_0cm/output/iid0/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.3/ch3_0cm/output/iid76/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.3/ch3_4cm/output/iid45/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.3/ch3_8cm/output/iid14/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.3/ch3_10cm/output/iid83/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_2cm/output/iid69/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_10cm/output/iid7/chr3/mmr95/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_6cm/output/iid38/chr3/mmr95/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual_mmr, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single parameter run\n",
    "Comment out the log file in analyze individual to see output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n"
     ]
    }
   ],
   "source": [
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_individual() takes from 1 to 12 positional arguments but 13 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e88a7e774481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: analyze_individual() takes from 1 to 12 positional arguments but 13 were given"
     ]
    }
   ],
   "source": [
    "analyze_individual(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_8cm/output/iid0/chr3/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

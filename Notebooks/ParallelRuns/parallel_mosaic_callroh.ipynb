{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel\n",
    "Import the code for calling ROHs on test cases (simulated mosaics), \n",
    "and then functions for various cases to parallelize it\n",
    "\n",
    "### Also contains Functions to merge blocks in the folder structure\n",
    "So generally: Run the Calls without the merging, and then create custom merges\n",
    "\n",
    "Original version with manual function is in ./Legacy\n",
    "\n",
    "@Author: Harald Ringbauer, February 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0401.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "import shutil as shutil\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "#sys.path.append(\"./package/\")  # Since now we are in the Root Directory.\n",
    "sys.path.insert(0,\"./package/\")  # Hack to get developer package\n",
    "#from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "\n",
    "#from PackagesSupport.parallel_runs.helper_functions import prepare_path, create_folders, postprocess_iid\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_chrom\n",
    "from hapsburg.PackagesSupport.parallel_runs.helper_functions import multi_run, split_up_roh_df  # Parallel Runs and forward ground truth\n",
    "from hapsburg.PackagesSupport.pp_individual_roh_csvs import merge_called_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parallel Calling on TSI (single Target HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "iids = [\"iid\" + str(i) for i in range(0,100)]   # List of iids to iterate over\n",
    "### Create list of IIDs and of Folders\n",
    "\n",
    "ch = 3 # For test case here: Only do Chromosome #3\n",
    "n_ref = 504  # 2504 All 503 Europe/TSI 504 EAS\n",
    "diploid_ref = True\n",
    "save = True\n",
    "save_fp = False\n",
    "\n",
    "#exclude_pops = [\"TSI\", ]\n",
    "exclude_pops = []\n",
    "e_model = \"haploid\"\n",
    "p_model = \"MosaicHDF5\"  \n",
    "readcounts = False\n",
    "destroy_phase = True\n",
    "post_model = \"Standard\"\n",
    "#h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240gzip/chr\" # Switch: Eur1240chr for classic\n",
    "h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/EAS_AFR1240/chr\"\n",
    "#meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\"  # meta_df.csv for full 1000G\n",
    "meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_EAS_AFR.tsv\"  # meta_df.csv for full 1000G\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\" # Simulated Mosaics\n",
    "#base_path=\"./Simulated/1000G_Mosaic/CLM/\" # Simulated Mosaics\n",
    "\n",
    "roh_in = 1   #1  New: 0.1\n",
    "roh_out = 20 # 20 Good: 10\n",
    "roh_jump = 500\n",
    "e_rate = 0.01  # The Error Rate\n",
    "e_rate_ref = 0.0\n",
    "max_gap = 0.00 # Gap Merging. In M\n",
    "#cutoffs = [0.9, 0.99, 0.9999, 0.99999]\n",
    "cutoffs = [0.999]\n",
    "l_cutoff = 0.01\n",
    "logfile = True\n",
    "#lengths = [0, 2, 4, 6, 8, 10] # Which Block Lengths to test\n",
    "lengths = [0, 2, 4, 6, 8, 10]  # Relevant ones for key performance testing\n",
    "#prefix_out = \"eas_ref/\" # Check as well below in loop!!!\n",
    "\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders. # \"cm/missing/5/\"\n",
    "\n",
    "#########################################################\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "for f in folders: \n",
    "    path_targets = f + \"data.h5\"\n",
    "    base_out_folder = os.path.join(f, \"output\", \"\")\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        #prefix_out = str(cutoff).replace(\".\", \"\") + \"/\"\n",
    "        prefix_out = \"eas_afr_ref/\"  # \"eas_ref.jump500/\"\n",
    "    \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, save, save_fp, n_ref, diploid_ref, exclude_pops, e_model, p_model, readcounts, destroy_phase,\n",
    "            post_model, path_targets, h5_path1000g, meta_path_ref, base_out_folder, prefix_out,\n",
    "            roh_in, roh_out, roh_jump, e_rate, e_rate_ref, max_gap, cutoff, l_cutoff, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "        \n",
    "assert(len(prms[0])==26)   # Sanity Check\n",
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testrun on single Set of Parameters for TSI5\n",
    "Set logfile parameter to `False` to get output in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 total jobs; 1 in parallel.\n",
      "Running single process...\n",
      "Using Rescaled HMM.\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 1165 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/EAS_AFR1240/chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77652\n",
      "Nr of Matching Refs: 77652 / 77652\n",
      "Ref/Alt Allele Matching: 77652 / 77652\n",
      "Flipped Ref/Alt Alleles for 0 SNPs\n",
      "Together: 77652 / 77652\n",
      "1165 / 1165 Individuals included in Reference\n",
      "Extracting up to 504 Individuals\n",
      "Exctraction of hdf5 done. Subsetting...!\n",
      "Extraction of 2 Haplotypes complete\n",
      "Flipping Ref/Alt Allele in target for 0 SNPs...\n",
      "Exctraction of hdf5 done. Subsetting...!\n",
      "Extraction of 1008 Haplotypes complete\n",
      "Reduced to markers called 77652 / 77652\n",
      "Fraction SNPs covered: 1.0000\n",
      "Successfully saved target individual data to: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/output/iid0/chr3/eas_afr_ref/\n",
      "Shuffling phase of target...\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/output/iid0/chr3/eas_afr_ref/\n",
      "Loaded Emission Model: haploid\n",
      "Loaded Transition Model: model\n",
      "Loaded Post Processing Model: Standard\n",
      "Minimum Genetic Map: 0.0000 Morgan\n",
      "Maximum Genetic Map: 2.2326 Morgan\n",
      "Gaps bigger than 0.1 cM: 214\n",
      "Maximum Gap: 0.2348 cM\n",
      "Upper Gap Cutoff: 5.0000 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(1009, 77652)\n",
      "Loaded Observations:\n",
      "(2, 77652)\n",
      "Reference Number: 1008\n",
      "Memory Usage at end of HMM:\n",
      "Memory Usage: 883.605504 mB\n",
      "Total Log likelihood: -26264.834\n",
      "Finished Calculation State Posteriors\n",
      "Saved Zero State Posterior to folder ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/output/iid0/chr3/eas_afr_ref/.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/output/iid0/chr3/eas_afr_ref/\n",
      "Fraction Markers in ROH: 0.4265\n",
      "Merged n=0 gaps < 0.0 M\n",
      "Called n=7 ROH Blocks > 1.0 cM\n",
      "Longest Block: 10.90 cM\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/output/iid0/chr3/eas_afr_ref/roh.csv\n",
      "CPU times: user 4.48 s, sys: 1.39 s, total: 5.87 s\n",
      "Wall time: 8.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multi_run(hapsb_chrom, [prms[500]], processes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all Individuals\n",
    "Takes 5 min for 600 Parameter Files (of Chr. 3, with 500 refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 total jobs; 20 in parallel.\n",
      "Starting Pool of multiple workers...\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid8/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid4/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid0/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid16/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid12/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid24/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid20/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid40/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid32/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid52/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid28/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid36/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid48/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid44/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid56/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid64/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid88/chr3/eas_afr_ref/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid80/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid72/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid96/chr3/eas_afr_ref/hmm_run_log.txt\n",
      "CPU times: user 368 ms, sys: 326 ms, total: 695 ms\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multi_run(hapsb_chrom, prms[:], processes = 20) # #For all ref: 4 for everything, 8 for 0.5x. For Europe only multiply x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up ground truth ROH into according folders\n",
    "Takes about 30s for 600 prms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Simulated/1000G_Mosaic/TSI5/ch3_0cm/', './Simulated/1000G_Mosaic/TSI5/ch3_2cm/', './Simulated/1000G_Mosaic/TSI5/ch3_4cm/', './Simulated/1000G_Mosaic/TSI5/ch3_6cm/', './Simulated/1000G_Mosaic/TSI5/ch3_8cm/', './Simulated/1000G_Mosaic/TSI5/ch3_10cm/']\n",
      "eas_afr_ref/\n"
     ]
    }
   ],
   "source": [
    "print(folders)\n",
    "print(prefix_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 s, sys: 267 ms, total: 3.7 s\n",
      "Wall time: 9.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Split up ground truth roh.csv \n",
    "#(to pack into output folder as well for easier comparison)\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids[:]:\n",
    "        for cutoff in cutoffs:\n",
    "            #prefix_out = str(cutoff).replace(\".\", \"\") + \"/\"  \n",
    "            #prefix_out=\"test/\"\n",
    "            path_out = os.path.join(f, \"output\", iid, \"chr\"+str(ch), prefix_out)\n",
    "            split_up_roh_df(f, path_out, iid, \n",
    "                            file_in=\"roh_info.csv\", \n",
    "                            file_out=\"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up with no different Output Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 ms, sys: 12 ms, total: 202 ms\n",
      "Wall time: 220 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Split up ground truth roh.csv \n",
    "#(to pack into output folder as well for easier comparison)\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids[:]:\n",
    "        path_out = os.path.join(f, \"output\", iid, \"chr\"+str(ch), prefix_out)\n",
    "        split_up_roh_df(f, path_out, iid, \n",
    "                        file_in=\"roh_info.csv\", file_out=\"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to merge blocks from Multi Run\n",
    "For range of iids and block lengths  \n",
    "Also copy over block length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_blocks_simulations(mosaic_folder = \"./Simulated/1000G_Mosaic/TSI6/\",\n",
    "                             max_gap=0.05, min_len1=0.02, min_len2=0.02,\n",
    "                             blens=[4], iids=[0], copy_gt = True,\n",
    "                             output_prefix=\"0999/\", output_prefix1=\"merged/\",\n",
    "                             error=\"\"):\n",
    "    \"\"\"Merges Gaps from Simulated ROH Blocks. Loop over IIDs and save with new prefix\n",
    "    output_prefix: Prefix of output to load\n",
    "    output_prefix1: Prefix to save merged gaps to\n",
    "    error: Either empty or missing/2/\"\"\"\n",
    "    for iid in iids:\n",
    "        for blen in blens:\n",
    "            path1 = mosaic_folder + \"ch3_\" + str(blen) + \"cm/\" + error + \"output/iid\"+str(iid)+\"/chr3/\"\n",
    "            load_path = path1 + output_prefix + \"roh.csv\"        \n",
    "            save_path =  path1 + output_prefix1 + \"roh.csv\"\n",
    "\n",
    "            df = pd.read_csv(load_path)\n",
    "            df1 = merge_called_blocks(df, max_gap=max_gap, min_len1=min_len1, min_len2=min_len2)\n",
    "            \n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "            df1.to_csv(save_path, index=False)\n",
    "            \n",
    "            ### Copy ground truth\n",
    "            if copy_gt:\n",
    "                shutil.copy(path1 + output_prefix + \"roh_gt.csv\", path1 + output_prefix1 + \"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the merging\n",
    "Takes about 50s for 600 iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 320 ms, total: 30.2 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iids = np.arange(100)\n",
    "blens = [0, 2, 4, 6, 8, 10]\n",
    "merge_blocks_simulations(mosaic_folder='./Simulated/1000G_Mosaic/TSI5/',\n",
    "                         output_prefix='eas_afr_ref/', output_prefix1='eas_afr_ref.merged/',\n",
    "                         blens=blens, iids=iids,\n",
    "                         max_gap=0.01, min_len1=0.02, min_len2=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run various Missing degree PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "iids = [\"iid\" + str(i) for i in range(0,100)]   # List of iids to iterate over\n",
    "### Create list of IIDs and of Folders\n",
    "\n",
    "ch = 3 # For test case here: Only do Chromosome #3\n",
    "n_ref = 2504  # 2504 All 503 Europe/TSI\n",
    "save = True\n",
    "save_fp = False\n",
    "\n",
    "exclude_pops = [\"TSI\", ]\n",
    "\n",
    "e_model = \"haploid\"\n",
    "p_model = \"MosaicHDF5\"  \n",
    "readcounts = False\n",
    "destroy_phase=True\n",
    "\n",
    "post_model = \"Standard\"\n",
    "h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240int8/chr\" # Switch: Eur1240chr\n",
    "meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\"  # meta_df.csv for full 1000G\n",
    "\n",
    "prefix_out = \"0999/\"\n",
    "roh_in = 1   #1  New: 0.1\n",
    "roh_out = 20 # 20 Good: 10\n",
    "roh_jump = 300\n",
    "e_rate = 0.01  # The Error Rate\n",
    "e_rate_ref = 0.0\n",
    "max_gap = 0.00 # Gap Merging. In M\n",
    "#cutoffs = [0.9, 0.99, 0.9999, 0.99999]\n",
    "#cutoffs = [0.996, 0.997, 0.998, 0.999]\n",
    "#cutoffs = [0.998, 0.999, 0.9995]\n",
    "cutoffs=0.999\n",
    "l_cutoff = 0.01\n",
    "\n",
    "logfile = True\n",
    "missing = [1,2,3,4,5]\n",
    "lengths = [0, 2, 4, 6, 8, 10]  # Relevant ones for key performance testing\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "\n",
    "#########################################################\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "for m in missing:\n",
    "    folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/missing/\" + str(m) + \"/\" for l in lengths]\n",
    "    for f in folders: \n",
    "        path_targets = f + \"data.h5\"\n",
    "        base_out_folder = os.path.join(f, \"output\", \"\")\n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, save, save_fp, n_ref, exclude_pops, e_model, p_model, readcounts, destroy_phase,\n",
    "            post_model, path_targets, h5_path1000g, meta_path_ref, base_out_folder, prefix_out,\n",
    "            roh_in, roh_out, roh_jump, e_rate, e_rate_ref, max_gap, cutoff, l_cutoff, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "        \n",
    "assert(len(prms[0]) == 25)   # Sanity Check\n",
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 5.55 s, total: 8.33 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Split up ground truth roh.csv. Copy over the true roh_gt.csv from base folder\n",
    "missing = [1,2,3,4,5]\n",
    "lengths = [0, 2, 4, 6, 8, 10]  # Relevant ones for key performance testing\n",
    "iids = [\"iid\" + str(i) for i in range(0,100)]   # List of iids to iterate over\n",
    "prefix_out = \"0999/\"\n",
    "\n",
    "for m in missing:\n",
    "    for l in lengths:\n",
    "        f0 = base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\"\n",
    "        f1 = base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/missing/\" + str(m) + \"/\"\n",
    "        \n",
    "        for f in folders:\n",
    "            for iid in iids[:]:\n",
    "                path0 = os.path.join(f0, \"output\", iid, \"chr\"+ str(ch), \"roh_gt.csv\")\n",
    "                path1 = os.path.join(f1, \"output\", iid, \"chr\"+str(ch), prefix_out, \"roh_gt.csv\")\n",
    "                shutil.copy(path0,  path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "multi_run(hapsb_chrom, [prms[-1]], processes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3000 total jobs; 8 in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/1/output/iid0/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/1/output/iid94/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/missing/1/output/iid82/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_10cm/missing/1/output/iid64/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/2/output/iid58/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_8cm/missing/1/output/iid70/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_6cm/missing/1/output/iid76/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/missing/1/output/iid88/chr3/0999/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multi_run(hapsb_chrom, prms[:], processes = 8) # #For all ref: 4 for everything, 8 for 0.5x. For Europe only multiply x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Split up ground truth roh.csv. Copy over the true roh_gt.csv from base folder\n",
    "### Takes about 1 min\n",
    "missing = [1,2,3,4,5]\n",
    "iids = [\"iid\" + str(i) for i in range(0,100)]   # List of iids to iterate over\n",
    "prefix_out = \"0999/\"\n",
    "\n",
    "for m in missing:\n",
    "    for l in lengths:\n",
    "        f0 = base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\"\n",
    "        f1 = base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/missing/\" + str(m) + \"/\"\n",
    "        \n",
    "        for f in folders:\n",
    "            for iid in iids[:]:\n",
    "                path0 = os.path.join(f0, \"output\", iid, \"chr\"+ str(ch), \"roh_gt.csv\")\n",
    "                path1 = os.path.join(f1, \"output\", iid, \"chr\"+str(ch), prefix_out, \"roh_gt.csv\")\n",
    "                shutil.copy(path0,  path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1.08 s, total: 1min 12s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Done for 2,5\n",
    "iids = np.arange(100)\n",
    "blens = [0, 2, 4, 6, 8, 10]\n",
    "missing = [1,3,4]  # Missingness Vector\n",
    "missing = [\"missing/\" + str(i) + \"/\" for i in missing]\n",
    "#blens = [4]\n",
    "for m in missing:\n",
    "    merge_blocks_simulations(mosaic_folder='./Simulated/1000G_Mosaic/TSI5/',\n",
    "                             output_prefix='0999/', output_prefix1='merged/',\n",
    "                             blens=blens, iids=iids,\n",
    "                             max_gap=0.008, min_len1=0.02, min_len2=0.02,\n",
    "                             error=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

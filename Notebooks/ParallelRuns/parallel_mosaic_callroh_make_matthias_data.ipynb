{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel\n",
    "Has Notebooks that import the code for the calling ROHs on Mosaics, and then functions for various cases to parallelize it\n",
    "\n",
    "@Author: Harald Ringbauer, June 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VioletQueen\n",
      "/home/harald/git/HAPSBURG\n",
      "CPU Count: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name[:7] == \"midway2\":\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "#sys.path.append(\"./Python3/create1000G_Mosaic/\")  # Since now we are in the Root Directory\n",
    "#from createMosaicsMulti import Mosaic_1000G_Multi  # Import the object that can create the Multiruns\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions and Paralellize Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_roh_df(base_path, iid, prefix_out=\"\"):\n",
    "    \"\"\"Splits up the ROH-dataframe\"\"\"\n",
    "    path = base_path + \"roh_info.csv\"\n",
    "    dft = pd.read_csv(path, sep=\"\\t\")  # Load the Meta File\n",
    "\n",
    "    save_df = dft[dft[\"iid\"] == iid]\n",
    "    save_path = base_path + \"output/\" + \\\n",
    "        iid + \"/chr\" + str(ch) + \"/\" + prefix_out + \"roh_gt.csv\"\n",
    "    save_df.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "    return\n",
    "\n",
    "def prepare_path(path_mosaic, iid, ch, prefix_out, logfile=True):\n",
    "    \"\"\"Prepare the path and pipe printing for one Individual\n",
    "    logfile: Whether to pipe output to log-file\"\"\"   \n",
    "    \n",
    "    if not os.path.exists(path_mosaic):\n",
    "            raise RuntimeError(f\"Path {path_mosaic} not Found. Check!\")\n",
    "    \n",
    "    path_log = path_mosaic + \"output/\" + iid + \"/chr\" + str(ch) + \"/\" + prefix_out\n",
    "    if not os.path.exists(path_log):\n",
    "            os.makedirs(path_log)\n",
    "    \n",
    "    #if os.path.isdir(path_log):\n",
    "    #     os.rmdir(path_log)   # From a previous whoopsie-daisy\n",
    "    \n",
    "    ##### The Log File.  For debugging comment out!!!! ####\n",
    "    if logfile == True:\n",
    "        path_log = path_log + \"hmm_run_log.txt\"\n",
    "        print(f\"Set Output Log path: {path_log}\")\n",
    "        sys.stdout = open(path_log, 'w') \n",
    "    \n",
    "def analyze_individual(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                       path_mosaic=\"./Simulated/1000G_Mosaic/TSI/ch3_5cm/\",\n",
    "                       exclude_pops=[\"TSI\", ], prefix_out=\"\", \n",
    "                       roh_in =1, roh_out=10, roh_jump=100, e_rate=0.001):\n",
    "    \"\"\"Run the analysis for one individual and chromosome.\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    prepare_path(path_mosaic, iid, ch, prefix_out, logfile=True)\n",
    "    \n",
    "    ### Do the full HMM Analysis\n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    ### Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_folder(path_mosaic)         # Set the Folder\n",
    "    #hmm.p_obj.set_prefix_out_data(prefix_out)\n",
    "    #hmm.p_obj.set_exclude_pops(pops=exclude_pops)\n",
    "    hmm.p_obj.set_params(destroy_phase=True, prefix_out_data=prefix_out,\n",
    "                        excluded=eclude_pops)\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    \n",
    "    ### Emission and Transition Model\n",
    "    hmm.load_emission_model()\n",
    "    hmm.load_transition_model()\n",
    "\n",
    "    #hmm.set_diploid_observations()             # To diploidize Individuals\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)  # Set Jump Parameters\n",
    "    hmm.e_obj.set_params(e_rate=e_rate)                  # Set error rates\n",
    "    \n",
    "    hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, iid, prefix_out)\n",
    "    \n",
    "    print(f\"Analysis of {iid} and Chr. {ch} successfully concluded!\")\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "### Do the Read Count Analysis Function\n",
    "\n",
    "def analyze_individual_rc(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                          path_mosaic=\"./Simulated/1000G_Mosaic/TSI/RC1.0/ch3_5cm/\",\n",
    "                          exclude_pops=[\"TSI\", ], prefix_out=\"\",\n",
    "                          roh_in=1, roh_out=10, roh_jump=100, e_rate=0.01, e_rate_ref=0.001):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on readcount data\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    prepare_path(path_mosaic, iid, ch, prefix_out, logfile=False)\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"readcount\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model and then data\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts = True, destroy_phase=False,\n",
    "                prefix_out_data=prefix_out, excluded=exclude_pops)\n",
    "    hmm.p_obj.set_folder(path_mosaic)         # Set the Folder\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    \n",
    "    hmm.load_secondary_objects()\n",
    "\n",
    "    ### Set the Parameters\n",
    "    hmm.e_obj.set_params(e_rate = e_rate, e_rate_ref = e_rate_ref)\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    \n",
    "    hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, iid, prefix_out)\n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "### Do the Read Count Analysis Function\n",
    "\n",
    "def analyze_individual_mmr(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                          path_mosaic=\"./Simulated/1000G_Mosaic/TSI/RC1.0/ch3_5cm/\",\n",
    "                          exclude_pops=[\"TSI\", ], prefix_out=\"\",\n",
    "                          cutoff_pp=0.95, windowSize=0.001, logfile=False):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on readcount data\n",
    "    and with mmr\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    prepare_path(path_mosaic, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"readcount\", post_model=\"MMR\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model and then data\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts=True, destroy_phase=False,\n",
    "                prefix_out_data=prefix_out, excluded=exclude_pops)\n",
    "    hmm.p_obj.set_folder(path_mosaic)         # Set the Folder\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "\n",
    "    ### Load and set Parameters for Postprocessing\n",
    "    hmm.load_postprocessing_model()\n",
    "    hmm.post_obj.set_params(cutoff=cutoff_pp)\n",
    "    \n",
    "    ### Run Inference and Postprocess\n",
    "    hmm.mmr_call(windowSize=windowSize, save=save)\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, iid, prefix_out)\n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "    \n",
    "def multi_run(fun, prms, processes = 4):\n",
    "    \"\"\"Implementation of running in Parallel.\n",
    "    fun: Function\n",
    "    prms: The Parameter Files\n",
    "    processes: How many Processes to use\"\"\"\n",
    "    print(f\"Running {len(prms)} jobs in parallel.\")\n",
    "    \n",
    "    with mp.Pool(processes = processes) as pool:\n",
    "        results = pool.starmap(fun, prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parallel Calling on TSI (single Target HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"e01rohin300/\"\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 300\n",
    "e_rate = 0.01  # The Error Rate\n",
    "n = 100\n",
    "\n",
    "#lengths = [0]  # For false positives\n",
    "lengths = [0, 2, 4, 6, 8, 10] # For chromosomes\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids:\n",
    "        new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate]\n",
    "        prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==12)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 jobs in parallel.\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid76/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid0/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid33/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid19/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid57/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid95/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid38/chr3/e01rohin300/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid14/chr3/e01rohin300/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")\n",
    "print(\"Run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROHS Blocks within multiple target HDF5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"\"\n",
    "\n",
    "n = 100\n",
    "targets = [\"CHB\", \"CLM\", \"YRI\"]\n",
    "lengths = [2, 4, 6, 8, 10]\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for t in targets:\n",
    "    base_path1 = base_path + t + \"/\"\n",
    "    folders = [base_path1 + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "    for f in folders:\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==8)   # The function takes 8 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1500 jobs in parallel.\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_2cm/output/iid0/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_2cm/output/iid47/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_2cm/output/iid94/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_4cm/output/iid88/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_4cm/output/iid41/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_6cm/output/iid35/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_6cm/output/iid82/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_8cm/output/iid29/chr3\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for multiple error levels (and multiple lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.01  # The Error Rate\n",
    "n = 100\n",
    "prefix_out = \"e01/\"   # Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] # For chromosomes\n",
    "error_vec = np.logspace(-3,-1, 8)\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "#folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for l in lengths:\n",
    "    for e in error_vec:\n",
    "        e_print = str(round(e, 4)).split(\".\")[1] # Extract four digits after decimal         \n",
    "        f = base_path + \"ch3_\" + str(l) + \"cm/error/\" + e_print + \"/\"   \n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==12)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4800 jobs in parallel.\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/001/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0072/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0019/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0139/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0037/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0518/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/1/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0019/output/iid0/chr3/e01/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for multiple downsample levels (and multiple lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/CHB/\"   #TSI5\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.001    # The Error Rate\n",
    "n = 100\n",
    "prefix_out = \"\"   #  e01/ Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] \n",
    "#lengths = [0,]\n",
    "\n",
    "missing_vec = np.linspace(0.1, 1.0, 10)\n",
    "#missing_vec = np.array([0.1, 0.2])\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for l in lengths:\n",
    "    for m in missing_vec:\n",
    "        m_print = str(round(m, 4)).split(\".\")[1] # Extract four digits after decimal         \n",
    "        f = base_path + \"ch3_\" + str(l) + \"cm/missing/\" + m_print + \"/\"   \n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==12)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for ReadCount data (Normal or Lambda)\n",
    "For Lambda change folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=True\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"   #TSI5\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.001    # The Error Rate for Read Count\n",
    "e_rate_ref = 0.001 # The  Error Rate for Reference Genotypes\n",
    "n = 1\n",
    "prefix_out = \"data_matthias/\"   #  e01/ Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "#lengths = [0, 2, 4, 6, 8, 10] \n",
    "#mean_rcs = np.linspace(0.1, 1, 10)\n",
    "lengths = [4]\n",
    "mean_rcs=[1.0,]\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for m_rc in mean_rcs:\n",
    "    for l in lengths:      \n",
    "        f = base_path + \"lambda_rc\" + str(m_rc) + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, e_rate_ref]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0]) == 13)  # The RC function takes 13 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 jobs in parallel.\n",
      "Using Linear-State Speed-Up\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "\n",
      "Loaded 77650 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 503 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77650\n",
      "Nr of Matching Refs: 77650 / 77650\n",
      "Full Intersection Ref/Alt Identical: 77650 / 77650\n",
      "396 / 503 Individuals included in Reference\n",
      "Extraction of 792 Haplotypes Complete!\n",
      "Markers called 38032 / 77650\n",
      "Successfully saved to: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/\n",
      "Loading Readcounts...\n",
      "Mean Readcount markers loaded: 2.04536\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/\n",
      "Loaded Emission Model: readcount\n",
      "Loaded Transition Model: model\n",
      "Loaded Post Processing Model: Standard\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 349\n",
      "Maximum Gap: 0.3916 cM\n",
      "Reference Number: 792\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(793, 38032, 3)\n",
      "Loaded Observations:\n",
      "(2, 38032)\n",
      "Log likelihood Path: -19520.759\n",
      "Saved to: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/viterbi_path.csv\n",
      "Finished Calculation Viterbi Path: [0 0 0 ... 0 0 0]\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 349\n",
      "Maximum Gap: 0.3916 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(793, 38032, 3)\n",
      "Loaded Observations:\n",
      "(2, 38032)\n",
      "Reference Number: 792\n",
      "Total Log likelihood: -18508.488\n",
      "Finished Calculation State Posteriors\n",
      "Saved Full Posterior and Ref GTS to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/\n",
      "Saved Zero State Posterior to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/\n",
      "Fraction Markers in ROH: 0.3024\n",
      "Merged n=0 gaps < 0.01 M\n",
      "Called n=5 ROH Blocks > 1.0 cM\n",
      "Longest Block: 4.590\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/data_matthias/roh.csv\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual_rc, prms, processes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH with Maximal Matching Rate (MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=True\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"   #TSI5\n",
    "exclude_pops = [\"TSI\", ]\n",
    "n = 1\n",
    "prefix_out = \"mmr95/\"   #  e01/ Error saved in folder structure\n",
    "cutoff_pp = 0.95\n",
    "windowSize = 0.001\n",
    "logfile=False  # Wether to print output into logfile\n",
    "\n",
    "### The arrays to iterate over\n",
    "#lengths = [0, 2, 4, 6, 8, 10] \n",
    "#mean_rcs = np.linspace(0.1, 1, 10)\n",
    "lengths = [4]\n",
    "mean_rcs=[1.0,]\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for m_rc in mean_rcs:\n",
    "    for l in lengths:      \n",
    "        f = base_path + \"lambda_rc\" + str(m_rc) + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, \n",
    "                       cutoff_pp, windowSize, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0]) == 11)  # The MMR function takes 13 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 jobs in parallel.\n",
      "Using Linear-State Speed-Up\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "\n",
      "Loaded 77650 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 503 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77650\n",
      "Nr of Matching Refs: 77650 / 77650\n",
      "Full Intersection Ref/Alt Identical: 77650 / 77650\n",
      "396 / 503 Individuals included in Reference\n",
      "Extraction of 792 Haplotypes Complete!\n",
      "Markers called 38032 / 77650\n",
      "Successfully saved to: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/mmr95/\n",
      "Loading Readcounts...\n",
      "Mean Readcount markers loaded: 2.04536\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/mmr95/\n",
      "Loaded Post Processing Model: MMR\n",
      "Saved Zero State Posterior to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/mmr95/posterior0.csv.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/mmr95/\n",
      "Fraction Markers in ROH: 0.3308\n",
      "Merged n=4 gaps < 0.01 M\n",
      "Called n=7 ROH Blocks > 1.0 cM\n",
      "Longest Block: 4.297\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/mmr95/roh.csv\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual_mmr, prms, processes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single parameter run\n",
    "Comment out the log file in analyze individual to see output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_individual() takes from 1 to 12 positional arguments but 13 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e88a7e774481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: analyze_individual() takes from 1 to 12 positional arguments but 13 were given"
     ]
    }
   ],
   "source": [
    "analyze_individual(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_8cm/output/iid0/chr3/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

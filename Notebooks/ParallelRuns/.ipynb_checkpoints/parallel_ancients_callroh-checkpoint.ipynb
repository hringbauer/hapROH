{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel within Ancient Individuals\n",
    "Notebooks that import the code for the calling ROHs on Ancients, and then functions for various cases to parallelize it.\n",
    "\n",
    "Highly similar to parallel_mosaic_callroh.ipynb\n",
    "\n",
    "@Author: Harald Ringbauer, June 2019\n",
    "All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midway jnovmbre partition detected.\n",
      "/project/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket.gethostname() == \"midway2-0401.rcc.local\" or socket.gethostname() == 'midway2-0402.rcc.local':\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "#sys.path.append(\"./Python3/create1000G_Mosaic/\")  # Since now we are in the Root Directory\n",
    "#from createMosaicsMulti import Mosaic_1000G_Multi  # Import the object that can create the Multiruns\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_path(path_output, iid, ch, prefix_out, logfile=True):\n",
    "    \"\"\"Prepare the path and pipe printing for one Individual\n",
    "    logfile: Whether to pipe output to log-file\"\"\"   \n",
    "    #if not os.path.exists(path_output):\n",
    "    #        raise RuntimeError(f\"Path {path_output} not Found. Check!\")\n",
    "            \n",
    "    path_log =  path_output + str(iid) + \"/chr\" + str(ch) + \"/\" + prefix_out\n",
    "    \n",
    "    if not os.path.exists(path_log):\n",
    "            os.makedirs(path_log)\n",
    "    \n",
    "    if logfile == True:\n",
    "        path_log = path_log + \"hmm_run_log.txt\"\n",
    "        print(f\"Set Output Log path: {path_log}\")\n",
    "        sys.stdout = open(path_log, 'w') \n",
    "    \n",
    "def analyze_individual(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                       path_output=\"./Empirical/1240k/\",\n",
    "                       exclude_pops=[\"TSI\", ], prefix_out=\"\", \n",
    "                       roh_in =1, roh_out=10, roh_jump=100, e_rate=0.001):\n",
    "    \"\"\"Run the analysis for one individual and chromosome.\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    prepare_path(path_output, iid, ch, prefix_out, logfile=False)\n",
    "    \n",
    "    ### Do the full HMM Analysis\n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"SardHDF5\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    ### Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(destroy_phase=True, prefix_out_data=prefix_out,\n",
    "                        excluded=eclude_pops)\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    \n",
    "    ### Emission and Transition Model\n",
    "    hmm.load_emission_model()\n",
    "    hmm.load_transition_model()\n",
    "\n",
    "    #hmm.set_diploid_observations()            # To diploidize Individuals\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)  # Set Jump Parameters\n",
    "    hmm.e_obj.set_params(e_rate=e_rate)        # Set error rates\n",
    "    \n",
    "    hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    print(f\"Analysis of {iid} and Chr. {ch} successfully concluded!\")\n",
    "    \n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "### Do the Read Count Analysis Function\n",
    "\n",
    "def analyze_individual_rc(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                          path_output=\"./Empirical/1240k/\",\n",
    "                          exclude_pops=[\"TSI\", ], prefix_out=\"rc/\",\n",
    "                          roh_in=1, roh_out=10, roh_jump=100, e_rate=0.01, e_rate_ref=0.001):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on readcount data\n",
    "    Wrapper for HMM Class. Takes 13 Parameters\"\"\"\n",
    "    \n",
    "    ### The folder on what to run the Data on (Permanently set here to fixed loaction)\n",
    "    h5_path_targets = \"./Data/Marcus2019_1240k/mod_reich_sardinia_ancients_rev_mrg_dedup_3trm_anno.h5\"\n",
    "    meta_path_targets = \"./Data/Marcus2019_1240k/meta_rev_final.csv\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    prepare_path(path_output, iid, ch, prefix_out, logfile=False)\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"SardHDF5\", e_model=\"readcount\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts = True, destroy_phase=False,\n",
    "                prefix_out_data=prefix_out, excluded=exclude_pops,\n",
    "                h5_path_targets = h5_path_targets, meta_path_targets=meta_path_targets)    \n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    \n",
    "    hmm.load_emission_model()\n",
    "    hmm.load_transition_model()\n",
    "\n",
    "    ### Set the Parameters\n",
    "    hmm.e_obj.set_params(e_rate = e_rate, e_rate_ref = e_rate_ref)\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    \n",
    "    hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "    \n",
    "def multi_run(fun, prms, processes = 4):\n",
    "    \"\"\"Implementation of running in Parallel.\n",
    "    fun: Function\n",
    "    prms: The Parameter Files\n",
    "    processes: How many Processes to use\"\"\"\n",
    "    print(f\"Running {len(prms)} jobs in parallel.\")\n",
    "    \n",
    "    with mp.Pool(processes = processes) as pool:\n",
    "        results = pool.starmap(fun, prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Single Ancient Individual Readcount Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_param_list_rc_individual(iid, n_ref=503, save=True, save_fp=False, prefix_out= \"e01/\",\n",
    "                      path_output=\"./Empirical/1240k/\", exclude_pops = [],\n",
    "                      roh_in = 100, roh_out= 100, roh_jump=385, e_rate = 0.01, e_rate_ref = 0.001):\n",
    "    \"\"\"Return List of Parameters for individual iid at Chromosome 1-23, which will be input for Starmap\"\"\"\n",
    "    ch_list = range(1, 23) ### List of All Chromosomes\n",
    "    prms = []\n",
    "\n",
    "    for ch in ch_list:\n",
    "        new_par = [iid, ch, n_ref, save, save_fp, path_output, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, e_rate_ref]\n",
    "        prms.append(new_par)  # Append to the Parameters\n",
    "        \n",
    "    assert(len(prms[0]) == 13)  # The RC function takes 13 Parameters as input\n",
    "    return prms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prms = give_param_list_rc_individual(iid = \"MA89\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_run(analyze_individual_rc, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MA89',\n",
       " 1,\n",
       " 503,\n",
       " True,\n",
       " False,\n",
       " './Empirical/1240k/',\n",
       " [],\n",
       " 'e01/',\n",
       " 100,\n",
       " 100,\n",
       " 385,\n",
       " 0.01,\n",
       " 0.001]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear-State Speed-Up\n",
      "Loaded Pre Processing Model: SardHDF5\n",
      "\n",
      "Loaded 1145647 variants\n",
      "Loaded 4616 individuals\n",
      "HDF5 loaded from ./Data/Marcus2019_1240k/mod_reich_sardinia_ancients_rev_mrg_dedup_3trm_anno.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 503 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/Eur1240chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77650\n",
      "Nr of Matching Refs: 77606 / 77650\n",
      "Full Intersection Ref/Alt Identical: 77553 / 77650\n",
      "503 / 503 Individuals included in Reference\n",
      "Extraction of 1006 Haplotypes Complete!\n",
      "Markers called 58903 / 77553\n",
      "Successfully saved to: ./Empirical/1240k/MA89/chr3/e01/\n",
      "Loading Readcounts...\n",
      "Successfully loaded Data from: ./Empirical/1240k/MA89/chr3/e01/\n",
      "Loaded Emission Model: readcount\n",
      "Loaded Transition Model: model\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 265\n",
      "Maximum Gap: 0.2681 cM\n",
      "Reference Number: 1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./Python3/hmm_inference.py:206: RuntimeWarning: invalid value encountered in log\n",
      "  end_p0 = np.log(end_p)  # Go to Log Space\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(1007, 58903, 3)\n",
      "Loaded Observations:\n",
      "(2, 58903)\n",
      "Log likelihood Path: nan\n",
      "Saved to: ./Empirical/1240k/MA89/chr3/e01/viterbi_path.csv\n",
      "Finished Calculation Viterbi Path: [0 0 0 ... 0 0 0]\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 265\n",
      "Maximum Gap: 0.2681 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(1007, 58903, 3)\n",
      "Loaded Observations:\n",
      "(2, 58903)\n",
      "Reference Number: 1006\n",
      "Total Log likelihood: -32920.045\n",
      "Finished Calculation State Posteriors\n",
      "Saved Zero State Posterior to ./Empirical/1240k/MA89/chr3/e01/.\n",
      "Successfully loaded for PP. from ./Empirical/1240k/MA89/chr3/e01/\n",
      "Fraction Markers in ROH: 0.4840\n",
      "Merged n=3 gaps < 0.01 M\n",
      "Called n=3 ROH Blocks > 1.0 cM\n",
      "Longest Block: 40.351\n",
      "Successfully saved to ./Empirical/1240k/MA89/chr3/e01/roh.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_up_roh_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b4ff0dece666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_individual_rc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Single Test Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-34c854f16423>\u001b[0m in \u001b[0;36manalyze_individual_rc\u001b[0;34m(iid, ch, n_ref, save, save_fp, path_output, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, e_rate_ref)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m### Split up the (only works for Mosaic so be careful when transferring this code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0msplit_up_roh_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_mosaic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m#########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_up_roh_df' is not defined"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(*prms[2])  # Single Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

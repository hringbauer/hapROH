{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH for individuals within a Eigenstrat folder\n",
    "Notebooks that import the code for the calling ROHs on pseudohaploid genotype individuals, and then a function to parallelize it.\n",
    "\n",
    "Very similar to parallel_mosaic_callroh.ipynb\n",
    "\n",
    "\n",
    "@Author: Harald Ringbauer, September 2019\n",
    "All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0408.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "# Assume that now we are in the root directory\n",
    "sys.path.append(\"./Python3/\")\n",
    "from hmm_inference import HMM_Analyze   # The HMM core object\n",
    "\n",
    "sys.path.append(\"./PackagesSupport/parallel_runs/\")\n",
    "sys.path.append(\"./PackagesSupport/\")\n",
    "from helper_functions import prepare_path, multi_run, combine_individual_data\n",
    "from pp_individual_roh_csvs import create_combined_ROH_df, give_iid_paths, pp_individual_roh\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_chromosome_rc(iid, ch=3, n_ref=503, save=True, save_fp=False, exclude_pops=[],\n",
    "                          h5_path_targets = \"./Data/SA_1240kHDF5/IPK12.h5\",\n",
    "                          base_out_folder=\"./Empirical/Eigenstrat/Reichall/test/\", prefix_out=\"\",\n",
    "                          roh_in=100, roh_out=100, roh_jump=300, e_rate=0.01, e_rate_ref=0.01, \n",
    "                          max_gap=0, logfile=True, e_model=\"readcount\", readcounts=True):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on eigenstrat data\n",
    "    Wrapper for HMM Class. Takes 13 Parameters\"\"\"\n",
    "    \n",
    "    ### The folder on what to run the Data on (PERMANENTLY set here to fixed loaction)\n",
    "    ## What Eigenstrat File to run on:\n",
    "    #h5_path_targets = \"./Data/SA_1240kHDF5/MA577_1240k.h5\"\n",
    "    \n",
    "    ## Reference Files:\n",
    "    h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr\" \n",
    "    meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    path_out = prepare_path(base_out_folder, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=e_model, post_model=\"Standard\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    ### Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts = readcounts, destroy_phase=False,\n",
    "                base_out_folder=base_out_folder, prefix_out_data=prefix_out, excluded=exclude_pops)\n",
    "    \n",
    "    ### Set the paths to target & ref\n",
    "    hmm.p_obj.set_params(h5_path1000g = h5_path1000g, meta_path_ref = meta_path_ref, h5_path_targets = h5_path_targets)\n",
    "    \n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    hmm.load_secondary_objects()\n",
    "\n",
    "    ### Set the Parameters\n",
    "    hmm.e_obj.set_params(e_rate = e_rate, e_rate_ref = e_rate_ref)\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    hmm.post_obj.set_params(max_gap=max_gap)\n",
    "    \n",
    "    ### hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "                         \n",
    "#########################################################\n",
    "def analyze_individual_rc(iid, chs=range(1,23), n_ref=2504, save=True, save_fp=False, \n",
    "                          exclude_pops=[], h5_path_targets = \"./Data/SA_1240kHDF5/IPK12.h5\", \n",
    "                          base_out_folder=\"./Empirical/1240k/SA_Readcounts/\", prefix_out=\"\", roh_in=100, roh_out=100, \n",
    "                          roh_jump=300, e_rate=0.01, e_rate_ref=0.01, max_gap=0, logfile=True, \n",
    "                          output=True, processes=5, delete=True, e_model=\"readcount\", readcounts=True):\n",
    "    \"\"\"Analyze a full single individual in a parallelized fasion. Run all Chromosome analyses in parallel\n",
    "    Wrapper for analyze_chromosome_gt.\n",
    "    logfile: Whether to use a logfile\n",
    "    output: Whether to print general Output\"\"\"\n",
    "                            \n",
    "    if output == True:\n",
    "        print(f\"Doing Individual {iid}...\")\n",
    "    \n",
    "    ### Prepare the Parameters for that Indivdiual\n",
    "    prms = [[iid, ch, n_ref, save, save_fp, exclude_pops, h5_path_targets, base_out_folder, prefix_out,\n",
    "         roh_in, roh_out, roh_jump, e_rate, e_rate_ref, max_gap, logfile, e_model, readcounts] for ch in chs] \n",
    "                            \n",
    "    ### Run the analysis in parallel\n",
    "    multi_run(analyze_chromosome_rc, prms, processes = processes)\n",
    "                            \n",
    "    ### Merge results for that Individual\n",
    "    combine_individual_data(base_out_folder, iid=iid, delete=delete, chs=chs, prefix_out=prefix_out)                  \n",
    "    return #prms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call ROH single Individual\n",
    "For reanalysis with delete=False (saves all data) to plot that indivdual / further analysis of posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Individual Loschbour...\n",
      "Running 22 jobs in parallel.\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Loschbour/chr1/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Loschbour/chr4/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(iid=\"Loschbour\", chs=range(1,23), processes=2, h5_path_targets = \"./Data/SA_1240kHDF5/Loschbour.h5\",\n",
    "                      delete=False, logfile=True, n_ref=2504) #Goyet_final.SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mini Area 51: Run one Chromosome:\n",
    "analyze_chromosome_rc(iid=\"Loschbour\", ch=20, n_ref=2504, save=True, save_fp=False, exclude_pops=[], \n",
    "                      base_out_folder=\"./Empirical/1240k/SA_Readcounts/\", h5_path_targets = \"./Data/SA_1240kHDF5/Loschbour.h5\",\n",
    "                      prefix_out=\"\", roh_in=100, roh_out=100, roh_jump=300, e_rate=0.01, e_rate_ref=0.01, \n",
    "                      max_gap=0, logfile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Downsampled Coverage Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iid = \"IPK12\"   #['IPY10', 'IPK12', 'MA577', '894', '895']\n",
    "#down_sampling_covs = np.geomspace(0.04, 1.0, 10)\n",
    "iid = \"Loschbour\"\n",
    "down_sampling_covs=np.geomspace(0.01, 1.0, 10)\n",
    "samples = np.array([iid + f\"{c:.4f}\" for c in down_sampling_covs])   # Numpy Array for better slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_individual_rc(iid=samples[0][:10], chs=range(20,21), processes=3,\n",
    "                          h5_path_targets = \"./Data/SA_1240kHDF5/Loschbour_downsample.h5\",\n",
    "                          base_out_folder=\"./Empirical/1240k/SA_Readcounts/Downsample_Loschbour/\",\n",
    "                          delete=False, logfile=False, n_ref=2504) #Goyet_final.SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Individual Loschbour0...\n",
      "Running 22 jobs in parallel.\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour/Loschbour0/chr1/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour/Loschbour0/chr4/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "for sample in samples[:]:\n",
    "    analyze_individual_rc(iid=sample[:10], chs=range(1,23), processes=2,\n",
    "                          h5_path_targets = \"./Data/SA_1240kHDF5/Loschbour_downsample.h5\",\n",
    "                          base_out_folder=\"./Empirical/1240k/SA_Readcounts/Downsample_Loschbour/\",\n",
    "                          delete=False, logfile=True, n_ref=2504) #Goyet_final.SG\n",
    "print(f\"Finished Run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Downsampled Haploid Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid = \"Loschbour\"   #['IPY10', 'IPK12', 'MA577', '894', '895']\n",
    "down_sampling_covs = np.linspace(0.3, 1.0, 8)\n",
    "samples = np.array([iid + f\"{c:.3f}\" for c in down_sampling_covs])   # Numpy Array for better slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test single Individual\n",
    "analyze_individual_rc(iid=samples[0][:10], chs=range(1,2), processes=3,\n",
    "                      h5_path_targets = \"./Data/SA_1240kHDF5/Loschbour_downsample_ph.h5\",\n",
    "                      base_out_folder=\"./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/\",\n",
    "                      delete=False, logfile=False, n_ref=2504, e_model=\"haploid\", readcounts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Individual Loschbour0...\n",
      "Running 22 jobs in parallel.\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/Loschbour0/chr3/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/Loschbour0/chr1/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/Loschbour0/chr4/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/Loschbour0/chr2/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/Loschbour0/chr6/hmm_run_log.txt\n",
      "Set Output Log path: ./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/Loschbour0/chr5/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "### Run all Individuals\n",
    "for sample in samples[:]:\n",
    "    analyze_individual_rc(iid=sample[:10], chs=range(1,23), processes=6,\n",
    "                          h5_path_targets = \"./Data/SA_1240kHDF5/Loschbour_downsample_ph.h5\",\n",
    "                          base_out_folder=\"./Empirical/1240k/SA_Readcounts/Downsample_Loschbour_ph/\",\n",
    "                          delete=False, logfile=True, n_ref=2504, e_model=\"haploid\", readcounts=False) #Goyet_final.SG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Process the individual output files\n",
    "(Standalone from here - but **need imports** from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iids = np.array(['IPY10', 'IPK12', 'MA577', '894', '895'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = give_iid_paths(iids, base_folder=\"./Empirical/1240k/SA_Readcounts/\", suffix='_roh_full.csv')\n",
    "df1 = create_combined_ROH_df(paths, iids, pops=iids, min_cm=[4,8,12], snp_cm=50, gap=0.5, output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"iid\"] = [\"IPK12.SG\", \"MA577.SG\", \"Yaghan894.SG\", \"IPY10.SG\", \"Yaghan895.SG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 5 Individuals to ./Empirical/1240k/SA_Readcounts/combined_roh05.csv\n"
     ]
    }
   ],
   "source": [
    "path_save = \"./Empirical/1240k/SA_Readcounts/combined_roh05.csv\"\n",
    "df1.to_csv(path_save, sep=\"\\t\", index=False)\n",
    "print(f\"Successfully saved {len(df1)} Individuals to {path_save}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check ROH against ROH inferred from pseudohaploid Eigenstrat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load also the original Dataframe\n",
    "df1 = pd.read_csv(\"./Empirical/1240k/SA_Readcounts/combined_roh05.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check against Original Dataframe\n",
    "df_es = pd.read_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh05.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df1, df_es, on=\"iid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pop</th>\n",
       "      <th>max_roh_x</th>\n",
       "      <th>sum_roh_x</th>\n",
       "      <th>n_roh_x</th>\n",
       "      <th>max_roh_y</th>\n",
       "      <th>sum_roh_y</th>\n",
       "      <th>n_roh_y</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>age</th>\n",
       "      <th>study</th>\n",
       "      <th>clst</th>\n",
       "      <th>mean_cov</th>\n",
       "      <th>n_cov_snp</th>\n",
       "      <th>include_alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IPK12.SG</td>\n",
       "      <td>IPK12</td>\n",
       "      <td>27.044898</td>\n",
       "      <td>356.677888</td>\n",
       "      <td>39</td>\n",
       "      <td>27.352100</td>\n",
       "      <td>405.611886</td>\n",
       "      <td>46</td>\n",
       "      <td>-52.350000</td>\n",
       "      <td>-70.966667</td>\n",
       "      <td>863.0</td>\n",
       "      <td>delaFuentePNAS2018</td>\n",
       "      <td>Chile_Kaweskar_1000BP.SG</td>\n",
       "      <td>7.800</td>\n",
       "      <td>1142798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA577.SG</td>\n",
       "      <td>MA577</td>\n",
       "      <td>35.407996</td>\n",
       "      <td>256.236129</td>\n",
       "      <td>27</td>\n",
       "      <td>35.410404</td>\n",
       "      <td>310.096593</td>\n",
       "      <td>36</td>\n",
       "      <td>-54.875556</td>\n",
       "      <td>-68.136389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RaghavanScience2015</td>\n",
       "      <td>Argentina_Fuego_Patagonian.SG</td>\n",
       "      <td>2.078</td>\n",
       "      <td>925364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yaghan894.SG</td>\n",
       "      <td>894</td>\n",
       "      <td>24.934506</td>\n",
       "      <td>186.756126</td>\n",
       "      <td>22</td>\n",
       "      <td>25.148904</td>\n",
       "      <td>263.349718</td>\n",
       "      <td>36</td>\n",
       "      <td>-54.875556</td>\n",
       "      <td>-68.136389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RaghavanScience2015</td>\n",
       "      <td>Argentina_Fuego_Patagonian.SG</td>\n",
       "      <td>1.137</td>\n",
       "      <td>618185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yaghan895.SG</td>\n",
       "      <td>895</td>\n",
       "      <td>20.032197</td>\n",
       "      <td>153.533948</td>\n",
       "      <td>23</td>\n",
       "      <td>20.316303</td>\n",
       "      <td>253.176316</td>\n",
       "      <td>41</td>\n",
       "      <td>-54.875556</td>\n",
       "      <td>-68.136389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RaghavanScience2015</td>\n",
       "      <td>Argentina_Fuego_Patagonian.SG</td>\n",
       "      <td>1.446</td>\n",
       "      <td>658876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            iid    pop  max_roh_x   sum_roh_x  n_roh_x  max_roh_y   sum_roh_y  \\\n",
       "0      IPK12.SG  IPK12  27.044898  356.677888       39  27.352100  405.611886   \n",
       "1      MA577.SG  MA577  35.407996  256.236129       27  35.410404  310.096593   \n",
       "2  Yaghan894.SG    894  24.934506  186.756126       22  25.148904  263.349718   \n",
       "3  Yaghan895.SG    895  20.032197  153.533948       23  20.316303  253.176316   \n",
       "\n",
       "   n_roh_y        lat        lon    age                study  \\\n",
       "0       46 -52.350000 -70.966667  863.0   delaFuentePNAS2018   \n",
       "1       36 -54.875556 -68.136389  100.0  RaghavanScience2015   \n",
       "2       36 -54.875556 -68.136389  100.0  RaghavanScience2015   \n",
       "3       41 -54.875556 -68.136389  100.0  RaghavanScience2015   \n",
       "\n",
       "                            clst  mean_cov  n_cov_snp  include_alt  \n",
       "0       Chile_Kaweskar_1000BP.SG     7.800    1142798            1  \n",
       "1  Argentina_Fuego_Patagonian.SG     2.078     925364            1  \n",
       "2  Argentina_Fuego_Patagonian.SG     1.137     618185            1  \n",
       "3  Argentina_Fuego_Patagonian.SG     1.446     658876            1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge = pd.merge(df1[[\"iid\", \"max_roh\", \"sum_roh\",\"n_roh\"]], df_anno, on=\"iid\")\n",
    "#df_merge.to_csv(\"./Empirical/Eigenstrat/Reichall/combined_roh_test2.csv\", index=\"False\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51\n",
    "Area to test code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test one Eigenstrat individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

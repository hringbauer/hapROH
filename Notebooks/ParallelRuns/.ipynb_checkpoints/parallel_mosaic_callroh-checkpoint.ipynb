{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel\n",
    "Includes Notebooks that import the code for the calling ROHs on Mosaics, and then functions for various cases to parallelize it\n",
    "\n",
    "@Author: Harald Ringbauer, June 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VioletQueen\n",
      "/home/harald/git/HAPSBURG\n",
      "CPU Count: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "#sys.path.append(\"./Python3/create1000G_Mosaic/\")  # Since now we are in the Root Directory\n",
    "#from createMosaicsMulti import Mosaic_1000G_Multi  # Import the object that can create the Multiruns\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions and Paralellize Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_roh_df(base_path, path_out, iid):\n",
    "    \"\"\"Splits up the ROH-dataframe.\n",
    "    base_path: Where to find roh_info.csv\n",
    "    path_out: Where to save roh_gt to\n",
    "    iid: Which Individual to extract from roh_info.csv\"\"\"\n",
    "    #path = base_path + \"roh_info.csv\"\n",
    "    path = os.path.join(base_path, \"roh_info.csv\")\n",
    "    dft = pd.read_csv(path, sep=\"\\t\")  # Load the Meta File\n",
    "\n",
    "    save_df = dft[dft[\"iid\"] == iid]\n",
    "    save_path = os.path.join(path_out, \"roh_gt.csv\")\n",
    "    save_df.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "    #print(f\"Saved to {save_path}\")\n",
    "    return\n",
    "\n",
    "def prepare_path(path_mosaic, iid, ch, prefix_out, logfile=True):\n",
    "    \"\"\"Prepare the path and pipe printing for one Individual\n",
    "    logfile: Whether to pipe output to log-file\"\"\"   \n",
    "    \n",
    "    if not os.path.exists(path_mosaic):\n",
    "            raise RuntimeError(f\"Path {path_mosaic} not Found. Check!\")\n",
    "    \n",
    "    #path_log = path_mosaic + \"output/\" + iid + \"/chr\" + str(ch) + \"/\" + prefix_out\n",
    "    path_out = os.path.join(path_mosaic, \"output\", iid, \"chr\" + str(ch), prefix_out, \"\")\n",
    "    if not os.path.exists(path_out):\n",
    "            os.makedirs(path_out)\n",
    "    \n",
    "    ##### The Log File.  For debugging comment out!!!! ####\n",
    "    if logfile == True:\n",
    "        #path_log = path_log + \"hmm_run_log.txt\"\n",
    "        path_log = os.path.join(path_out, \"hmm_run_log.txt\")\n",
    "        print(f\"Set Output Log path: {path_log}\")\n",
    "        sys.stdout = open(path_log, 'w') \n",
    "    return path_out\n",
    "    \n",
    "def analyze_individual(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                       path_mosaic=\"./Simulated/1000G_Mosaic/TSI/ch3_5cm/\",\n",
    "                       exclude_pops=[\"TSI\", ], prefix_out=\"\", \n",
    "                       roh_in=1, roh_out=10, roh_jump=100, e_rate=0.001, logfile=True):\n",
    "    \"\"\"Run the analysis for one individual and chromosome.\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Prepare output folder, and pipe output to log file if wanted\n",
    "    path_out = prepare_path(path_mosaic, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    ### Do the full HMM Analysis\n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"diploid_gt\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)  \n",
    "    # \"diploid_gt\" for analysis of dpld. \"haploid\" for analysis of haploid\n",
    "\n",
    "    ### Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(destroy_phase=True, prefix_out_data=prefix_out,\n",
    "                        excluded=exclude_pops, h5_path_targets=path_mosaic + \"data.h5\",\n",
    "                        base_out_folder=os.path.join(path_mosaic, \"output\",\"\"))\n",
    "    ### Set paths for reference: DELETE when run for with European Reference!!\n",
    "    hmm.p_obj.set_params(h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr\", \n",
    "                         meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\")\n",
    "    \n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    hmm.load_secondary_objects()  # Load transition, emission and postprocessing objects\n",
    "    \n",
    "    ### Set the Parameters\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    hmm.e_obj.set_params(e_rate=e_rate)\n",
    "    \n",
    "    #hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, path_out, iid)\n",
    "    \n",
    "    print(f\"Analysis of {iid} and Chr. {ch} successfully concluded!\")\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "### Do the Read Count Analysis Function\n",
    "\n",
    "def analyze_individual_rc(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                          path_mosaic=\"./Simulated/1000G_Mosaic/TSI/RC1.0/ch3_5cm/\",\n",
    "                          exclude_pops=[\"TSI\", ], prefix_out=\"\",\n",
    "                          roh_in=1, roh_out=10, roh_jump=100, e_rate=0.01, e_rate_ref=0.001, logfile=True):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on readcount data\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    path_out = prepare_path(path_mosaic, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"readcount\", post_model=\"Standard\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts=True, destroy_phase=False,\n",
    "                         prefix_out_data=prefix_out, excluded=exclude_pops,\n",
    "                         h5_path_targets=path_mosaic + \"data.h5\",\n",
    "                         base_out_folder=os.path.join(path_mosaic, \"output\",\"\"))\n",
    "    \n",
    "    ### Set paths for reference: DELETE when run for with European Reference!!\n",
    "    hmm.p_obj.set_params(h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr\", \n",
    "                         meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\")\n",
    "    \n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    hmm.load_secondary_objects()\n",
    "\n",
    "    ### Set the Parameters\n",
    "    hmm.e_obj.set_params(e_rate=e_rate, e_rate_ref=e_rate_ref)\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    \n",
    "    #hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, path_out, iid)\n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "    \n",
    "def multi_run(fun, prms, processes = 4):\n",
    "    \"\"\"Implementation of running in Parallel.\n",
    "    fun: Function\n",
    "    prms: The Parameter Files\n",
    "    processes: How many Processes to use\"\"\"\n",
    "    print(f\"Running {len(prms)} jobs in parallel.\")\n",
    "    \n",
    "    with mp.Pool(processes = processes) as pool:\n",
    "        results = pool.starmap(fun, prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parallel Calling on TSI (single Target HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 500  # 2504 500\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"test_d/\"  # allRef\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 300\n",
    "e_rate = 0.001  # The Error Rate\n",
    "n = 100\n",
    "logfile = False\n",
    "\n",
    "lengths = [0, 2, 4, 6, 8, 10] # Which Block Lengths to test\n",
    "lengths = [4, 0]  # Only do the relevant ones for key performance testing\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids:\n",
    "        new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "        prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 13 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid0/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid90/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_2cm/output/iid20/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid30/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid60/chr/3/allRef/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")\n",
    "print(\"Run complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a single example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Low-Mem Cython Linear Speed Up.\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 2504 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77652\n",
      "Nr of Matching Refs: 77652 / 77652\n",
      "Full Intersection Ref/Alt Identical: 77652 / 77652\n",
      "2397 / 2504 Individuals included in Reference\n",
      "Extraction of 2 Haplotypes Complete!\n",
      "Extraction of 1000 Haplotypes Complete!\n",
      "Reduced to markers called 77652 / 77652\n",
      "(Fraction SNP: 1.0)\n",
      "Successfully saved to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/\n",
      "Shuffling phase of target...\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/\n",
      "Loaded Emission Model: diploid_gt\n",
      "Loaded Transition Model: model\n",
      "Loaded Post Processing Model: Standard\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 214\n",
      "Maximum Gap: 0.2348 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(1001, 77652)\n",
      "Loaded Observations:\n",
      "(2, 77652)\n",
      "Memory Usage: 920.244224 mB\n",
      "Reference Number: 1000\n",
      "Total Log likelihood: -35651.505\n",
      "Memory Usage: 924.50816 mB\n",
      "Finished Calculation State Posteriors\n",
      "Saved Zero State Posterior to ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/\n",
      "Fraction Markers in ROH: 0.3669\n",
      "Merged n=0 gaps < 0.01 M\n",
      "Called n=5 ROH Blocks > 1.0 cM\n",
      "Longest Block: 4.472\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/roh.csv\n",
      "Analysis of iid0 and Chr. 3 successfully concluded!\n",
      "CPU times: user 25.7 s, sys: 1.07 s, total: 26.8 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analyze_individual(*prms[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROHS Blocks within multiple target HDF5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"ROH1000/\" # Initially: None\n",
    "\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 1000\n",
    "e_rate = 0.001  # The Error Rate\n",
    "\n",
    "n = 100\n",
    "#targets = [\"CHB\", \"CLM\", \"YRI\"]\n",
    "targets = [\"TSI5\",]\n",
    "lengths = [0, 2, 4, 6, 8, 10]\n",
    "logfile = True\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for t in targets:\n",
    "    base_path1 = base_path + t + \"/\"\n",
    "    folders = [base_path1 + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "    for f in folders:\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi_run(analyze_individual, [prms[0],], processes = 1)  # To Trouble Shoot\n",
    "len(prms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid57/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid33/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid14/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid38/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid19/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid76/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid0/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid95/chr3/ROH1000/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for multiple error levels (and multiple lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.01  # The Error Rate\n",
    "n = 100\n",
    "prefix_out = \"e01/\"   # Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] # For chromosomes\n",
    "error_vec = np.logspace(-3,-1, 8)\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "logfile = True\n",
    "#folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for l in lengths:\n",
    "    for e in error_vec:\n",
    "        e_print = str(round(e, 4)).split(\".\")[1] # Extract four digits after decimal         \n",
    "        f = base_path + \"ch3_\" + str(l) + \"cm/error/\" + e_print + \"/\"   \n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4800 jobs in parallel.\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/001/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0072/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0019/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0139/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0037/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0518/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/1/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0019/output/iid0/chr3/e01/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for multiple downsample levels (and multiple lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"   #TSI5 CHB\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.001    # The Error Rate\n",
    "n = 100\n",
    "prefix_out = \"diploidGT/\"   #  e01/ Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] \n",
    "missing_vec = np.linspace(0.1, 1.0, 10)\n",
    "#missing_vec = np.array([0.1, 0.2])\n",
    "logfile = True\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for l in lengths:\n",
    "    for m in missing_vec:\n",
    "        m_print = str(round(m, 4)).split(\".\")[1] # Extract four digits after decimal         \n",
    "        f = base_path + \"ch3_\" + str(l) + \"cm/missing/\" + m_print + \"/\"   \n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 6000 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/1/output/iid0/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/missing/1/output/iid0/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/3/output/iid50/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/8/output/iid50/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/6/output/iid0/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/missing/3/output/iid50/chr3/diploidGT/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for ReadCount data (Normal or Lambda)\n",
    "For Lambda change folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"   #TSI5 CHB\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.001    # The Error Rate for Read Count\n",
    "e_rate_ref = 0.001 # The  Error Rate for Reference Genotypes\n",
    "n = 100\n",
    "prefix_out = \"test/\"   #  e01/ e001/ Error saved in folder structure ROH385\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] \n",
    "lengths =[4,]\n",
    "\n",
    "#mean_rcs = np.linspace(2, 6, 5)\n",
    "mean_rcs = np.linspace(0.1, 1, 10)\n",
    "mean_rcs= [mean_rcs[-1],]\n",
    "logfile = False\n",
    "\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for m_rc in mean_rcs:\n",
    "    for l in lengths:      \n",
    "        f = base_path + \"lambda_rc\" + f\"{m_rc:.1f}\" + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, e_rate_ref, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0]) == 14)  # The RC function takes 14 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 6000 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.1/ch3_6cm/output/iid76/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.1/ch3_10cm/output/iid64/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.1/ch3_0cm/output/iid0/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_10cm/output/iid28/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_2cm/output/iid52/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.1/ch3_2cm/output/iid88/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.2/ch3_6cm/output/iid40/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/CHB/lambda_rc0.3/ch3_2cm/output/iid16/chr3/ROH1000/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual_rc, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run for single individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Low-Mem Cython Linear Speed Up.\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "\n",
      "Loaded 77650 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 2504 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77650\n",
      "Nr of Matching Refs: 77650 / 77650\n",
      "Full Intersection Ref/Alt Identical: 77650 / 77650\n",
      "2397 / 2504 Individuals included in Reference\n",
      "Extraction of 2 Haplotypes Complete!\n",
      "Extraction of 1006 Haplotypes Complete!\n",
      "Reduced to markers called 38032 / 77650\n",
      "(Fraction SNP: 0.48978750804893756)\n",
      "Successfully saved to: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/test/\n",
      "Loading Readcounts...\n",
      "Mean Readcount markers loaded: 2.04536\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/test/\n",
      "Loaded Emission Model: readcount\n",
      "Loaded Transition Model: model\n",
      "Loaded Post Processing Model: Standard\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 349\n",
      "Maximum Gap: 0.3916 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(1007, 38032)\n",
      "Loaded Observations:\n",
      "(2, 38032)\n",
      "Memory Usage: 483.569664 mB\n",
      "Reference Number: 1006\n",
      "Total Log likelihood: -18753.948\n",
      "Memory Usage: 489.71776 mB\n",
      "Finished Calculation State Posteriors\n",
      "Saved Zero State Posterior to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/test/.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/test/\n",
      "Fraction Markers in ROH: 0.3208\n",
      "Merged n=0 gaps < 0.01 M\n",
      "Called n=5 ROH Blocks > 1.0 cM\n",
      "Longest Block: 4.590\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_4cm/output/iid0/chr3/test/roh.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iid0/roh_gt.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-bb3fdc924d25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_individual_rc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-7947a9b150a6>\u001b[0m in \u001b[0;36manalyze_individual_rc\u001b[0;34m(iid, ch, n_ref, save, save_fp, path_mosaic, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, e_rate_ref, logfile)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m### Split up the (only works for Mosaic so be careful when transferring this code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0msplit_up_roh_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_mosaic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m#########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-7947a9b150a6>\u001b[0m in \u001b[0;36msplit_up_roh_df\u001b[0;34m(base_path, path_out, iid)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#    iid + \"/chr\" + str(ch) + \"/\" + prefix_out + \"roh_gt.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"roh_gt.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msave_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(f\"Saved to {save_path}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iid0/roh_gt.csv'"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(*prms[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single parameter run\n",
    "Set logfile=False in analyze_individual to print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test/why/not/lol.txt'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"./test/why/not\",\"lol.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_8cm/output/iid0/chr3/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

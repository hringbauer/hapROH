{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel\n",
    "Has Notebooks that import the code for the calling ROHs on Mosaics, and then functions for various cases to parallelize it\n",
    "\n",
    "@Author: Harald Ringbauer, June 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midway jnovmbre partition detected.\n",
      "/project/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "if socket.gethostname() == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket.gethostname() == \"midway2-0401.rcc.local\":\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./Python3/\")  # Since now we are in the Root Directory\n",
    "from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "#sys.path.append(\"./Python3/create1000G_Mosaic/\")  # Since now we are in the Root Directory\n",
    "#from createMosaicsMulti import Mosaic_1000G_Multi  # Import the object that can create the Multiruns\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_roh_df(base_path, iid, prefix_out=\"\"):\n",
    "    \"\"\"Splits up the ROH-dataframe\"\"\"\n",
    "    path = base_path + \"roh_info.csv\"\n",
    "    dft = pd.read_csv(path, sep=\"\\t\")  # Load the Meta File\n",
    "\n",
    "    save_df = dft[dft[\"iid\"] == iid]\n",
    "    save_path = base_path + \"output/\" + \\\n",
    "        iid + \"/chr\" + str(ch) + \"/\" + prefix_out + \"roh_gt.csv\"\n",
    "    save_df.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "    return\n",
    "\n",
    "def analyze_individual(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                       path_mosaic=\"./Simulated/1000G_Mosaic/TSI/ch3_5cm/\",\n",
    "                       exclude_pops=[\"TSI\", ], prefix_out=\"\", \n",
    "                       roh_in =1, roh_out=10, roh_jump=100):\n",
    "    \"\"\"Run the analysis for one individual and chromosome.\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ########### Pipe the output    \n",
    "    if not os.path.exists(path_mosaic):\n",
    "            raise RuntimeError(f\"Path {path_mosaic} not Found. Check!\")\n",
    "    \n",
    "    path_log = path_mosaic + \"output/\" + iid + \"/chr\" + str(ch) + \"/\" + prefix_out\n",
    "    \n",
    "    if not os.path.exists(path_log):\n",
    "            os.makedirs(path_log)\n",
    "    path_log = path_log + \"hmm_run_log.txt\"\n",
    "    #if os.path.isdir(path_log):\n",
    "    #     os.rmdir(path_log)   # From a previous whoopsie-daisy\n",
    "    print(f\"Output Log path: {path_log}\")\n",
    "    \n",
    "    sys.stdout = open(path_log, 'w')  # Create the log file\n",
    "    \n",
    "    ### Do the full HMM Analysis\n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_folder(path_mosaic)         # Set the Folder\n",
    "    hmm.p_obj.set_prefix_out_data(prefix_out)\n",
    "    hmm.p_obj.set_exclude_pops(pops=exclude_pops)\n",
    "\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    hmm.load_emission_model()\n",
    "    hmm.load_transition_model()\n",
    "\n",
    "    hmm.set_diploid_observations()             # To diploidize Individuals\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, iid, prefix_out)\n",
    "    \n",
    "    print(f\"Analysis of {iid} and Chr. {ch} successfully concluded!\")\n",
    "    \n",
    "def multi_run(fun, prms, processes = 4):\n",
    "    \"\"\"Implementation of running in Parallel.\n",
    "    fun: Function\n",
    "    prms: The Parameter Files\n",
    "    processes: How many Processes to use\"\"\"\n",
    "    print(f\"Running {len(prms)} jobs in parallel.\")\n",
    "    \n",
    "    with mp.Pool(processes = processes) as pool:\n",
    "        results = pool.starmap(fun, prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parallel Calling on TSI (single Target HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"ROHin200/\"\n",
    "roh_in = 200 \n",
    "roh_out= 200\n",
    "roh_jump= 385\n",
    "\n",
    "n = 100\n",
    "#lengths = [0]  # For false positives\n",
    "lengths = [0, 2, 4, 6, 8, 10] # For chromosomes\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids:\n",
    "        new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump]\n",
    "        prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==11)   # The function takes 11 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 jobs in parallel.\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid19/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid57/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid95/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid76/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid0/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid38/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid14/chr3/ROHin200/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid33/chr3/ROHin200/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")\n",
    "print(\"Run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROHS Blocks within multiple target HDF5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"\"\n",
    "\n",
    "n = 100\n",
    "targets = [\"CHB\", \"CLM\", \"YRI\"]\n",
    "lengths = [2, 4, 6, 8, 10]\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for t in targets:\n",
    "    base_path1 = base_path + t + \"/\"\n",
    "    folders = [base_path1 + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "    for f in folders:\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==8)   # The function takes 8 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1500 jobs in parallel.\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_2cm/output/iid0/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_2cm/output/iid47/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_2cm/output/iid94/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_4cm/output/iid88/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_4cm/output/iid41/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_6cm/output/iid35/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_6cm/output/iid82/chr3\n",
      "Setting output path...: ./Simulated/1000G_Mosaic/CHB/ch3_8cm/output/iid29/chr3\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting output path...: ./Simulated/1000G_Mosaic/TSI1/ch3_1cm/output/iid0/chr3\n"
     ]
    }
   ],
   "source": [
    "analyze_individual(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello. Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"hello. Blizzard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whoho\n"
     ]
    }
   ],
   "source": [
    "print(\"whoho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

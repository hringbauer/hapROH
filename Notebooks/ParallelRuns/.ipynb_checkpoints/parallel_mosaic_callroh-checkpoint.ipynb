{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel\n",
    "Import the code for calling ROHs on test cases (simulated mosaics), \n",
    "and then functions for various cases to parallelize it\n",
    "\n",
    "Original version with manual function is in ./Legacy\n",
    "\n",
    "@Author: Harald Ringbauer, February 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0404.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "sys.path.append(\"./package/\")  # Since now we are in the Root Directory\n",
    "#from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "\n",
    "#from PackagesSupport.parallel_runs.helper_functions import prepare_path, create_folders, postprocess_iid\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_chrom\n",
    "from hapsburg.PackagesSupport.parallel_runs.helper_functions import multi_run, split_up_roh_df  # Parallel Runs and forward ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parallel Calling on TSI (single Target HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "iids = [\"iid\" + str(i) for i in range(100)]   # List of iids to iterate over\n",
    "### Create list of IIDs and of Folders\n",
    "\n",
    "ch = 3 # For test case here: Only do Chromosome #3\n",
    "n_ref = 2504  # 2504 All 503 Europe/TSI\n",
    "save = True\n",
    "save_fp = False\n",
    "\n",
    "exclude_pops = [\"TSI\", ]\n",
    "\n",
    "e_model = \"haploid\"\n",
    "p_model = \"MosaicHDF5\"  \n",
    "readcounts = False\n",
    "destroy_phase=True\n",
    "\n",
    "post_model = \"Standard\"\n",
    "h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240int8/chr\" # Switch: Eur1240chr\n",
    "meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\"  # meta_df.csv for full 1000G\n",
    "\n",
    "roh_in = 1 \n",
    "roh_out = 20\n",
    "roh_jump = 300\n",
    "e_rate = 0.01  # The Error Rate\n",
    "e_rate_ref = 0.0\n",
    "max_gap = 0.00 # Gap Merging. In M\n",
    "#cutoffs = [0.9, 0.99, 0.9999, 0.99999]\n",
    "#cutoffs = [0.996, 0.997, 0.998, 0.999]\n",
    "#cutoffs = [0.998, 0.999, 0.9995]\n",
    "cutoffs=[0.999]\n",
    "l_cutoff = 0.01\n",
    "\n",
    "logfile = True\n",
    "#lengths = [0, 2, 4, 6, 8, 10] # Which Block Lengths to test\n",
    "lengths = [2,6,8,10]  # Relevant ones for key performance testing\n",
    "\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI6/\"\n",
    "\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders. # \"cm/missing/5/\"\n",
    "\n",
    "#########################################################\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "for f in folders: \n",
    "    path_targets = f + \"data.h5\"\n",
    "    base_out_folder = os.path.join(f, \"output\", \"\")\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        prefix_out = str(cutoff).replace(\".\", \"\") + \"/\"\n",
    "    \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, save, save_fp, n_ref, exclude_pops, e_model, p_model, readcounts, destroy_phase,\n",
    "            post_model, path_targets, h5_path1000g, meta_path_ref, base_out_folder, prefix_out,\n",
    "            roh_in, roh_out, roh_jump, e_rate, e_rate_ref, max_gap, cutoff, l_cutoff, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "        \n",
    "assert(len(prms[0])==25)   # Sanity Check\n",
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testrun on single Set of Parameters for TSI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "multi_run(hapsb_chrom, [prms[0]], processes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 400 total jobs; 4 in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/ch3_2cm/output/iid0/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/ch3_2cm/output/iid25/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/ch3_2cm/output/iid50/chr3/0999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/ch3_2cm/output/iid75/chr3/0999/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multi_run(hapsb_chrom, prms[:], processes = 4) # Or 20 processes for Europe #For all ref: 4 for everything, 8 for 0.5x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up ground truth ROH into according folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.58 s, sys: 240 ms, total: 2.82 s\n",
      "Wall time: 8.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Split up ground truth roh.csv \n",
    "#(to pack into output folder as well for easier comparison)\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids[:]:\n",
    "        for cutoff in cutoffs:\n",
    "            prefix_out = str(cutoff).replace(\".\", \"\") + \"/\"            \n",
    "            path_out = os.path.join(f, \"output\", iid, \"chr\"+str(ch), prefix_out)\n",
    "            split_up_roh_df(f, path_out, iid, \n",
    "                        file_in=\"roh_info.csv\", file_out=\"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up with no different Output Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 ms, sys: 12 ms, total: 202 ms\n",
      "Wall time: 220 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Split up ground truth roh.csv \n",
    "#(to pack into output folder as well for easier comparison)\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids[:]:\n",
    "        path_out = os.path.join(f, \"output\", iid, \"chr\"+str(ch), prefix_out)\n",
    "        split_up_roh_df(f, path_out, iid, \n",
    "                    file_in=\"roh_info.csv\", file_out=\"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Blizzard? WC3?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Blizzard? WC3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0402.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "import shutil as shutil\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "#sys.path.append(\"./package/\")  # Since now we are in the Root Directory.\n",
    "sys.path.insert(0,\"./package/\")  # Hack to get developer package\n",
    "#from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "\n",
    "#from PackagesSupport.parallel_runs.helper_functions import prepare_path, create_folders, postprocess_iid\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_chrom\n",
    "from hapsburg.PackagesSupport.parallel_runs.helper_functions import multi_run, split_up_roh_df  # Parallel Runs and forward ground truth\n",
    "from hapsburg.PackagesSupport.pp_individual_roh_csvs import merge_called_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the test case \n",
    "Vary Parameters and the suffixes to explore parameter range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "iids = [\"iid\" + str(i) for i in range(0,100)]   # List of iids to iterate over\n",
    "### Create list of IIDs and of Folders\n",
    "\n",
    "ch = 3 # For test case here: Only do Chromosome #3\n",
    "n_ref = 2504  # 2504 All 503 Europe/TSI 504 EAS\n",
    "diploid_ref = True\n",
    "save = True\n",
    "save_fp = False\n",
    "\n",
    "#exclude_pops = [\"TSI\", ]\n",
    "exclude_pops = []\n",
    "e_model = \"readcount\"\n",
    "p_model = \"MosaicHDF5\"  \n",
    "readcounts = True\n",
    "destroy_phase = False\n",
    "post_model = \"Standard\"\n",
    "h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240gzip/chr\" # Switch: Eur1240chr for classic\n",
    "meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\"  # meta_df.csv for full 1000G\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/\" # Simulated Mosaics\n",
    "#base_path=\"./Simulated/1000G_Mosaic/CLM/\" # Simulated Mosaics\n",
    "\n",
    "roh_in = 1   #1  New: 0.1\n",
    "roh_out = 20 # 20 Good: 10\n",
    "roh_jump = 300\n",
    "e_rate = 0.01  # The Error Rate\n",
    "e_rate_ref = 0.0\n",
    "max_gap = 0.0 # Gap Merging. In M\n",
    "cutoffs = [0.99]\n",
    "#cutoffs = [0.9]\n",
    "l_cutoff = 0.02\n",
    "logfile = True\n",
    "#lengths = [0, 2, 4, 6, 8, 10] # Which Block Lengths to test\n",
    "lengths = [0,4]  # 0, 4 Relevant ones for key performance testing\n",
    "#prefix_out = \"eas_ref/\" # Check as well below in loop!!!\n",
    "\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders. # \"cm/missing/5/\"\n",
    "\n",
    "#########################################################\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "for f in folders: \n",
    "    path_targets = f + \"data.h5\"\n",
    "    base_out_folder = os.path.join(f, \"output\", \"\")\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        prefix_out = \"c\" + str(cutoff).replace(\"0.\", \"\") + \"/\"\n",
    "        #prefix_out = \"c9/\"  # \"eas_ref.jump500/\"\n",
    "    \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, save, save_fp, n_ref, diploid_ref, exclude_pops, e_model, p_model, readcounts, destroy_phase,\n",
    "            post_model, path_targets, h5_path1000g, meta_path_ref, base_out_folder, prefix_out,\n",
    "            roh_in, roh_out, roh_jump, e_rate, e_rate_ref, max_gap, cutoff, l_cutoff, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "        \n",
    "assert(len(prms[0])==26)   # Sanity Check\n",
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c99/'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run of single indivdual\n",
    "Takes about 45 seconds for one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "assert(logfile==False)\n",
    "multi_run(hapsb_chrom, [prms[119]], processes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full list of parameters\n",
    "Watch out: 20 or even 10 does not work.\n",
    "\n",
    "With runtime updates: Shoots up to 10 gb memory per process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 400 total jobs; 10 in parallel.\n",
      "Starting Pool of multiple workers...\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid40/chr3/c95/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid0/chr3/c95/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid20/chr3/c95/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid50/chr3/c95/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid30/chr3/c95/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid60/chr3/c95/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid80/chr3/c95/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid90/chr3/c95/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid70/chr3/c95/hmm_run_log.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI6/lambda_rc1.0/ch3_0cm/output/iid10/chr3/c95/hmm_run_log.txt\n",
      "CPU times: user 873 ms, sys: 491 ms, total: 1.36 s\n",
      "Wall time: 15min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "assert(logfile==True) # Sanity Check\n",
    "multi_run(hapsb_chrom, prms[:], processes = 10) # #For all ref: 4 for everything, 8 for 0.5x. For Europe only multiply x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up ground truth ROH into according folders\n",
    "Modify function if multiple prefix_out are given\n",
    "\n",
    "Takes about 30s for 600 prms  \n",
    "Takes about 4s for 200 prms! (including 100 0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_gt():\n",
    "    \"\"\"Split up ground truth roh.csv into\n",
    "    ground truth for each folder\"\"\"\n",
    "    for f in folders:\n",
    "        for iid in iids[:]:\n",
    "            for cutoff in cutoffs:\n",
    "                prefix_out = \"c\" + str(cutoff).replace(\"0.\", \"\") + \"/\" # Comment out\n",
    "                #prefix_out=\"test/\"\n",
    "                path_out = os.path.join(f, \"output\", iid, \"chr\"+str(ch), prefix_out)\n",
    "                split_up_roh_df(f, path_out, iid, \n",
    "                                file_in=\"roh_info.csv\", \n",
    "                                file_out=\"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 150 ms, total: 2.23 s\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_gt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run various degrees of downsampling for read-count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "iids = [\"iid\" + str(i) for i in range(0,100)]   # List of iids to iterate over\n",
    "ch = 3 # For test case here: Only do Chromosome #3\n",
    "n_ref = 2504  # 2504 All 503 Europe/TSI\n",
    "save = True\n",
    "save_fp = False\n",
    "diploid_ref = True\n",
    "\n",
    "exclude_pops = [\"TSI\", ]\n",
    " \n",
    "e_model = \"haploid\"  # \"readcount\"\n",
    "p_model = \"MosaicHDF5\"  \n",
    "readcounts = False\n",
    "destroy_phase = True\n",
    "\n",
    "post_model = \"Standard\"\n",
    "h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240int8/chr\" # Switch: Eur1240chr\n",
    "meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\"  # meta_df.csv for full 1000G\n",
    "\n",
    "prefix_out = \"ph_c999/\"\n",
    "roh_in = 1   #1  New: 0.1\n",
    "roh_out = 20 # 20 Good: 10\n",
    "roh_jump = 300\n",
    "e_rate = 0.01  # The Error Rate\n",
    "e_rate_ref = 0.0\n",
    "max_gap = 0.01 # Gap Merging. In M\n",
    "#cutoffs = [0.9, 0.99, 0.9999, 0.99999]\n",
    "#cutoffs = [0.996, 0.997, 0.998, 0.999]\n",
    "#cutoffs = [0.998, 0.999, 0.9995]\n",
    "cutoff = 0.999\n",
    "l_cutoff = 0.01\n",
    "\n",
    "logfile = True\n",
    "rcs = [\"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\"] # Various degrees of missing data\n",
    "rcs = [\"0.3\"]\n",
    "lengths = [0, 4]  # Relevant ones for key performance testing\n",
    "base_path = \"./Simulated/1000G_Mosaic/TSI5/lambda_rc\" #0.4/ch3_4cm/data.h5\"\n",
    "\n",
    "#########################################################\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "\n",
    "prms = []\n",
    "for rc in rcs:\n",
    "    folders = [base_path + rc + \"/ch\" + str(ch) + \"_\" \n",
    "               + str(int(l)) + \"cm/\" for l in lengths]\n",
    "    \n",
    "    for f in folders: \n",
    "        path_targets = f + \"data.h5\"\n",
    "        base_out_folder = os.path.join(f, \"output\", \"\")\n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, save, save_fp, n_ref, diploid_ref, exclude_pops, e_model, p_model, readcounts, destroy_phase,\n",
    "            post_model, path_targets, h5_path1000g, meta_path_ref, base_out_folder, prefix_out,\n",
    "            roh_in, roh_out, roh_jump, e_rate, e_rate_ref, max_gap, cutoff, l_cutoff, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "        \n",
    "assert(len(prms[0]) == 26)   # Sanity Check\n",
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run of single individual\n",
    "Check how long a single individual runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prms[1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "assert(logfile==False)\n",
    "multi_run(hapsb_chrom, [prms[1400]], processes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run full set of replicates\n",
    "Single replicate: ~30s. \n",
    "Depending on how much downsampling was done.\n",
    "\n",
    "100 Replicates with 10 cores ~ 2-5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 200 total jobs; 12 in parallel.\n",
      "Starting Pool of multiple workers...\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid15/chr3/ph_c999/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid10/chr3/ph_c999/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid0/chr3/ph_c999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid25/chr3/ph_c999/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid20/chr3/ph_c999/hmm_run_log.txt\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid5/chr3/ph_c999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid40/chr3/ph_c999/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid30/chr3/ph_c999/hmm_run_log.txtSet Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid35/chr3/ph_c999/hmm_run_log.txt\n",
      "\n",
      "\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid55/chr3/ph_c999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid50/chr3/ph_c999/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.3/ch3_0cm/output/iid45/chr3/ph_c999/hmm_run_log.txt\n",
      "CPU times: user 233 ms, sys: 186 ms, total: 420 ms\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "assert(logfile == True) # Sanity Check\n",
    "multi_run(hapsb_chrom, prms[:], \n",
    "          processes = 12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_gt():\n",
    "    \"\"\"Split up ground truth roh.csv into\n",
    "    ground truth for each folder\"\"\"\n",
    "    for rc in rcs:\n",
    "        folders = [base_path + rc + \"/ch\" + str(ch) + \"_\" \n",
    "                   + str(int(l)) + \"cm/\" for l in lengths]\n",
    "        for f in folders:\n",
    "            for iid in iids[:]:\n",
    "                #prefix_out = \"c\" + str(cutoff).replace(\"0.\", \"\") + \"/\" # Comment out\n",
    "                prefix_out=\"ph_c999/\"\n",
    "                path_out = os.path.join(f, \"output\", iid, \"chr\" + str(ch), prefix_out)\n",
    "                split_up_roh_df(f, path_out, iid, \n",
    "                                file_in=\"roh_info.csv\", \n",
    "                                file_out=\"roh_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 73 ms, total: 1.14 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

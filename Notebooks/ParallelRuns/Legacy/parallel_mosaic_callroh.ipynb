{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to call ROH in parallel [Legacy as of February2020, refactored with new functions]\n",
    "Includes Notebooks that import the code for the calling ROHs on Mosaics, and then functions for various cases to parallelize it\n",
    "\n",
    "@Author: Harald Ringbauer, June 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0402.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"./package/hapsburg/\")  # Since now we are in the Root Directory\n",
    "from hmm_inference import HMM_Analyze   # Do not move. Should be after sys.path..\n",
    "\n",
    "from PackagesSupport.parallel_runs.helper_functions import split_up_roh_df, prepare_path\n",
    "from PackagesSupport.parallel_runs.helper_functions import prepare_path, create_folders, postprocess_iid\n",
    "#from PackagesSupport.hapsburg_run import hapsb_chrom, hapsb_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions and Paralellize Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_individual(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                       path_mosaic=\"./Simulated/1000G_Mosaic/TSI/ch3_5cm/\",\n",
    "                       exclude_pops=[\"TSI\", ], prefix_out=\"\", \n",
    "                       roh_in=1, roh_out=10, roh_jump=100, e_rate=0.001, logfile=True):\n",
    "    \"\"\"Run the analysis for one individual and chromosome.\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Prepare output folder, and pipe output to log file if wanted\n",
    "    path_out = prepare_path(path_mosaic, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    ### Do the full HMM Analysis\n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"diploid_gt\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)  \n",
    "    # \"diploid_gt\" for analysis of dpld. \"haploid\" for analysis of haploid\n",
    "\n",
    "    ### Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(destroy_phase=True, prefix_out_data=prefix_out,\n",
    "                        excluded=exclude_pops, h5_path_targets=path_mosaic + \"data.h5\",\n",
    "                        base_out_folder=os.path.join(path_mosaic, \"output\",\"\"))\n",
    "    ### Set paths for reference: DELETE when run for with European Reference!!\n",
    "    hmm.p_obj.set_params(h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr\", \n",
    "                         meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\")\n",
    "    \n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    hmm.load_secondary_objects()  # Load transition, emission and postprocessing objects\n",
    "    \n",
    "    ### Set the Parameters\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "    hmm.e_obj.set_params(e_rate=e_rate)\n",
    "    \n",
    "    #hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, path_out, iid)\n",
    "    \n",
    "    print(f\"Analysis of {iid} and Chr. {ch} successfully concluded!\")\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "### Do the Read Count Analysis Function\n",
    "\n",
    "def analyze_individual_rc(iid, ch=3, n_ref=503, save=True, save_fp=False,\n",
    "                          path_mosaic=\"./Simulated/1000G_Mosaic/TSI/RC1.0/ch3_5cm/\",\n",
    "                          exclude_pops=[\"TSI\", ], prefix_out=\"\",\n",
    "                          roh_in=1, roh_out=10, roh_jump=100, e_rate=0.01, e_rate_ref=0.001, logfile=True):\n",
    "    \"\"\"Run the analysis for one individual and chromosome on readcount data\n",
    "    Wrapper for HMM Class\"\"\"\n",
    "    \n",
    "    ### Create Folder if needed, and pipe output if wanted\n",
    "    path_output = os.path.join(path_mosaic, \"output\", \"\")  # Include the \"output\" Folder\n",
    "    path_out = prepare_path(path_output, iid, ch, prefix_out, logfile=logfile)\n",
    "    \n",
    "    if os.path.exists(os.path.join(path_out, \"roh.csv\")):\n",
    "        return\n",
    "    \n",
    "    hmm = HMM_Analyze(cython=2, p_model=\"MosaicHDF5\", e_model=\"readcount\", post_model=\"Standard\",\n",
    "                      manual_load=True, save=save, save_fp=save_fp)\n",
    "\n",
    "    # Load and prepare the pre-processing Model\n",
    "    hmm.load_preprocessing_model()              # Load the preprocessing Model\n",
    "    hmm.p_obj.set_params(readcounts=True, destroy_phase=False,\n",
    "                         prefix_out_data=prefix_out, excluded=exclude_pops,\n",
    "                         h5_path_targets=path_mosaic + \"data.h5\",\n",
    "                         base_out_folder=path_output)\n",
    "\n",
    "    ### Set paths for reference: DELETE when run for with European Reference!!\n",
    "    hmm.p_obj.set_params(h5_path1000g = \"./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr\", \n",
    "                         meta_path_ref = \"./Data/1000Genomes/Individuals/meta_df_all.csv\")\n",
    "\n",
    "    hmm.load_data(iid=iid, ch=ch, n_ref=n_ref)  # Load the actual Data\n",
    "    hmm.load_secondary_objects()\n",
    "\n",
    "    ### Set the Parameters\n",
    "    hmm.e_obj.set_params(e_rate=e_rate, e_rate_ref=e_rate_ref)\n",
    "    hmm.t_obj.set_params(roh_in=roh_in, roh_out=roh_out, roh_jump=roh_jump)\n",
    "\n",
    "    #hmm.calc_viterbi_path(save=save)           # Calculate the Viterbi Path.\n",
    "    hmm.calc_posterior(save=save)              # Calculate the Posterior.\n",
    "    hmm.post_processing(save=save)             # Do the Post-Processing.\n",
    "    \n",
    "    ### Split up the (only works for Mosaic so be careful when transferring this code)\n",
    "    split_up_roh_df(path_mosaic, path_out, iid)\n",
    "    \n",
    "#########################################################\n",
    "#########################################################\n",
    "    \n",
    "def multi_run(fun, prms, processes = 4):\n",
    "    \"\"\"Implementation of running in Parallel.\n",
    "    fun: Function\n",
    "    prms: The Parameter Files\n",
    "    processes: How many Processes to use\"\"\"\n",
    "    print(f\"Running {len(prms)} jobs in parallel.\")\n",
    "    with mp.Pool(processes = processes) as pool:\n",
    "        results = pool.starmap(fun, prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parallel Calling on TSI (single Target HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503  # 2504 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"test_d/\"  # allRef\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 300\n",
    "e_rate = 0.001  # The Error Rate\n",
    "n = 100\n",
    "logfile = False\n",
    "\n",
    "lengths = [0, 2, 4, 6, 8, 10] # Which Block Lengths to test\n",
    "lengths = [4, 0]  # Only do the relevant ones for key performance testing\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for f in folders:\n",
    "    for iid in iids:\n",
    "        new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "        prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 13 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid0/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid90/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_2cm/output/iid20/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid30/chr/3/allRef/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/YRI/ch3_0cm/output/iid60/chr/3/allRef/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")\n",
    "print(\"Run complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a single example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Low-Mem Cython Linear Speed Up.\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 2504 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77652\n",
      "Nr of Matching Refs: 77652 / 77652\n",
      "Full Intersection Ref/Alt Identical: 77652 / 77652\n",
      "2397 / 2504 Individuals included in Reference\n",
      "Extraction of 2 Haplotypes Complete!\n",
      "Extraction of 1000 Haplotypes Complete!\n",
      "Reduced to markers called 77652 / 77652\n",
      "(Fraction SNP: 1.0)\n",
      "Successfully saved to: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/\n",
      "Shuffling phase of target...\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/\n",
      "Loaded Emission Model: diploid_gt\n",
      "Loaded Transition Model: model\n",
      "Loaded Post Processing Model: Standard\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2326\n",
      "Gaps bigger than 0.1 cM: 214\n",
      "Maximum Gap: 0.2348 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(1001, 77652)\n",
      "Loaded Observations:\n",
      "(2, 77652)\n",
      "Memory Usage: 920.244224 mB\n",
      "Reference Number: 1000\n",
      "Total Log likelihood: -35651.505\n",
      "Memory Usage: 924.50816 mB\n",
      "Finished Calculation State Posteriors\n",
      "Saved Zero State Posterior to ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/\n",
      "Fraction Markers in ROH: 0.3669\n",
      "Merged n=0 gaps < 0.01 M\n",
      "Called n=5 ROH Blocks > 1.0 cM\n",
      "Longest Block: 4.472\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/ch3_4cm/output/iid0/chr3/test_d/roh.csv\n",
      "Analysis of iid0 and Chr. 3 successfully concluded!\n",
      "CPU times: user 25.7 s, sys: 1.07 s, total: 26.8 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analyze_individual(*prms[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROHS Blocks within multiple target HDF5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "prefix_out = \"ROH1000/\" # Initially: None\n",
    "\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 1000\n",
    "e_rate = 0.001  # The Error Rate\n",
    "\n",
    "n = 100\n",
    "#targets = [\"CHB\", \"CLM\", \"YRI\"]\n",
    "targets = [\"TSI5\",]\n",
    "lengths = [0, 2, 4, 6, 8, 10]\n",
    "logfile = True\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for t in targets:\n",
    "    base_path1 = base_path + t + \"/\"\n",
    "    folders = [base_path1 + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "    for f in folders:\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi_run(analyze_individual, [prms[0],], processes = 1)  # To Trouble Shoot\n",
    "len(prms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid57/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid33/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/output/iid14/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid38/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid19/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid76/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid0/chr3/ROH1000/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/output/iid95/chr3/ROH1000/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for multiple error levels (and multiple lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.01  # The Error Rate\n",
    "n = 100\n",
    "prefix_out = \"e01/\"   # Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] # For chromosomes\n",
    "error_vec = np.logspace(-3,-1, 8)\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "logfile = True\n",
    "#folders = [base_path + \"ch\" + str(ch) + \"_\" + str(int(l)) + \"cm/\" for l in lengths]  # Prepare Length folders\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for l in lengths:\n",
    "    for e in error_vec:\n",
    "        e_print = str(round(e, 4)).split(\".\")[1] # Extract four digits after decimal         \n",
    "        f = base_path + \"ch3_\" + str(l) + \"cm/error/\" + e_print + \"/\"   \n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4800 jobs in parallel.\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/001/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0072/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0019/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0139/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0037/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/0518/output/iid0/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/error/1/output/iid50/chr3/e01/hmm_run_log.txt\n",
      "Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/error/0019/output/iid0/chr3/e01/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for multiple downsample levels (and multiple lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref = 503\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"   #TSI5 CHB\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.001    # The Error Rate\n",
    "n = 100\n",
    "prefix_out = \"diploidGT/\"   #  e01/ Error saved in folder structure\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] \n",
    "missing_vec = np.linspace(0.1, 1.0, 10)\n",
    "#missing_vec = np.array([0.1, 0.2])\n",
    "logfile = True\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for l in lengths:\n",
    "    for m in missing_vec:\n",
    "        m_print = str(round(m, 4)).split(\".\")[1] # Extract four digits after decimal         \n",
    "        f = base_path + \"ch3_\" + str(l) + \"cm/missing/\" + m_print + \"/\"   \n",
    "\n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0])==13)   # The function takes 12 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 6000 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/1/output/iid0/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/missing/1/output/iid0/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/3/output/iid50/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/8/output/iid50/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_0cm/missing/6/output/iid0/chr3/diploidGT/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/ch3_2cm/missing/3/output/iid50/chr3/diploidGT/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual, prms, processes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call ROH for ReadCount data (Normal or Lambda)\n",
    "For Lambda change folder name (parameter f below)\n",
    "\n",
    "In above function analyze_individual_rc it is hard-coded which reference files to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Parameter files and run\n",
    "#### Create the parameters array for the starmap:\n",
    "ch = 3\n",
    "n_ref=2504\n",
    "save=True\n",
    "save_fp=False\n",
    "base_path=\"./Simulated/1000G_Mosaic/TSI5/\"   #TSI5 CHB\n",
    "exclude_pops = [\"TSI\", ]\n",
    "roh_in = 100 \n",
    "roh_out= 100\n",
    "roh_jump= 385\n",
    "e_rate = 0.001    # The Error Rate for Read Count\n",
    "e_rate_ref = 0.001 # The  Error Rate for Reference Genotypes\n",
    "n = 100  # The Number of Individuals\n",
    "prefix_out = \"allref/\"   #  e01/ e001/ Error saved in folder structure ROH385\n",
    "\n",
    "### The arrays to iterate over\n",
    "lengths = [0, 2, 4, 6, 8, 10] \n",
    "\n",
    "mean_rcs = np.linspace(0.1, 1, 10)\n",
    "#mean_rcs= [mean_rcs[-1],]\n",
    "logfile = True\n",
    "\n",
    "### Create list of IIDs and of Folders\n",
    "iids = [\"iid\" + str(i) for i in range(n)]   # Prepare List of iids\n",
    "\n",
    "### Create the List of Parameter Lists (input for starmap)\n",
    "prms = []\n",
    "\n",
    "for m_rc in mean_rcs:\n",
    "    for l in lengths:      \n",
    "        #f = base_path + \"lambda_rc\" + f\"{m_rc:.1f}\" + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        f = base_path + \"lambda_rc\" + str(m_rc) + \"/ch3_\" + str(l) + \"cm/\"   # lambda_rc or rc\n",
    "        \n",
    "        for iid in iids:\n",
    "            new_par = [iid, ch, n_ref, save, save_fp, f, exclude_pops, prefix_out, roh_in, roh_out, roh_jump, e_rate, e_rate_ref, logfile]\n",
    "            prms.append(new_par)  # Append to the Parameters\n",
    "\n",
    "assert(len(prms[0]) == 14)  # The RC function takes 14 Parameters as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3000 jobs in parallel.\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_0cm/output/iid0/chr3/allref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_2cm/output/iid25/chr3/allref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_4cm/output/iid50/chr3/allref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid75/chr3/allref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.7000000000000001/ch3_0cm/output/iid25/chr3/allref/hmm_run_log.txt\n",
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_10cm/output/iid0/chr3/allref/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "multi_run(analyze_individual_rc, prms[3000:], processes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unnecessary folders\n",
    "(Introduced by happy little accident where \"output\" was forgotten in prepare path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prm in prms:\n",
    "    print(f\"Doing {prm[0]}...\")\n",
    "    f0 = os.path.join(prm[5], prm[0], \"\")\n",
    "    !rm -r $f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(f, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run for single individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(prms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iid0',\n",
       " 3,\n",
       " 2504,\n",
       " True,\n",
       " False,\n",
       " './Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_0cm/',\n",
       " ['TSI'],\n",
       " 'allref/',\n",
       " 100,\n",
       " 100,\n",
       " 385,\n",
       " 0.001,\n",
       " 0.001,\n",
       " False]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prms[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Low-Mem Cython Linear Speed Up.\n",
      "Loaded Pre Processing Model: MosaicHDF5\n",
      "Loading Individual: iid0\n",
      "Creating folder ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid0/chr3/allref/...\n",
      "\n",
      "Loaded 77650 variants\n",
      "Loaded 100 individuals\n",
      "HDF5 loaded from ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/data.h5\n",
      "\n",
      "Loaded 77652 variants\n",
      "Loaded 2504 individuals\n",
      "HDF5 loaded from ./Data/1000Genomes/HDF5/1240kHDF5/all1240/chr3.hdf5\n",
      "\n",
      "Intersection on Positions: 77650\n",
      "Nr of Matching Refs: 77650 / 77650\n",
      "Full Intersection Ref/Alt Identical: 77650 / 77650\n",
      "2397 / 2504 Individuals included in Reference\n",
      "Extraction of 2 Haplotypes complete\n",
      "Extraction of 4794 Haplotypes complete\n",
      "Reduced to markers called 28745 / 77650\n",
      "(Fraction SNP: 0.37018673535093366)\n",
      "Successfully saved to: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid0/chr3/allref/\n",
      "Loading Readcounts...\n",
      "Mean Readcount markers loaded: 1.62362\n",
      "Successfully loaded Data from: ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid0/chr3/allref/\n",
      "Loaded Emission Model: readcount\n",
      "Loaded Transition Model: model\n",
      "Loaded Post Processing Model: Standard\n",
      "Minimum Genetic Map: 0.0000\n",
      "Maximum Genetic Map: 2.2325\n",
      "Gaps bigger than 0.1 cM: 380\n",
      "Maximum Gap: 0.3910 cM\n",
      "Loaded Transition and Emission Matrix:\n",
      "(3, 3)\n",
      "(4795, 28745)\n",
      "Loaded Observations:\n",
      "(2, 28745)\n",
      "Memory Usage: 1406.5664 mB\n",
      "Reference Number: 4794\n",
      "Total Log likelihood: -12931.234\n",
      "Memory Usage: 1406.570496 mB\n",
      "Finished Calculation State Posteriors\n",
      "Saved Zero State Posterior to ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid0/chr3/allref/.\n",
      "Successfully loaded for PP. from ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid0/chr3/allref/\n",
      "Fraction Markers in ROH: 0.3674\n",
      "Merged n=1 gaps < 0.01 M\n",
      "Called n=6 ROH Blocks > 1.0 cM\n",
      "Longest Block: 9.007\n",
      "Successfully saved to ./Simulated/1000G_Mosaic/TSI5/lambda_rc0.6/ch3_6cm/output/iid0/chr3/allref/roh.csv\n",
      "CPU times: user 1min 58s, sys: 8.73 s, total: 2min 6s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analyze_individual_rc(*prms[3300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single parameter run\n",
    "Set logfile=False in analyze_individual to print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Output Log path: ./Simulated/1000G_Mosaic/TSI5/lambda_rc1.0/ch3_8cm/output/iid0/chr3/hmm_run_log.txt\n"
     ]
    }
   ],
   "source": [
    "analyze_individual_rc(*prms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

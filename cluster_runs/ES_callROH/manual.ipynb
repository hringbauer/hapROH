{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Clusterbatch Code\n",
    "Same code as in ./run_individual.py, but with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway2-0401.rcc.local\n",
      "Midway jnovmbre partition detected.\n",
      "/project2/jnovembre/hringbauer/HAPSBURG\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/HAPSBURG/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "### Assume that now we are in the root directory\n",
    "sys.path.append(\"./package/\")  \n",
    "\n",
    "from hapsburg.hmm_inference import HMM_Analyze   # The HMM core object\n",
    "from hapsburg.PackagesSupport.hapsburg_run import hapsb_chrom, hapsb_ind\n",
    "from hapsburg.PackagesSupport.pp_individual_roh_csvs import create_combined_ROH_df, give_iid_paths, pp_individual_roh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eigenstrat_anno(path=\"./Data/ReichLabEigenstrat/Raw/v37.2.1240K.clean4.anno\", \n",
    "                         anc_only=True, min_snps=400000):\n",
    "    \"\"\"Load annotated Eigenstrat (from D. Reich's group).\n",
    "    anc_only: Return only the ancients with age>0\"\"\"\n",
    "    df_anno = pd.read_csv(path, sep=\"\\t\", engine=\"python\")\n",
    "    coverage = pd.to_numeric(df_anno[\"Coverage\"], errors='coerce')\n",
    "    df_anno[\"coverage\"]=coverage\n",
    "\n",
    "    # Convert the Ages as well\n",
    "    ages = df_anno[\"Average of 95.4% date range in calBP (defined as 1950 CE)  \"]\n",
    "    df_anno[\"ages\"] = pd.to_numeric(ages, errors='coerce')  #\n",
    "\n",
    "    ### Convert Longitude and Latitude\n",
    "    lat = df_anno[\"Lat.\"]\n",
    "    lon = df_anno[\"Long.\"]\n",
    "    df_anno[\"lat\"] = pd.to_numeric(lat, errors='coerce')\n",
    "    df_anno[\"lon\"] = pd.to_numeric(lon, errors='coerce')\n",
    "    \n",
    "    if anc_only:\n",
    "        df_anc = df_anno[df_anno[\"ages\"]>0]\n",
    "        print(f\"Loaded {len(df_anc)} / {len(df_anno)} ancient Indivdiuals Anno File.\")\n",
    "        df_anno=df_anc\n",
    "        \n",
    "    df_anno = df_anno[df_anno[\"SNPs hit on autosomes\"]>min_snps]\n",
    "    print(f\"Loaded {len(df_anno)} Individuals with >{min_snps} SNPs covered\")\n",
    "    return df_anno\n",
    "\n",
    "def load_meta_csv(path=\"\", anc_only=True, min_snps=400000,\n",
    "                 cov_col=\"n_cov_snp\"):\n",
    "    \"\"\"Load dataframe from pre-processed Metafile\"\"\"\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    \n",
    "    if anc_only:\n",
    "        df_anc = df[df[\"age\"]>0]\n",
    "        print(f\"Loaded {len(df_anc)} / {len(df)} ancient Indivdiuals Anno File.\")\n",
    "        df=df_anc\n",
    "        \n",
    "    df[cov_col] = pd.to_numeric(df[cov_col], errors=\"coerce\")\n",
    "    df = df[df[cov_col]>min_snps]\n",
    "    print(f\"Loaded {len(df)} Individuals with >{min_snps} SNPs covered\")\n",
    "    return df\n",
    "    \n",
    "def get_iid_from_df(df, i, id_col=\"Instance ID\"):\n",
    "    \"\"\"Get the Individual IID\"\"\"\n",
    "    if i<0 or i>=len(df):    # Sanity Check\n",
    "        raise RuntimeError(f\"Index {i} out of Range of High Coverage ancients.\") \n",
    "    iid = df[id_col].values[i]\n",
    "    return iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2106 / 5081 ancient Indivdiuals Anno File.\n",
      "Loaded 1095 Individuals with >400000 SNPs covered\n"
     ]
    }
   ],
   "source": [
    "df_anno = load_eigenstrat_anno(path=\"./Data/ReichLabEigenstrat/Raw/v37.2.1240K.clean4.anno\")\n",
    "#df_anno = pd.read_csv(\"./cluster_runs/ES_callROH/rerun_top100.csv\")  # For the rerun of Shotgun Individuals\n",
    "#get_iid_from_df(df_anno, 1094, id_col=\"Instance ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for the v42 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 / 30 ancient Indivdiuals Anno File.\n",
      "Loaded 28 Individuals with >400000 SNPs covered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Goyet_final_provisional.SG'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno = load_meta_csv(path = \"./Data/ReichLabEigenstrat/Raw/meta.v42_old.csv\",\n",
    "                       min_snps=400000)  # meta.v42_additional.csv or _core.csv\n",
    "get_iid_from_df(df_anno, 20, id_col=\"iid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_anno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for the actual run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        raise RuntimeError(\"Script needs argument (indiviual i)\")\n",
    "    #run_nr = int(sys.argv[1]) # The Parameter passed to the Python Script from outside\n",
    "    df_anno = load_eigenstrat_anno()\n",
    "    iid = get_iid_from_df(df_anno, run_nr, id_col=\"Instance ID\")\n",
    "    \n",
    "    hapsb_ind(iid, chs=range(21, 23), processes=1, delete=False, output=True, \n",
    "               save=True, save_fp=False, n_ref=2504, exclude_pops=[], \n",
    "               e_model='haploid', p_model='EigenstratPacked', readcounts=False, \n",
    "               destroy_phase=True, post_model='Standard', \n",
    "               path_targets='./Data/ReichLabEigenstrat/Raw/v37.2.1240K', \n",
    "               h5_path1000g='./Data/1000Genomes/HDF5/1240kHDF5/all1240int8/chr', \n",
    "               meta_path_ref='./Data/1000Genomes/Individuals/meta_df_all.csv', \n",
    "               base_out_folder='./Empirical/Eigenstrat/Reichall/final/', prefix_out='', \n",
    "               roh_in=1, roh_out=20, roh_jump=300, e_rate=0.01, e_rate_ref=0.0, max_gap=0, \n",
    "               cutoff=0.999, l_cutoff=0.02, logfile=True, combine=True, file_name='_roh_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area 51: Do a Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid='Sumidouro6.SG'\n",
    "hapsb_ind(iid, chs=range(21, 23), processes=1, delete=False, output=True, \n",
    "           save=True, save_fp=False, n_ref=2504, exclude_pops=[], \n",
    "           e_model='haploid', p_model='EigenstratPacked', readcounts=False, \n",
    "           destroy_phase=True, post_model='Standard', \n",
    "           path_targets='./Data/ReichLabEigenstrat/Raw/v37.2.1240K', \n",
    "           h5_path1000g='./Data/1000Genomes/HDF5/1240kHDF5/all1240int8/chr', \n",
    "           meta_path_ref='./Data/1000Genomes/Individuals/meta_df_all.csv', \n",
    "           base_out_folder='./Empirical/Eigenstrat/Reichall/final/', prefix_out='', \n",
    "           roh_in=1, roh_out=20, roh_jump=300, e_rate=0.01, e_rate_ref=0.0, max_gap=0, \n",
    "           cutoff=0.999, l_cutoff=0.02, logfile=True, combine=False, file_name='_roh_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def extract_snps_hdf5(h5, ids_ref, markers, diploid=False):\n",
    "        \"\"\"Extract genotypes from h5 on ids and markers.\n",
    "        If diploid, concatenate haplotypes along 0 axis.\n",
    "        Extract indivuals first, and then subset to SNPs.\n",
    "        Return 2D array [# haplotypes, # markers]\"\"\"\n",
    "        # Important: Swap of Dimensions [loci<->individuals]\n",
    "        nblocks = math.ceil(len(markers)/8)\n",
    "        nsample = len(ids_ref)\n",
    "        ploidy = 2 if diploid else 1\n",
    "        gts = np.zeros((ploidy*nsample, nblocks), dtype=np.uint8)\n",
    "        haplotype_id_with_missing_data = set() # maintain a list of haplotype ids with missing data at any site of interest\n",
    "        for i in range(nblocks):\n",
    "            j = min((i+1)*8, len(markers))\n",
    "            raw_gt = h5[\"calldata/GT\"][markers[i*8:j], :, :ploidy] # can only indexing one dimension at a time, so need to split this into two lines of code\n",
    "            raw_gt = raw_gt[:, ids_ref, :].reshape((-1, ploidy*nsample)).T\n",
    "            haplotype_id_with_missing_data.update(np.where(raw_gt == -1)[0])\n",
    "            gts[:, i] = np.packbits(raw_gt, axis=1).flatten()\n",
    "\n",
    "        # get rid of haplotypes with missing data\n",
    "        # eg. male samples only have one chrX\n",
    "        gts = gts[np.setdiff1d(np.arange(ploidy*nsample), list(haplotype_id_with_missing_data)), :]\n",
    "        return gts, markers%8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530434, 2504, 2)\n",
      "(530434, 2504, 2)\n",
      "(array([[ 56,   0],\n",
      "       [176,   0],\n",
      "       [ 24,   0],\n",
      "       [220,   0]], dtype=uint8), array([5, 3, 7, 2, 5, 7, 7, 2, 5, 4, 0]))\n",
      "[[0 0 1 1 1 0 0 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0]\n",
      " [1 1 0 1 1 1 0 0 0 0 0]]\n",
      "[[ 56   0]\n",
      " [176   0]\n",
      " [ 24   0]\n",
      " [220   0]]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "path2h5 = '/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/maf5_auto/maf5_chr1.hdf5'\n",
    "f = h5py.File(path2h5, 'r')\n",
    "nloci, nsample, ploidy = f['calldata/GT'].shape\n",
    "print(f['calldata/GT'].shape)\n",
    "ids_ref = np.array([5,10])\n",
    "markers = np.sort(np.random.choice(nloci, 11, replace=False))\n",
    "\n",
    "gts_compact = extract_snps_hdf5(f, ids_ref, markers, diploid=True)\n",
    "print(f['calldata/GT'].shape)\n",
    "gts_raw = f['calldata/GT'][markers, :, :]\n",
    "gts_raw = gts_raw[:, ids_ref, :].reshape((-1, 4)).T\n",
    "print(gts_compact)\n",
    "print(gts_raw)\n",
    "print(np.packbits(gts_raw, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3-th bit of 0b101011 is: 1\n"
     ]
    }
   ],
   "source": [
    "def get_ith_bit(number, i):\n",
    "    # Shift the number i positions to the right and perform a bitwise AND with 1\n",
    "    # This will isolate the i-th bit\n",
    "    return (number >> i) & 1\n",
    "\n",
    "# Example usage:\n",
    "binary_number = 0b101011   # Example binary number\n",
    "i = 3                       # Index of the bit to extract (0-based indexing)\n",
    "result = get_ith_bit(binary_number, i)\n",
    "print(f\"The {i}-th bit of {bin(binary_number)} is: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check my bit-wise operation for allele frequency calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "path2h5 = '/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/maf5_auto/maf5_chr18.hdf5'\n",
    "f = h5py.File(path2h5, 'r')\n",
    "nloci, nsample, ploidy = f['calldata/GT'].shape\n",
    "print(f['calldata/GT'].shape)\n",
    "ids_ref = np.arange(nsample)\n",
    "markers = np.arange(nloci)\n",
    "\n",
    "blocksize = 8\n",
    "gts_compact, overhang = extract_snps_hdf5(f, ids_ref, markers, diploid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21345847, 0.09704473, 0.10023962, 0.19968051, 0.24001597,\n",
       "       0.20507188, 0.06908946, 0.12679712])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def allele_freq_per_block(gts_one_block, blocksize):\n",
    "    \"\"\"Calculate allele frequency per block.\n",
    "    Return 1D array of length blocksize\"\"\"\n",
    "    freq = np.zeros(blocksize)\n",
    "    for i in range(blocksize):\n",
    "        freq[i] = np.mean(gts_one_block >> (blocksize -1 - i) & 1)\n",
    "    return freq\n",
    "\n",
    "allele_freq_per_block(gts_compact[:, -1], blocksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5008, 12152)\n",
      "for loop takes 1.5874099731445312 seconds\n",
      "normal calculation takes 0.30373620986938477 seconds\n",
      "blockwise calculation takes 1.7471349239349365 seconds\n",
      "[0.11242013 0.14117412 0.09384984 ... 0.20507188 0.06908946 0.12679712]\n",
      "[0.11242013 0.14117412 0.09384984 ... 0.20507188 0.06908946 0.12679712]\n",
      "[0.11242013 0.14117412 0.09384984 ... 0.20507188 0.06908946 0.12679712]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "allelefreq = np.zeros(nloci)\n",
    "print(gts_compact.shape)\n",
    "t1 = time.time()\n",
    "for i in range(nloci):\n",
    "    index = i//blocksize\n",
    "    offset = i%blocksize\n",
    "    allelefreq[i] = np.sum(gts_compact[:, index] >> (blocksize - 1 - offset) & 1)/gts_compact.shape[0]\n",
    "print(f'for loop takes {time.time()-t1} seconds')\n",
    "\n",
    "gts = f['calldata/GT'][:, :, :]\n",
    "gts = gts.reshape((nloci, nsample*2)).T\n",
    "t1 = time.time()\n",
    "allelefreq_normal_calculation = np.mean(gts, axis=0)\n",
    "print(f'normal calculation takes {time.time()-t1} seconds')\n",
    "\n",
    "# blockwise computation\n",
    "t1 = time.time()\n",
    "allelefreq_blockwise = np.concatenate(np.apply_along_axis(allele_freq_per_block, 0, gts_compact, blocksize).T, axis=0)\n",
    "print(f'blockwise calculation takes {time.time()-t1} seconds')\n",
    "\n",
    "print(allelefreq)\n",
    "print(allelefreq_normal_calculation)\n",
    "print(allelefreq_blockwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51517572 0.22364217 0.07268371 ... 0.11980831 0.12000799 0.16972843]\n"
     ]
    }
   ],
   "source": [
    "gts = f['calldata/GT'][:, :, :]\n",
    "gts = gts.reshape((nloci, nsample*2)).T\n",
    "allelefreq_normal_calculation = np.mean(gts, axis=0)\n",
    "print(allelefreq_normal_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.isclose(allelefreq - allelefreq_normal_calculation, 0, atol=1e-6).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60857344\n",
      "128\n",
      "486857856\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(gts_compact))\n",
    "print(sys.getsizeof(gts))\n",
    "gts_bool = gts.astype(bool)\n",
    "print(sys.getsizeof(gts_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 1 0 0]\n",
      " [1 0 1 ... 1 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "ploidy=2\n",
    "raw_gt = f[\"calldata/GT\"][np.arange(nloci), :, :ploidy]\n",
    "raw_gt = raw_gt[:, np.arange(nsample), :].reshape((-1, ploidy*nsample)).T\n",
    "print(sys.getsizeof(raw_gt))\n",
    "print(raw_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31 46 37 ... 23 68 20]\n",
      " [62 37 54 ... 31 19 76]]\n",
      "(3, 1000)\n",
      "[[0.01]\n",
      " [0.5 ]\n",
      " [0.99]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "DTYPE = np.float64\n",
    "e_rate_ref = 0.001\n",
    "e_rate_read = 0.01\n",
    "rc = np.random.randint(0, 100, (2, 1000))\n",
    "print(rc)\n",
    "\n",
    "p_derived_read = np.empty(3, dtype=DTYPE)\n",
    "p_derived_read[0] = e_rate_read\n",
    "p_derived_read[1] = 0.5\n",
    "p_derived_read[2] = 1 - e_rate_read\n",
    "\n",
    "### precompute one component of the emission probability for the ROH state\n",
    "# aka, the binomial pmf at each marker for each of the three possible underlying genotype 00,01,11\n",
    "genotype_prob = np.empty((2, 3), dtype=DTYPE)\n",
    "genotype_prob[0,0] = 1-e_rate_ref\n",
    "genotype_prob[0,1] = e_rate_ref/2\n",
    "genotype_prob[0,2] = e_rate_ref/2\n",
    "genotype_prob[1,0] = e_rate_ref/2\n",
    "genotype_prob[1,1] = e_rate_ref/2\n",
    "genotype_prob[1,2] = 1-e_rate_ref\n",
    "binom_pmf = binom.pmf(rc[1, :], rc[0, :] + rc[1, :], p_derived_read[:, None])\n",
    "print(binom_pmf.shape)\n",
    "print(p_derived_read[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test directly loading binary genotype array from hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def extract_snps_hdf5(h5, ids_ref, markers, diploid=False):\n",
    "        \"\"\"Extract genotypes from h5 on ids and markers.\n",
    "        If diploid, concatenate haplotypes along 0 axis.\n",
    "        Extract indivuals first, and then subset to SNPs.\n",
    "        Return 2D array [# haplotypes, # markers]\"\"\"\n",
    "        # Important: Swap of Dimensions [loci<->individuals]\n",
    "        nblocks = math.ceil(len(markers)/8)\n",
    "        nsample = len(ids_ref)\n",
    "        ploidy = 2 if diploid else 1\n",
    "        gts = np.zeros((ploidy*nsample, nblocks), dtype=np.uint8)\n",
    "        t1 = time.time()\n",
    "        for i in range(nblocks):\n",
    "            j = min((i+1)*8, len(markers))\n",
    "            raw_gt = h5[\"calldata/GT\"][markers[i*8:j], :, :ploidy] # can only indexing one dimension at a time, so need to split this into two lines of code\n",
    "            raw_gt = raw_gt[:, ids_ref, :].reshape((-1, ploidy*nsample)).T\n",
    "            gts[:, i] = np.packbits(raw_gt, axis=1).flatten()\n",
    "        print(f'extracting genotypes from hdf5 calldata/GT took {time.time()-t1:.2f} seconds')\n",
    "\n",
    "        time1 = time.time()\n",
    "        raw_gt = h5[\"calldata/GTbinary\"][:, ids_ref, :ploidy]\n",
    "        indices = markers // 8\n",
    "        offset = markers % 8\n",
    "        # get the offset bit from the uint8 integer at indices\n",
    "        gts2 = np.packbits((raw_gt[indices, :, :] >> (7 - offset[:, None, None])) & 1, axis=0)\n",
    "        gts2 = gts2.reshape((-1, ploidy*nsample)).T\n",
    "        print(f'extracting genotypes from hdf5 calldata/GTbinary took {time.time()-time1:.2f} seconds')\n",
    "        print(f'gts and gts2 are equal: {np.array_equal(gts, gts2)}')\n",
    "\n",
    "        return gts, markers%8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150277, 2504, 2)\n",
      "extracting genotypes from hdf5 calldata/GT took 2.04 seconds\n",
      "extracting genotypes from hdf5 calldata/GTbinary took 0.06 seconds\n",
      "gts and gts2 are equal: True\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "path2h5 = '/mnt/archgen/users/yilei/Data/1000G/1000g1240khdf5/all1240/maf5_auto/binary/maf5_chr20_binary.hdf5'\n",
    "f = h5py.File(path2h5, 'r')\n",
    "nloci, nsample, ploidy = f['calldata/GT'].shape\n",
    "print(f['calldata/GT'].shape)\n",
    "ids_ref = np.sort(np.random.choice(nsample, 100, replace=False))\n",
    "markers = np.sort(np.random.choice(nloci, 207, replace=False))\n",
    "\n",
    "gts_compact, overhang = extract_snps_hdf5(f, ids_ref, markers, diploid=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
